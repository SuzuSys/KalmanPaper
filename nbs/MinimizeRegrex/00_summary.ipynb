{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd37c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28238313",
   "metadata": {},
   "source": [
    "# Regret 最小化の概要\n",
    "\n",
    "> 概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79e205",
   "metadata": {},
   "source": [
    "## 設定: 確率質量関数\n",
    "\n",
    "$y_t$ は $t$ ごとに存在するパラメータ $\\theta_t\\in[0,1]$ をもつベルヌーイ分布に従う値とする。\n",
    "\n",
    "ベルヌーイ分布の確率質量関数 $p(y_t\\mid\\theta_t)$ は\n",
    "\n",
    "$$p(y_t\\mid\\mathbf w_t,\\mathbf x_t)=\\theta_t^{y_t}(1-\\theta_t)^{1-y_t}\\tag{1}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "である。 \n",
    "\n",
    "ロジスティックシグモイド関数の逆関数として知られるロジット変換 $a$ は\n",
    "\n",
    "$$a(\\theta)=\\ln\\frac{\\theta}{1-\\theta}\\tag{2}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "と定義され、これを $\\theta_t$ について表すと\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "e^{a_t} &=\\frac{\\theta_t}{1-\\theta_t} \\\\\n",
    "\\theta_t &= e^{a_t}(1-\\theta_t) \\\\\n",
    "\\end{split}\\tag{3}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "となる。これを $(1)$ に適用すると、\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "p(y_t\\mid a_t) &= \\theta_t^{y_t}(1-\\theta_t)^{1-y_t} \\\\\n",
    "&= e^{a_ty_t}(1-\\theta_t)^{y_t}(1-\\theta_t)^{1-y_t} \\\\\n",
    "&= e^{a_ty_t}(1-\\theta_t) \\\\\n",
    "&= \\exp\\{ y_ta_t - \\ln (1+e^{a_t}) \\}\n",
    "\\end{split}\\tag{4}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "となる。この変換によって確率質量関数のパラメータは $\\theta_t\\in[0,1]$ から $a_t\\in(-\\infty,+\\infty)$ となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95174d59",
   "metadata": {},
   "source": [
    "## 設定: ロジスティック誤差関数\n",
    "\n",
    "$(4)$ から導出される負の対数尤度 $-\\ln p(y_t\\mid a_t)$ によるロジスティック誤差関数を\n",
    "\n",
    "$$E(y_t,a_t)=-y_ta_t+\\ln(1+e^{a_t})\\tag{5}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "と定義する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e162a3d",
   "metadata": {},
   "source": [
    "## 設定: $a_t$ の系列変化が滑らか\n",
    "\n",
    "$a_t$ の系列の変化が滑らかであるという事前知識を考慮した式\n",
    "\n",
    "$$\\lambda \\sum_{t=1}^{T+1}(a_t-a_{t-1})^2\\tag{6}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "を導入する。$\\lambda$ は予測する系列の滑らかさの度合いを決める係数である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7320a4",
   "metadata": {},
   "source": [
    "## 設定: リグレット\n",
    "\n",
    "リグレットとは、オフライン予測の結果とオンライン予測の予測結果それぞれの損失を比較し、相対的に評価する指標である。\n",
    "\n",
    "オンライン予測の予測結果の系列を $a_1,a_2,\\ldots,a_T$ とし、損失関数を $l(y_t,a_t)$ とする。オフライン予測の予測結果の系列を $\\hat a_1,\\hat a_2,\\ldots,\\hat a_T$ とする。\n",
    "\n",
    "リグレット $R$ は\n",
    "\n",
    "$$R=\\sum_{t=1}^T l(y_t,a_t)-\\min_{\\hat a_1,\\ldots,\\hat a_T}\\left\\{\\sum_{t=1}^Tl(y_t,\\hat a_t)+\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2\\right\\}\\tag{8}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "で定義される。$(12)$ の第２項はスムーザの目的関数であり、オフライン予測の最適な損失を表している。第１項はオンライン予測の損失であるため、「オンライン予測の損失からスムーザの損失を引いたもの」がリグレットとなる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d75ff",
   "metadata": {},
   "source": [
    "## 目的\n",
    "\n",
    "損失関数 $l$ として $(12)$ の $E(y_t,a_t)$ を用い、ミニマックス問題\n",
    "\n",
    "$$\\min_{a_t}\\max_{y_t}\\cdots\\min_{a_T}\\max_{y_T}R\\tag{9}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "を解く。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5b7dc",
   "metadata": {},
   "source": [
    "## 本研究との兼ね合い\n",
    "\n",
    "$\\theta_t$ は $\\sigma_t=\\sigma(\\mathbf w_t^T\\mathbf x_t)$ と対応する。\n",
    "\n",
    "$a_t$ は $\\mathbf w_t^T\\mathbf x_t$ と対応する。\n",
    "\n",
    "$(12)$ は、本研究では\n",
    "\n",
    "$$E(y_t,\\mathbf w_t)=-y_t\\mathbf w_t^T\\mathbf x_t+\\ln(1+e^{\\mathbf w_t^T\\mathbf x_t})\\tag{10}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "と表される。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0403c",
   "metadata": {},
   "source": [
    "## 損失関数の導出\n",
    "\n",
    "$f(a)$ を\n",
    "\n",
    "$$f(a)=\\ln\\left(e^{a/2}+e^{-a/2}\\right)\\tag{11}$$\n",
    "\n",
    "とおく。ここで、$f(a)=g(a^2)$ とおくと、\n",
    "\n",
    "$$g(a^2)=\\ln\\left(e^{\\sqrt {a^2}/2}+e^{-\\sqrt {a^2}/2}\\right)$$\n",
    "\n",
    "\n",
    "となる $g'(a^2)$ は\n",
    "\n",
    "$$g'(a^2)=\\frac{1}{4a}\\tanh\\frac{a}{2}\\tag{12}$$\n",
    "\n",
    "となる。\n",
    "\n",
    "$$g''(a^2)\\le 0\\tag{13}$$\n",
    "\n",
    "となるため、 $g(a^2)$ は凹関数である。これにより、\n",
    "\n",
    "$$g(a^2)\\le g(\\xi^2)+g'(\\xi^2)(a^2-\\xi^2)\\tag{14}$$\n",
    "\n",
    "であるから、 $g'(a^2)=\\phi(a)$ とすると\n",
    "\n",
    "$$f(a)\\le f(\\xi)+\\phi(\\xi)(a^2-\\xi^2)\\tag{15}$$\n",
    "\n",
    "が成り立つ。\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\ln(1+e^a) &= \\ln(e^{a/2}+e^{-a/2})+\\ln(e^{a/2}) \\\\\n",
    "&= f(a) + \\frac{a}{2}\n",
    "\\end{split} \\tag{16}\n",
    "$$\n",
    "\n",
    "であるから、 $(5)$, $(15)$ より、\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E(y_t,a_t) &=-y_ta_t+\\ln(1+e^{a_t}) \\\\\n",
    "&= -y_ta_t+f(a_t)+\\frac{a_t}{2} \\\\\n",
    "&\\le -y_ta_t+\\frac{a_t}{2}+f(\\xi_t)+\\phi(\\xi_t)(a_t^2-\\xi_t^2)\n",
    "\\end{split} \\tag{17}\n",
    "$$\n",
    "\n",
    "目的は、損失関数 $l$ として $E(y_t,a_t)$ を用いることであるから\n",
    "\n",
    "$$l(a_t,y_t)=-a_ty_t+\\frac{a_t}{2}+f(\\xi_t)+\\phi(\\xi_t)(a_t^2-\\xi_t^2)\\tag{18}$$\n",
    "\n",
    "となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf205b",
   "metadata": {},
   "source": [
    "## オフライン予測による損失\n",
    "\n",
    "$(8)$ より\n",
    "\n",
    "$$\n",
    "R =\\sum_{t=1}^T l(y_t,a_t)-\\min_{\\hat a_1,\\ldots,\\hat a_T}\\left\\{\\sum_{t=1}^Tl(y_t,\\hat a_t)+\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2\\right\\}\n",
    "$$\n",
    "\n",
    "であった。この第２項に注目したとき、オフライン予測を行った際の損失 $L$ は\n",
    "\n",
    "$$\n",
    "L =\\sum_{t=1}^Tl(y_t,\\hat a_t)+\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2 \\tag {19}\n",
    "$$\n",
    "\n",
    "となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac52bd",
   "metadata": {},
   "source": [
    "$L$ を最小にする $\\mathbf{\\hat A}=\\begin{pmatrix}\\hat{a_1} & \\cdots & \\hat{a_T}\\end{pmatrix}^T$ は\n",
    "\n",
    "$$\\mathbf{\\hat A}=\\frac{1}{2}(\\mathbf\\Phi+\\lambda\\mathbf K)^{-1}\\left(\\mathbf Y-\\frac{1}{2}\\mathbf 1\\right)\\tag{20}$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\displaystyle \\mathbf\\Phi &=\\mathrm {diag}(\\phi(\\xi_t),\\ldots,\\phi(\\xi_T)) \\tag{21}\\\\\n",
    "\\displaystyle \\mathbf K &= \\begin{pmatrix}2 & -1 \\\\ -1 & 2 & -1 \\\\ & & \\ddots \\\\ & & -1 & 2 & -1 \\\\ & & & -1 & 2\\end{pmatrix} \\tag{22} \\\\\n",
    "\\displaystyle \\mathbf Y &= \\begin{pmatrix}y_1 & \\cdots & y_T\\end{pmatrix}^T \\tag{23}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "であり、その時の損失 $L^*$ は\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\displaystyle L^* &=-\\frac{1}{4}\\left(\\mathbf Y-\\frac{1}{2}\\mathbf 1\\right)^T\\left(\\mathbf \\Phi+\\lambda \\mathbf K\\right)^{-1}\\left(\\mathbf Y-\\frac{1}{2}\\mathbf 1\\right)+\\mathbf F^T\\mathbf 1 - \\Xi^T\\mathbf\\Phi\\Xi \\\\\n",
    "\\displaystyle \\mathbf F &= \\begin{pmatrix}f(\\xi_1) & \\cdots & f(\\xi_T)\\end{pmatrix}^T \\\\\n",
    "\\displaystyle \\mathbf \\Xi &= \\begin{pmatrix}\\xi_1 & \\cdots & \\xi_T\\end{pmatrix}^T\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d4aca",
   "metadata": {},
   "source": [
    "## ある時点での minimax 損失\n",
    "\n",
    "ある時点における損失 $V$ を\n",
    "\n",
    "$$V(a,y)=-ay+\\frac{a}{2}+\\phi(\\xi)a^2+\\alpha\\left(x-\\frac{1}{2}\\right)\\tag{24}$$\n",
    "\n",
    "とする。$\\alpha$ は任意の定数である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903c10a",
   "metadata": {},
   "source": [
    "ここで、ある時点における minimax 損失 $V^*$ を\n",
    "\n",
    "$$V^*=\\min_a\\max_yV(a,y)\\tag{25}$$\n",
    "\n",
    "とする。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71fd04e",
   "metadata": {},
   "source": [
    "$$\\forall y^0\\in\\{0,1\\},\\ V^*=V(\\alpha,y^0)=\\phi(\\xi)\\alpha^2\\tag{26}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9caabe",
   "metadata": {},
   "source": [
    "## オンライン予測式の導出\n",
    "\n",
    "$(8)$ , $(18)$ より\n",
    "\n",
    "$$R=\\sum_{t=1}^T l(y_t,a_t)-\\min_{\\hat a_1,\\ldots,\\hat a_T}\\left\\{\\sum_{t=1}^Tl(y_t,\\hat a_t)+\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2\\right\\}$$\n",
    "\n",
    "$$l(a_t,y_t)=-a_ty_t+\\frac{a_t}{2}+f(\\xi_t)+\\phi(\\xi_t)(a_t^2-\\xi_t^2)$$\n",
    "\n",
    "であり、　$(9)$ より、minimax リグレット $R^*$ は\n",
    "\n",
    "$$R^*=\\min_{a_1}\\max_{y_1}\\cdots\\min_{a_T}\\max_{y_T}R$$\n",
    "\n",
    "であった。$R$ の第二項は $-L^*$ であらわせるため、"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6868f69",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf Y_t &=\\begin{pmatrix}y_1 & \\cdots & y_t\\end{pmatrix}\\tag{28} \\\\\n",
    "V(\\mathbf Y_T) &= -L^* \\tag{29}\\\\\n",
    "V(\\mathbf Y_{t-1}) &= \\min_{a_t}\\max_{y_t}\\left\\{-a_ty_t+\\frac{y_t}{2}-f(\\xi_t)+\\phi(\\xi_t)(a_t^2-\\xi_t^2)\\right\\}+V(\\mathbf Y_t) \\tag{30}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "このように定義すると、$R^*$ は\n",
    "\n",
    "$$R^*=V(\\mathbf Y_0)$$\n",
    "\n",
    "となる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb5961",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
