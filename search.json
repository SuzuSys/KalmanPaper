[
  {
    "objectID": "common.html",
    "href": "common.html",
    "title": "共通概念・表記",
    "section": "",
    "text": "\\[\n\\begin{split}\np(y_t=1\\mid\\mathbf w_t) &= \\sigma(\\mathbf w_t^T\\mathbf x_t) \\\\\np(\\mathbf w_{t+1}\\mid\\mathbf w_t) &= \\mathcal N(\\mathbf w_{t+1}\\mid\\mathbf w_t,\\mathbf \\Gamma)\n\\end{split}\n\\]",
    "crumbs": [
      "共通概念・表記"
    ]
  },
  {
    "objectID": "common.html#環境",
    "href": "common.html#環境",
    "title": "共通概念・表記",
    "section": "",
    "text": "\\[\n\\begin{split}\np(y_t=1\\mid\\mathbf w_t) &= \\sigma(\\mathbf w_t^T\\mathbf x_t) \\\\\np(\\mathbf w_{t+1}\\mid\\mathbf w_t) &= \\mathcal N(\\mathbf w_{t+1}\\mid\\mathbf w_t,\\mathbf \\Gamma)\n\\end{split}\n\\]",
    "crumbs": [
      "共通概念・表記"
    ]
  },
  {
    "objectID": "common.html#記法",
    "href": "common.html#記法",
    "title": "共通概念・表記",
    "section": "記法",
    "text": "記法\n\\[\n\\begin{split}\np(\\mathbf w_t\\mid\\mathbf Y_t) &= \\mathcal N(\\mathbf w_t\\mid\\hat{\\mathbf w}_{t/t},\\mathbf P_{t/t}) \\\\\np(\\mathbf w_{t+1}\\mid\\mathbf Y_t) &= \\mathcal N(\\mathbf w_{t+1}\\mid\\hat{\\mathbf w}_{t+1/t},\\mathbf P_{t+1/t})\n\\end{split}\n\\]\n\n\\(\\hat{\\mathbf w}_{t/t}\\) : 濾波推定値\n\\(\\hat{\\mathbf w}_{t+1/t}\\) : 一段予測推定値\n\\(\\mathbf P_{t/t}\\), \\(\\mathbf P_{t+1/t}\\) : 推定誤差共分散行列",
    "crumbs": [
      "共通概念・表記"
    ]
  },
  {
    "objectID": "common.html#logistic-sigmoid-func.-と-softmax-func.",
    "href": "common.html#logistic-sigmoid-func.-と-softmax-func.",
    "title": "共通概念・表記",
    "section": "Logistic sigmoid func. と Softmax func.",
    "text": "Logistic sigmoid func. と Softmax func.\nクラスの条件付き確率密度がガウス分布であると仮定する。このとき、共分散行列が各クラスに共有されるとする。\n\\[p(\\mathbf x_t\\mid y_t=\\mathcal C_1)=\\mathcal N(\\mathbf x_t\\mid\\boldsymbol \\mu_{\\mathcal C_1},\\boldsymbol\\Sigma)\\]\nこのとき、決定境界は \\(\\mathbf x_t\\) に対して線形となる。\n共分散行列が各クラスに共有されないとすると、決定境界は２次判別関数となる \\(\\mathbf x_t\\) の２次関数を得る。",
    "crumbs": [
      "共通概念・表記"
    ]
  },
  {
    "objectID": "common.html#状態推定問題",
    "href": "common.html#状態推定問題",
    "title": "共通概念・表記",
    "section": "状態推定問題",
    "text": "状態推定問題\n観測データ \\(\\mathbf Y_t\\) に基づいて、ベイズリスク\n\\[\nJ=\\mathbb E[\\|\\mathbf w_{t+m}-\\hat{\\mathbf w}_{t+m/t}\\|^2],\\ m=0,1\n\\]\nを最小にする最適推定値 \\(\\hat{\\mathbf w}_{t+m/t}\\) は\n\\[\n\\hat{\\mathbf w}_{t+m/t}=\\mathbb E_{\\mathbf w_{t+m}\\mid\\mathbf Y_t}[\\mathbf w_{t+m}]\n\\]\nで与えられる。次式で説明される。\n\\[\\frac{\\partial}{\\partial \\hat{\\mathbf w}_{t+m/t}}J=\\int 2(\\mathbf w_{t+m}-\\hat{\\mathbf w}_{t+m/t})p(\\mathbf w\\mid y)d\\mathbf w=0\\]",
    "crumbs": [
      "共通概念・表記"
    ]
  },
  {
    "objectID": "common.html#logistic-sigmoid-関数",
    "href": "common.html#logistic-sigmoid-関数",
    "title": "共通概念・表記",
    "section": "Logistic Sigmoid 関数",
    "text": "Logistic Sigmoid 関数\n\\[\\sigma(\\mathbf w^T\\mathbf x)=\\frac{1}{1+e^{-\\mathbf w^T\\mathbf x}}\\]\n\\[\\frac{\\partial}{\\partial \\mathbf w}\\sigma(\\mathbf w^T\\mathbf x)=\\sigma(\\mathbf w^T\\mathbf x)\\{1-\\sigma(\\mathbf w^T\\mathbf x)\\}\\mathbf x\\]\n\\[\\frac{\\partial}{\\partial \\mathbf w}\\ln\\sigma(\\mathbf w^T\\mathbf x)=[1-\\sigma(\\mathbf w^T\\mathbf x)]\\mathbf x\\]\n\\[\\frac{\\partial^2}{\\partial \\mathbf w^2}=-\\sigma(\\mathbf w^T\\mathbf x)(1-\\sigma(\\mathbf w^T\\mathbf x))\\mathbf x\\mathbf x^T\\]\n\\[\\frac{\\partial}{\\partial \\mathbf w}\\ln\\{1-\\sigma(\\mathbf w^T\\mathbf x)\\}=-\\sigma(\\mathbf w^T\\mathbf x)\\mathbf x\\]\n\\[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln\\{1-\\sigma(\\mathbf w^T\\mathbf x)\\}=-\\sigma(\\mathbf w^T\\mathbf x)(1-\\sigma(\\mathbf w^T\\mathbf x))\\mathbf x\\mathbf x^T\\]",
    "crumbs": [
      "共通概念・表記"
    ]
  },
  {
    "objectID": "common.html#maximising-evidence-of-class-labels",
    "href": "common.html#maximising-evidence-of-class-labels",
    "title": "共通概念・表記",
    "section": "Maximising Evidence of Class Labels",
    "text": "Maximising Evidence of Class Labels\n\\[\\text{Ev}(y_t)=p(y_t)=\\int p(y_t\\mid\\mathbf w_t)p(\\mathbf w_t)d\\mathbf w_t\\]",
    "crumbs": [
      "共通概念・表記"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis02.html",
    "href": "AnalysisStorage/analysis02.html",
    "title": "分析02",
    "section": "",
    "text": "Parameter (G:jaxtyping.Float[Array,'{N}{N}'],\n            S:jaxtyping.Float[Array,'{N}{N}'],\n            w0:jaxtyping.Float[Array,'{N}'],\n            P0:jaxtyping.Float[Array,'{N}{N}'],\n            epsilon:jaxtyping.Float[Array,'']=Array(1.5258789e-05,\n            dtype=float32, weak_type=True))\n\n\\(\\!\\) 00_Gen/gen_xy_logistic によって生成するときのパラメータ。\n\n\n\n\\(\\!\\)\nType\nDefault\nDetails\n\n\n\n\nG\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\boldsymbol\\Gamma\\)\n\n\nS\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\boldsymbol\\Sigma\\)\n\n\nw0\nFloat[Array, ‘{N}’]\n\\(\\!\\)\n\\(\\mathbf w_{-1}\\)\n\n\nP0\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\mathbf P_{-1}\\)\n\n\nepsilon\nFloat[Array, ’’]\n1.52587890625e-05\n\\(\\epsilon\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n Param (N:int, p:int, q:int, r:int)\n\n\\(\\!\\) 可変パラメータ。各パラメータは次のように定義される。\n\n\\(N\\)\n\\(T=1000\\)\n\\(\\boldsymbol\\Gamma=2^p\\mathbf I\\)\n\\(\\boldsymbol\\Sigma=2^q\\mathbf I\\)\n\\(\\mathbf w_{-1}=(r/2)(1,\\ldots,1)^T/\\sqrt{N}\\)\n\\(\\mathbf P_{-1}=\\boldsymbol\\Gamma\\)\n\\(\\epsilon=2^{-16}\\)\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nN\nint\n\\(N\\)\n\n\np\nint\n\\(p\\)\n\n\nq\nint\n\\(q\\)\n\n\nr\nint\n\\(r\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n restore_param (param:__main__.Param)\n\n\\(\\!\\) Param から Parameter に変換する。 \\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nReturns\nTuple\n\\(N\\), \\(T\\), Parameter\n\n\n\n\n\n\n\n\n\n\n\n\n save_data (param:__main__.Param, name:str, data:dict)\n\n\\(\\!\\) 02_Data.h5 にデータを格納する\n.\n├───param1\n│   ├───Gen\n│   │       W (seed, T, N)\n│   │       X (seed, T, N)\n│   │       Y (seed, T)\n│   │\n│   ├───Model1\n│   │       W (seed, T, N)\n│   │       P (seed, T, N, N)\n│   │\n│   ├───Model2\n│\n├───param2\n\\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nname\nstr\nModel name (Gen, EKF, etc.)\n\n\ndata\ndict\ndataset_name: jnp.array\n\n\nReturns\nNone\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n\n\n\n WXY (W:jaxtyping.Float[Array,'TN'], X:jaxtyping.Float[Array,'TN'],\n      Y:jaxtyping.Float[Array,'T'])\n\n\\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nW\nFloat[Array, ‘T N’]\n\\(\\{\\mathbf w_t\\}_{t=0,\\ldots,T-1}\\)\n\n\nX\nFloat[Array, ‘T N’]\n\\(\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1}\\)\n\n\nY\nFloat[Array, ‘T’]\n\\(\\{y_t\\}_{t=0,\\ldots,T-1}\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n generate (key:Union[jaxtyping.Key[Array,''],jaxtyping.UInt32[Array,'2']],\n           N:int, T:int, p:__main__.Parameter)\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nkey\nUnion\nPRNGKeyArray\n\n\nN\nint\n\\(N\\)\n\n\nT\nint\n\\(T\\)\n\n\np\nParameter\nParameter\n\n\nReturns\nWXY\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n\n\n\n generate_main (param:__main__.Param, seed:int)\n\n\\(\\!\\) データを生成し、02_Data.h5 に保存する。 \\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nseed\nint\nseed値\n\n\n\n\n\n\n\n\n\n\n\n\n predict_main (param:__main__.Param, model_name:str, func:Callable[[int,in\n               t,jaxtyping.Float[Array,'TN'],jaxtyping.Float[Array,'T'],__\n               main__.Parameter],NamedTuple])\n\n\\(\\!\\) 02_Data.h5 のデータ \\(X,Y\\) に対して func で \\(W\\) 等を推論し、保存する。 \\(\\!\\)\n\n\n\n\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nmodel_name\nstr\nEKF, etc.\n\n\nfunc\nCallable\n\\(N,T,\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1},\\{y_t\\}_{t=0,\\ldots,T-1},\\mathrm{p}\\to\\{\\hat{\\mathbf w_t}\\}_{t=0,\\ldots,T-1},\\{\\mathbf P_{t/t}\\}_{t=0,\\ldots,T-1},\\ldots\\)",
    "crumbs": [
      "分析データ",
      "分析02"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis02.html#関数定義",
    "href": "AnalysisStorage/analysis02.html#関数定義",
    "title": "分析02",
    "section": "",
    "text": "Parameter (G:jaxtyping.Float[Array,'{N}{N}'],\n            S:jaxtyping.Float[Array,'{N}{N}'],\n            w0:jaxtyping.Float[Array,'{N}'],\n            P0:jaxtyping.Float[Array,'{N}{N}'],\n            epsilon:jaxtyping.Float[Array,'']=Array(1.5258789e-05,\n            dtype=float32, weak_type=True))\n\n\\(\\!\\) 00_Gen/gen_xy_logistic によって生成するときのパラメータ。\n\n\n\n\\(\\!\\)\nType\nDefault\nDetails\n\n\n\n\nG\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\boldsymbol\\Gamma\\)\n\n\nS\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\boldsymbol\\Sigma\\)\n\n\nw0\nFloat[Array, ‘{N}’]\n\\(\\!\\)\n\\(\\mathbf w_{-1}\\)\n\n\nP0\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\mathbf P_{-1}\\)\n\n\nepsilon\nFloat[Array, ’’]\n1.52587890625e-05\n\\(\\epsilon\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n Param (N:int, p:int, q:int, r:int)\n\n\\(\\!\\) 可変パラメータ。各パラメータは次のように定義される。\n\n\\(N\\)\n\\(T=1000\\)\n\\(\\boldsymbol\\Gamma=2^p\\mathbf I\\)\n\\(\\boldsymbol\\Sigma=2^q\\mathbf I\\)\n\\(\\mathbf w_{-1}=(r/2)(1,\\ldots,1)^T/\\sqrt{N}\\)\n\\(\\mathbf P_{-1}=\\boldsymbol\\Gamma\\)\n\\(\\epsilon=2^{-16}\\)\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nN\nint\n\\(N\\)\n\n\np\nint\n\\(p\\)\n\n\nq\nint\n\\(q\\)\n\n\nr\nint\n\\(r\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n restore_param (param:__main__.Param)\n\n\\(\\!\\) Param から Parameter に変換する。 \\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nReturns\nTuple\n\\(N\\), \\(T\\), Parameter\n\n\n\n\n\n\n\n\n\n\n\n\n save_data (param:__main__.Param, name:str, data:dict)\n\n\\(\\!\\) 02_Data.h5 にデータを格納する\n.\n├───param1\n│   ├───Gen\n│   │       W (seed, T, N)\n│   │       X (seed, T, N)\n│   │       Y (seed, T)\n│   │\n│   ├───Model1\n│   │       W (seed, T, N)\n│   │       P (seed, T, N, N)\n│   │\n│   ├───Model2\n│\n├───param2\n\\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nname\nstr\nModel name (Gen, EKF, etc.)\n\n\ndata\ndict\ndataset_name: jnp.array\n\n\nReturns\nNone\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n\n\n\n WXY (W:jaxtyping.Float[Array,'TN'], X:jaxtyping.Float[Array,'TN'],\n      Y:jaxtyping.Float[Array,'T'])\n\n\\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nW\nFloat[Array, ‘T N’]\n\\(\\{\\mathbf w_t\\}_{t=0,\\ldots,T-1}\\)\n\n\nX\nFloat[Array, ‘T N’]\n\\(\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1}\\)\n\n\nY\nFloat[Array, ‘T’]\n\\(\\{y_t\\}_{t=0,\\ldots,T-1}\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n generate (key:Union[jaxtyping.Key[Array,''],jaxtyping.UInt32[Array,'2']],\n           N:int, T:int, p:__main__.Parameter)\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nkey\nUnion\nPRNGKeyArray\n\n\nN\nint\n\\(N\\)\n\n\nT\nint\n\\(T\\)\n\n\np\nParameter\nParameter\n\n\nReturns\nWXY\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n\n\n\n generate_main (param:__main__.Param, seed:int)\n\n\\(\\!\\) データを生成し、02_Data.h5 に保存する。 \\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nseed\nint\nseed値\n\n\n\n\n\n\n\n\n\n\n\n\n predict_main (param:__main__.Param, model_name:str, func:Callable[[int,in\n               t,jaxtyping.Float[Array,'TN'],jaxtyping.Float[Array,'T'],__\n               main__.Parameter],NamedTuple])\n\n\\(\\!\\) 02_Data.h5 のデータ \\(X,Y\\) に対して func で \\(W\\) 等を推論し、保存する。 \\(\\!\\)\n\n\n\n\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nmodel_name\nstr\nEKF, etc.\n\n\nfunc\nCallable\n\\(N,T,\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1},\\{y_t\\}_{t=0,\\ldots,T-1},\\mathrm{p}\\to\\{\\hat{\\mathbf w_t}\\}_{t=0,\\ldots,T-1},\\{\\mathbf P_{t/t}\\}_{t=0,\\ldots,T-1},\\ldots\\)",
    "crumbs": [
      "分析データ",
      "分析02"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis02.html#関数のテスト",
    "href": "AnalysisStorage/analysis02.html#関数のテスト",
    "title": "分析02",
    "section": "関数のテスト",
    "text": "関数のテスト\n\nLOCK = True",
    "crumbs": [
      "分析データ",
      "分析02"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis02.html#データ生成",
    "href": "AnalysisStorage/analysis02.html#データ生成",
    "title": "分析02",
    "section": "データ生成",
    "text": "データ生成",
    "crumbs": [
      "分析データ",
      "分析02"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis02.html#分析",
    "href": "AnalysisStorage/analysis02.html#分析",
    "title": "分析02",
    "section": "分析",
    "text": "分析\n\n推論結果の様子\n\n\n\n\n\n\n\n\n\n\n\n結果\n\n\\(N\\)\n\\(T=1000\\)\n\\(\\boldsymbol\\Gamma=2^p\\mathbf I\\)\n\\(\\boldsymbol\\Sigma=2^q\\mathbf I\\)\n\\(\\mathbf w_{-1}=(r/2)(1,\\ldots,1)^T/\\sqrt{N}\\)\n\\(\\mathbf P_{-1}=\\boldsymbol\\Gamma\\)\n\\(\\epsilon=2^{-16}\\)\n\n\n\nListening on: localhost:8080\n\n\n\n        \n        \n\n\n\n\n誤差\n\\[E(\\{w_{0,t}\\}_{t=0,\\ldots,T})=\\{\\hat{w}_{0,t} - w_{0,t}\\}_{t=0,\\ldots,T}\\]\n\n\\(N\\)\n\\(T=1000\\)\n\\(\\boldsymbol\\Gamma=2^p\\mathbf I\\)\n\\(\\boldsymbol\\Sigma=2^q\\mathbf I\\)\n\\(\\mathbf w_{-1}=(r/2)(1,\\ldots,1)^T/\\sqrt{N}\\)\n\\(\\mathbf P_{-1}=\\boldsymbol\\Gamma\\)\n\\(\\epsilon=2^{-16}\\)\n\n\n\nListening on: localhost:8081\n\n\n\n        \n        \n\n\n\n\nListening on: localhost:8082\n\n\n\n        \n        \n\n\n\n\n\n\n\n\n\n\n\nalgorithm\nfrob_error\nrelative_error\n\n\np\n\n\n\n\n\n\n\n-4\nEKF\n2.979151\n33.705244\n\n\n-4\nVApre\n1.796990\n20.330618\n\n\n-4\nVAEM\n1.792639\n20.281393\n\n\n-4\nwEXP_PVA\n1.763215\n19.948498\n\n\n-6\nEKF\n0.973215\n44.042689\n\n\n-6\nVApre\n0.778222\n35.218304\n\n\n-6\nVAEM\n0.777547\n35.187783\n\n\n-6\nwEXP_PVA\n0.774319\n35.041681\n\n\n-8\nEKF\n0.380470\n68.872392\n\n\n-8\nVApre\n0.352851\n63.872866\n\n\n-8\nVAEM\n0.352767\n63.857691\n\n\n-8\nwEXP_PVA\n0.352492\n63.807886\n\n\n-10\nEKF\n0.165993\n120.191809\n\n\n-10\nVApre\n0.162936\n117.978518\n\n\n-10\nVAEM\n0.162928\n117.972616\n\n\n-10\nwEXP_PVA\n0.162913\n117.961913\n\n\n-12\nEKF\n0.072970\n211.344333\n\n\n-12\nVApre\n0.072780\n210.792704\n\n\n-12\nVAEM\n0.072779\n210.791215\n\n\n-12\nwEXP_PVA\n0.072779\n210.790546",
    "crumbs": [
      "分析データ",
      "分析02"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis01.html",
    "href": "AnalysisStorage/analysis01.html",
    "title": "分析01",
    "section": "",
    "text": "https://archive.ics.uci.edu/dataset/312/dow+jones+index\nThis dataset contains weekly data for the Dow Jones Industrial Index. It has been used in computational investing research.\n\n\n\n\n\n\n\n項目名\n説明\n\n\n\n\nquarter\n年間の四半期（1 = 1〜3月、2 = 4〜6月）\n\n\nstock\n株式のシンボル（ティッカーコード）\n\n\ndate\n週の最終営業日（通常は金曜日）\n\n\nopen\n週の始めの株価（始値）\n\n\nhigh\n週の最高株価\n\n\nlow\n週の最安株価\n\n\nclose\n週の終わりの株価（終値）\n\n\nvolume\nその週に取引された株式の出来高（取引株数）\n\n\npercent_change_price\n週を通しての株価変動率（％）\n\n\npercent_change_volume_over_last_week\n前週と比較した出来高の変化率（％）\n\n\nprevious_weeks_volume\n前週の出来高（取引株数）\n\n\nnext_weeks_open\n翌週の始値\n\n\nnext_weeks_close\n翌週の終値\n\n\npercent_change_next_weeks_price\n翌週の株価変動率（％）\n\n\ndays_to_next_dividend\n次回配当までの日数\n\n\npercent_return_next_dividend\n次回配当による利回り（％）\n\n\n\n\ndf = pd.read_csv(\"01_Data/dow_jones_index/dow_jones_index.data\")\ndf\n\n\n\n\n\n\n\n\nquarter\nstock\ndate\nopen\nhigh\nlow\nclose\nvolume\npercent_change_price\npercent_change_volume_over_last_wk\nprevious_weeks_volume\nnext_weeks_open\nnext_weeks_close\npercent_change_next_weeks_price\ndays_to_next_dividend\npercent_return_next_dividend\n\n\n\n\n0\n1\nAA\n1/7/2011\n$15.82\n$16.72\n$15.78\n$16.42\n239655616\n3.79267\nNaN\nNaN\n$16.71\n$15.97\n-4.428490\n26\n0.182704\n\n\n1\n1\nAA\n1/14/2011\n$16.71\n$16.71\n$15.64\n$15.97\n242963398\n-4.42849\n1.380223\n239655616.0\n$16.19\n$15.79\n-2.470660\n19\n0.187852\n\n\n2\n1\nAA\n1/21/2011\n$16.19\n$16.38\n$15.60\n$15.79\n138428495\n-2.47066\n-43.024959\n242963398.0\n$15.87\n$16.13\n1.638310\n12\n0.189994\n\n\n3\n1\nAA\n1/28/2011\n$15.87\n$16.63\n$15.82\n$16.13\n151379173\n1.63831\n9.355500\n138428495.0\n$16.18\n$17.14\n5.933250\n5\n0.185989\n\n\n4\n1\nAA\n2/4/2011\n$16.18\n$17.39\n$16.18\n$17.14\n154387761\n5.93325\n1.987452\n151379173.0\n$17.33\n$17.37\n0.230814\n97\n0.175029\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n745\n2\nXOM\n5/27/2011\n$80.22\n$82.63\n$80.07\n$82.63\n68230855\n3.00424\n-21.355713\n86758820.0\n$83.28\n$81.18\n-2.521610\n75\n0.568801\n\n\n746\n2\nXOM\n6/3/2011\n$83.28\n$83.75\n$80.18\n$81.18\n78616295\n-2.52161\n15.221032\n68230855.0\n$80.93\n$79.78\n-1.420980\n68\n0.578960\n\n\n747\n2\nXOM\n6/10/2011\n$80.93\n$81.87\n$79.72\n$79.78\n92380844\n-1.42098\n17.508519\n78616295.0\n$80.00\n$79.02\n-1.225000\n61\n0.589120\n\n\n748\n2\nXOM\n6/17/2011\n$80.00\n$80.82\n$78.33\n$79.02\n100521400\n-1.22500\n8.811952\n92380844.0\n$78.65\n$76.78\n-2.377620\n54\n0.594786\n\n\n749\n2\nXOM\n6/24/2011\n$78.65\n$81.12\n$76.78\n$76.78\n118679791\n-2.37762\n18.064204\n100521400.0\n$76.88\n$82.01\n6.672740\n47\n0.612139\n\n\n\n\n750 rows × 16 columns\n\n\n\n\ndf1 = df.set_index(\"date\")\ndf1\n\n\n\n\n\n\n\n\nquarter\nstock\nopen\nhigh\nlow\nclose\nvolume\npercent_change_price\npercent_change_volume_over_last_wk\nprevious_weeks_volume\nnext_weeks_open\nnext_weeks_close\npercent_change_next_weeks_price\ndays_to_next_dividend\npercent_return_next_dividend\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1/7/2011\n1\nAA\n$15.82\n$16.72\n$15.78\n$16.42\n239655616\n3.79267\nNaN\nNaN\n$16.71\n$15.97\n-4.428490\n26\n0.182704\n\n\n1/14/2011\n1\nAA\n$16.71\n$16.71\n$15.64\n$15.97\n242963398\n-4.42849\n1.380223\n239655616.0\n$16.19\n$15.79\n-2.470660\n19\n0.187852\n\n\n1/21/2011\n1\nAA\n$16.19\n$16.38\n$15.60\n$15.79\n138428495\n-2.47066\n-43.024959\n242963398.0\n$15.87\n$16.13\n1.638310\n12\n0.189994\n\n\n1/28/2011\n1\nAA\n$15.87\n$16.63\n$15.82\n$16.13\n151379173\n1.63831\n9.355500\n138428495.0\n$16.18\n$17.14\n5.933250\n5\n0.185989\n\n\n2/4/2011\n1\nAA\n$16.18\n$17.39\n$16.18\n$17.14\n154387761\n5.93325\n1.987452\n151379173.0\n$17.33\n$17.37\n0.230814\n97\n0.175029\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5/27/2011\n2\nXOM\n$80.22\n$82.63\n$80.07\n$82.63\n68230855\n3.00424\n-21.355713\n86758820.0\n$83.28\n$81.18\n-2.521610\n75\n0.568801\n\n\n6/3/2011\n2\nXOM\n$83.28\n$83.75\n$80.18\n$81.18\n78616295\n-2.52161\n15.221032\n68230855.0\n$80.93\n$79.78\n-1.420980\n68\n0.578960\n\n\n6/10/2011\n2\nXOM\n$80.93\n$81.87\n$79.72\n$79.78\n92380844\n-1.42098\n17.508519\n78616295.0\n$80.00\n$79.02\n-1.225000\n61\n0.589120\n\n\n6/17/2011\n2\nXOM\n$80.00\n$80.82\n$78.33\n$79.02\n100521400\n-1.22500\n8.811952\n92380844.0\n$78.65\n$76.78\n-2.377620\n54\n0.594786\n\n\n6/24/2011\n2\nXOM\n$78.65\n$81.12\n$76.78\n$76.78\n118679791\n-2.37762\n18.064204\n100521400.0\n$76.88\n$82.01\n6.672740\n47\n0.612139\n\n\n\n\n750 rows × 15 columns\n\n\n\n\ndf1.plot()\n\n\n\n\n\n\n\n\n\nx quarter\n\n\ndol_cols = [\n  \"open\", \n  \"high\", \n  \"low\", \n  \"close\", \n  \"next_weeks_open\", \n  \"next_weeks_close\"\n  ]\n\ndf1[dol_cols] = (\n    df1[dol_cols]\n    .replace('[\\$,]', '', regex=True)  # $, , を削除\n    .astype(float)                     # float型に変換\n)\n\n\ndf1\n\n\n\n\n\n\n\n\nquarter\nstock\nopen\nhigh\nlow\nclose\nvolume\npercent_change_price\npercent_change_volume_over_last_wk\nprevious_weeks_volume\nnext_weeks_open\nnext_weeks_close\npercent_change_next_weeks_price\ndays_to_next_dividend\npercent_return_next_dividend\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1/7/2011\n1\nAA\n15.82\n16.72\n15.78\n16.42\n239655616\n3.79267\nNaN\nNaN\n16.71\n15.97\n-4.428490\n26\n0.182704\n\n\n1/14/2011\n1\nAA\n16.71\n16.71\n15.64\n15.97\n242963398\n-4.42849\n1.380223\n239655616.0\n16.19\n15.79\n-2.470660\n19\n0.187852\n\n\n1/21/2011\n1\nAA\n16.19\n16.38\n15.60\n15.79\n138428495\n-2.47066\n-43.024959\n242963398.0\n15.87\n16.13\n1.638310\n12\n0.189994\n\n\n1/28/2011\n1\nAA\n15.87\n16.63\n15.82\n16.13\n151379173\n1.63831\n9.355500\n138428495.0\n16.18\n17.14\n5.933250\n5\n0.185989\n\n\n2/4/2011\n1\nAA\n16.18\n17.39\n16.18\n17.14\n154387761\n5.93325\n1.987452\n151379173.0\n17.33\n17.37\n0.230814\n97\n0.175029\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5/27/2011\n2\nXOM\n80.22\n82.63\n80.07\n82.63\n68230855\n3.00424\n-21.355713\n86758820.0\n83.28\n81.18\n-2.521610\n75\n0.568801\n\n\n6/3/2011\n2\nXOM\n83.28\n83.75\n80.18\n81.18\n78616295\n-2.52161\n15.221032\n68230855.0\n80.93\n79.78\n-1.420980\n68\n0.578960\n\n\n6/10/2011\n2\nXOM\n80.93\n81.87\n79.72\n79.78\n92380844\n-1.42098\n17.508519\n78616295.0\n80.00\n79.02\n-1.225000\n61\n0.589120\n\n\n6/17/2011\n2\nXOM\n80.00\n80.82\n78.33\n79.02\n100521400\n-1.22500\n8.811952\n92380844.0\n78.65\n76.78\n-2.377620\n54\n0.594786\n\n\n6/24/2011\n2\nXOM\n78.65\n81.12\n76.78\n76.78\n118679791\n-2.37762\n18.064204\n100521400.0\n76.88\n82.01\n6.672740\n47\n0.612139\n\n\n\n\n750 rows × 15 columns\n\n\n\n\ndf1.groupby(\"stock\").count()\n\n\n\n\n\n\n\n\nquarter\nopen\nhigh\nlow\nclose\nvolume\npercent_change_price\npercent_change_volume_over_last_wk\nprevious_weeks_volume\nnext_weeks_open\nnext_weeks_close\npercent_change_next_weeks_price\ndays_to_next_dividend\npercent_return_next_dividend\n\n\nstock\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAA\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nAXP\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nBA\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nBAC\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nCAT\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nCSCO\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nCVX\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nDD\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nDIS\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nGE\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nHD\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nHPQ\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nIBM\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nINTC\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nJNJ\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nJPM\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nKO\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nKRFT\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nMCD\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nMMM\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nMRK\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nMSFT\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nPFE\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nPG\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nT\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nTRV\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nUTX\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nVZ\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nWMT\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nXOM\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\n\n\n\n\n\n\nnumcols = [\"open\", \"high\", \"low\", \"close\", \"volume\", \"percent_change_price\", \"percent_change_volume_over_last_wk\", \"previous_weeks_volume\", \"next_weeks_open\", \"next_weeks_close\", \"percent_change_next_weeks_price\", \"days_to_next_dividend\", \"percent_return_next_dividend\"]\ndfAA = df1[df1[\"stock\"] == \"AA\"][numcols]\ndfAA\n\n\n\n\n\n\n\n\nopen\nhigh\nlow\nclose\nvolume\npercent_change_price\npercent_change_volume_over_last_wk\nprevious_weeks_volume\nnext_weeks_open\nnext_weeks_close\npercent_change_next_weeks_price\ndays_to_next_dividend\npercent_return_next_dividend\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1/7/2011\n15.82\n16.72\n15.78\n16.42\n239655616\n3.792670\nNaN\nNaN\n16.71\n15.97\n-4.428490\n26\n0.182704\n\n\n1/14/2011\n16.71\n16.71\n15.64\n15.97\n242963398\n-4.428490\n1.380223\n239655616.0\n16.19\n15.79\n-2.470660\n19\n0.187852\n\n\n1/21/2011\n16.19\n16.38\n15.60\n15.79\n138428495\n-2.470660\n-43.024959\n242963398.0\n15.87\n16.13\n1.638310\n12\n0.189994\n\n\n1/28/2011\n15.87\n16.63\n15.82\n16.13\n151379173\n1.638310\n9.355500\n138428495.0\n16.18\n17.14\n5.933250\n5\n0.185989\n\n\n2/4/2011\n16.18\n17.39\n16.18\n17.14\n154387761\n5.933250\n1.987452\n151379173.0\n17.33\n17.37\n0.230814\n97\n0.175029\n\n\n2/11/2011\n17.33\n17.48\n16.97\n17.37\n114691279\n0.230814\n-25.712195\n154387761.0\n17.39\n17.28\n-0.632547\n90\n0.172712\n\n\n2/18/2011\n17.39\n17.68\n17.28\n17.28\n80023895\n-0.632547\n-30.226696\n114691279.0\n16.98\n16.68\n-1.766780\n83\n0.173611\n\n\n2/25/2011\n16.98\n17.15\n15.96\n16.68\n132981863\n-1.766780\n66.177694\n80023895.0\n16.81\n16.58\n-1.368230\n76\n0.179856\n\n\n3/4/2011\n16.81\n16.94\n16.13\n16.58\n109493077\n-1.368230\n-17.663150\n132981863.0\n16.58\n16.03\n-3.317250\n69\n0.180941\n\n\n3/11/2011\n16.58\n16.75\n15.42\n16.03\n114332562\n-3.317250\n4.419900\n109493077.0\n15.95\n16.11\n1.003130\n62\n0.187149\n\n\n3/18/2011\n15.95\n16.33\n15.43\n16.11\n130374108\n1.003130\n14.030601\n114332562.0\n16.38\n17.09\n4.334550\n55\n0.186220\n\n\n3/25/2011\n16.38\n17.24\n16.26\n17.09\n95550392\n4.334550\n-26.710607\n130374108.0\n17.13\n17.47\n1.984820\n48\n0.175541\n\n\n4/1/2011\n17.13\n17.80\n17.02\n17.47\n103320396\n1.984820\n8.131839\n95550392.0\n17.42\n17.92\n2.870260\n41\n0.171723\n\n\n4/8/2011\n17.42\n18.47\n17.42\n17.92\n129237024\n2.870260\n25.083748\n103320396.0\n18.06\n16.52\n-8.527130\n34\n0.167411\n\n\n4/15/2011\n18.06\n18.19\n16.38\n16.52\n213061090\n-8.527130\n64.860721\n129237024.0\n16.36\n16.97\n3.728610\n27\n0.181598\n\n\n4/21/2011\n16.36\n16.97\n15.88\n16.97\n85235391\n3.728610\n-59.994858\n213061090.0\n16.94\n17.00\n0.354191\n21\n0.176783\n\n\n4/29/2011\n16.94\n17.24\n16.66\n17.00\n90831895\n0.354191\n6.565939\n85235391.0\n17.27\n17.15\n-0.694847\n13\n0.176471\n\n\n5/6/2011\n17.27\n17.96\n16.83\n17.15\n225053559\n-0.694847\n147.769309\n90831895.0\n17.16\n17.10\n-0.349650\n6\n0.174927\n\n\n5/13/2011\n17.16\n17.62\n16.75\n17.10\n111630753\n-0.349650\n-50.398139\n225053559.0\n17.00\n16.26\n-4.352940\n82\n0.175439\n\n\n5/20/2011\n17.00\n17.29\n16.26\n16.26\n118281015\n-4.352940\n5.957374\n111630753.0\n15.96\n16.48\n3.258150\n75\n0.184502\n\n\n5/27/2011\n15.96\n16.48\n15.83\n16.48\n77236662\n3.258150\n-34.700711\n118281015.0\n16.73\n15.92\n-4.841600\n68\n0.182039\n\n\n6/3/2011\n16.73\n16.83\n15.77\n15.92\n77152591\n-4.841600\n-0.108849\n77236662.0\n15.92\n15.28\n-4.020100\n61\n0.188442\n\n\n6/10/2011\n15.92\n16.03\n15.17\n15.28\n94970970\n-4.020100\n23.094985\n77152591.0\n15.29\n14.72\n-3.727930\n54\n0.196335\n\n\n6/17/2011\n15.29\n15.50\n14.59\n14.72\n111273573\n-3.727930\n17.165880\n94970970.0\n14.67\n15.23\n3.817310\n47\n0.203804\n\n\n6/24/2011\n14.67\n15.60\n14.56\n15.23\n99423717\n3.817310\n-10.649299\n111273573.0\n15.22\n16.31\n7.161630\n40\n0.196980\n\n\n\n\n\n\n\n\ncols1 = [\"open\", \"high\", \"low\", \"close\", \"next_weeks_open\", \"next_weeks_close\"]\ncols2 = [\"volume\", \"previous_weeks_volume\"]\ncols3 = [\"percent_change_price\", \"percent_change_next_weeks_price\"]\ncols4 = [\"percent_change_volume_over_last_wk\"]\ncols5 = [\"days_to_next_dividend\"]\ncols6 = [\"percent_return_next_dividend\"]\n\n\ndfAA[cols1].plot()\n\n\n\n\n\n\n\n\n\ndfAA[cols2].plot()\n\n\n\n\n\n\n\n\n\ndfAA[cols3].plot()\n\n\n\n\n\n\n\n\n\ndfAA[cols4].plot()\n\n\n\n\n\n\n\n\n\ndfAA[cols5].plot()\n\n\n\n\n\n\n\n\n\ndfAA[cols6].plot()\n\n\n\n\n\n\n\n\n\n\n\ndfAA[\"open_updown\"] = dfAA[\"open\"] &lt; dfAA[\"next_weeks_open\"]\ndfAA[\"close_updown\"] = dfAA[\"close\"] &lt; dfAA[\"next_weeks_close\"]\n\n\nup = dfAA[dfAA[\"open_updown\"]]\ndown = dfAA[~dfAA[\"open_updown\"]]\nplt.scatter(x = up[\"high\"], y = up[\"low\"])\nplt.scatter(x = down[\"high\"], y = down[\"low\"])\n\n\n\n\n\n\n\n\n\nplt.scatter(x = up[cols3[0]], y = up[cols2[0]])\nplt.scatter(x = down[cols3[0]], y = down[cols2[0]])\n\n\n\n\n\n\n\n\n\nplt.scatter(x = up[cols6[0]], y = up[cols2[0]])\nplt.scatter(x = down[cols6[0]], y = down[cols2[0]])\n\n\n\n\n\n\n\n\n\nplt.scatter(x = up[cols6[0]], y = up[cols3[0]])\nplt.scatter(x = down[cols6[0]], y = down[cols3[0]])\n\n\n\n\n\n\n\n\n\nplt.scatter(x = up[cols4[0]], y = up[cols3[0]])\nplt.scatter(x = down[cols4[0]], y = down[cols3[0]])\n\n\n\n\n\n\n\n\n\ndef load_custom_file(filepath):\n    data = []\n\n    with open(filepath, 'r') as f:\n        for line in f:\n            parts = line.strip().split()\n            label = parts[0]  # 最初の数字（ラベル部分）\n\n            # 残りの \"番号:値\" ペアを辞書に変換\n            features = {}\n            for item in parts[1:]:\n                idx, val = item.split(':')\n                features[int(idx)] = float(val)\n\n            # ラベルを追加\n            features['label'] = label\n            data.append(features)\n\n    # DataFrameに変換（欠けているカラムはNaNで埋める）\n    df = pd.DataFrame(data)\n\n    # カラム順を label → feature1, feature2, ...\n    cols = ['label'] + sorted([c for c in df.columns if c != 'label'])\n    df = df[cols]\n\n    return df\n\n\nDF = load_custom_file(\"01_Data/Gas Sensor Array Drift Dataset/batch6.dat\")\nDF.plot(legend=None)\n\n\n\n\n\n\n\n\n\ndf = pd.read_csv(\n    \"01_Data/secom/secom_labels.data\",\n    sep=r'\\s+',\n    quotechar='\"',\n    names=['label', 'timestamp']\n)\ndf['timestamp'] = pd.to_datetime(df['timestamp'], format='%d/%m/%Y %H:%M:%S')\ndf\n\n\n\n\n\n\n\n\nlabel\ntimestamp\n\n\n\n\n0\n-1\n2008-07-19 11:55:00\n\n\n1\n-1\n2008-07-19 12:32:00\n\n\n2\n1\n2008-07-19 13:17:00\n\n\n3\n-1\n2008-07-19 14:43:00\n\n\n4\n-1\n2008-07-19 15:22:00\n\n\n...\n...\n...\n\n\n1562\n-1\n2008-10-16 15:13:00\n\n\n1563\n-1\n2008-10-16 20:49:00\n\n\n1564\n-1\n2008-10-17 05:26:00\n\n\n1565\n-1\n2008-10-17 06:01:00\n\n\n1566\n-1\n2008-10-17 06:07:00\n\n\n\n\n1567 rows × 2 columns\n\n\n\n\ndf1 = pd.read_csv(\"01_Data/secom/secom.data\", sep=r'\\s+', header=None)\ndf1\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n\n\n\n\n0\n3030.93\n2564.00\n2187.7333\n1411.1265\n1.3602\n100.0\n97.6133\n0.1242\n1.5005\n0.0162\n...\nNaN\nNaN\n0.5005\n0.0118\n0.0035\n2.3630\nNaN\nNaN\nNaN\nNaN\n\n\n1\n3095.78\n2465.14\n2230.4222\n1463.6606\n0.8294\n100.0\n102.3433\n0.1247\n1.4966\n-0.0005\n...\n0.0060\n208.2045\n0.5019\n0.0223\n0.0055\n4.4447\n0.0096\n0.0201\n0.0060\n208.2045\n\n\n2\n2932.61\n2559.94\n2186.4111\n1698.0172\n1.5102\n100.0\n95.4878\n0.1241\n1.4436\n0.0041\n...\n0.0148\n82.8602\n0.4958\n0.0157\n0.0039\n3.1745\n0.0584\n0.0484\n0.0148\n82.8602\n\n\n3\n2988.72\n2479.90\n2199.0333\n909.7926\n1.3204\n100.0\n104.2367\n0.1217\n1.4882\n-0.0124\n...\n0.0044\n73.8432\n0.4990\n0.0103\n0.0025\n2.0544\n0.0202\n0.0149\n0.0044\n73.8432\n\n\n4\n3032.24\n2502.87\n2233.3667\n1326.5200\n1.5334\n100.0\n100.3967\n0.1235\n1.5031\n-0.0031\n...\nNaN\nNaN\n0.4800\n0.4766\n0.1045\n99.3032\n0.0202\n0.0149\n0.0044\n73.8432\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1562\n2899.41\n2464.36\n2179.7333\n3085.3781\n1.4843\n100.0\n82.2467\n0.1248\n1.3424\n-0.0045\n...\n0.0047\n203.1720\n0.4988\n0.0143\n0.0039\n2.8669\n0.0068\n0.0138\n0.0047\n203.1720\n\n\n1563\n3052.31\n2522.55\n2198.5667\n1124.6595\n0.8763\n100.0\n98.4689\n0.1205\n1.4333\n-0.0061\n...\nNaN\nNaN\n0.4975\n0.0131\n0.0036\n2.6238\n0.0068\n0.0138\n0.0047\n203.1720\n\n\n1564\n2978.81\n2379.78\n2206.3000\n1110.4967\n0.8236\n100.0\n99.4122\n0.1208\nNaN\nNaN\n...\n0.0025\n43.5231\n0.4987\n0.0153\n0.0041\n3.0590\n0.0197\n0.0086\n0.0025\n43.5231\n\n\n1565\n2894.92\n2532.01\n2177.0333\n1183.7287\n1.5726\n100.0\n98.7978\n0.1213\n1.4622\n-0.0072\n...\n0.0075\n93.4941\n0.5004\n0.0178\n0.0038\n3.5662\n0.0262\n0.0245\n0.0075\n93.4941\n\n\n1566\n2944.92\n2450.76\n2195.4444\n2914.1792\n1.5978\n100.0\n85.1011\n0.1235\nNaN\nNaN\n...\n0.0045\n137.7844\n0.4987\n0.0181\n0.0040\n3.6275\n0.0117\n0.0162\n0.0045\n137.7844\n\n\n\n\n1567 rows × 590 columns",
    "crumbs": [
      "分析データ",
      "分析01"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis01.html#dow_jones_index",
    "href": "AnalysisStorage/analysis01.html#dow_jones_index",
    "title": "分析01",
    "section": "",
    "text": "https://archive.ics.uci.edu/dataset/312/dow+jones+index\nThis dataset contains weekly data for the Dow Jones Industrial Index. It has been used in computational investing research.\n\n\n\n\n\n\n\n項目名\n説明\n\n\n\n\nquarter\n年間の四半期（1 = 1〜3月、2 = 4〜6月）\n\n\nstock\n株式のシンボル（ティッカーコード）\n\n\ndate\n週の最終営業日（通常は金曜日）\n\n\nopen\n週の始めの株価（始値）\n\n\nhigh\n週の最高株価\n\n\nlow\n週の最安株価\n\n\nclose\n週の終わりの株価（終値）\n\n\nvolume\nその週に取引された株式の出来高（取引株数）\n\n\npercent_change_price\n週を通しての株価変動率（％）\n\n\npercent_change_volume_over_last_week\n前週と比較した出来高の変化率（％）\n\n\nprevious_weeks_volume\n前週の出来高（取引株数）\n\n\nnext_weeks_open\n翌週の始値\n\n\nnext_weeks_close\n翌週の終値\n\n\npercent_change_next_weeks_price\n翌週の株価変動率（％）\n\n\ndays_to_next_dividend\n次回配当までの日数\n\n\npercent_return_next_dividend\n次回配当による利回り（％）\n\n\n\n\ndf = pd.read_csv(\"01_Data/dow_jones_index/dow_jones_index.data\")\ndf\n\n\n\n\n\n\n\n\nquarter\nstock\ndate\nopen\nhigh\nlow\nclose\nvolume\npercent_change_price\npercent_change_volume_over_last_wk\nprevious_weeks_volume\nnext_weeks_open\nnext_weeks_close\npercent_change_next_weeks_price\ndays_to_next_dividend\npercent_return_next_dividend\n\n\n\n\n0\n1\nAA\n1/7/2011\n$15.82\n$16.72\n$15.78\n$16.42\n239655616\n3.79267\nNaN\nNaN\n$16.71\n$15.97\n-4.428490\n26\n0.182704\n\n\n1\n1\nAA\n1/14/2011\n$16.71\n$16.71\n$15.64\n$15.97\n242963398\n-4.42849\n1.380223\n239655616.0\n$16.19\n$15.79\n-2.470660\n19\n0.187852\n\n\n2\n1\nAA\n1/21/2011\n$16.19\n$16.38\n$15.60\n$15.79\n138428495\n-2.47066\n-43.024959\n242963398.0\n$15.87\n$16.13\n1.638310\n12\n0.189994\n\n\n3\n1\nAA\n1/28/2011\n$15.87\n$16.63\n$15.82\n$16.13\n151379173\n1.63831\n9.355500\n138428495.0\n$16.18\n$17.14\n5.933250\n5\n0.185989\n\n\n4\n1\nAA\n2/4/2011\n$16.18\n$17.39\n$16.18\n$17.14\n154387761\n5.93325\n1.987452\n151379173.0\n$17.33\n$17.37\n0.230814\n97\n0.175029\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n745\n2\nXOM\n5/27/2011\n$80.22\n$82.63\n$80.07\n$82.63\n68230855\n3.00424\n-21.355713\n86758820.0\n$83.28\n$81.18\n-2.521610\n75\n0.568801\n\n\n746\n2\nXOM\n6/3/2011\n$83.28\n$83.75\n$80.18\n$81.18\n78616295\n-2.52161\n15.221032\n68230855.0\n$80.93\n$79.78\n-1.420980\n68\n0.578960\n\n\n747\n2\nXOM\n6/10/2011\n$80.93\n$81.87\n$79.72\n$79.78\n92380844\n-1.42098\n17.508519\n78616295.0\n$80.00\n$79.02\n-1.225000\n61\n0.589120\n\n\n748\n2\nXOM\n6/17/2011\n$80.00\n$80.82\n$78.33\n$79.02\n100521400\n-1.22500\n8.811952\n92380844.0\n$78.65\n$76.78\n-2.377620\n54\n0.594786\n\n\n749\n2\nXOM\n6/24/2011\n$78.65\n$81.12\n$76.78\n$76.78\n118679791\n-2.37762\n18.064204\n100521400.0\n$76.88\n$82.01\n6.672740\n47\n0.612139\n\n\n\n\n750 rows × 16 columns\n\n\n\n\ndf1 = df.set_index(\"date\")\ndf1\n\n\n\n\n\n\n\n\nquarter\nstock\nopen\nhigh\nlow\nclose\nvolume\npercent_change_price\npercent_change_volume_over_last_wk\nprevious_weeks_volume\nnext_weeks_open\nnext_weeks_close\npercent_change_next_weeks_price\ndays_to_next_dividend\npercent_return_next_dividend\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1/7/2011\n1\nAA\n$15.82\n$16.72\n$15.78\n$16.42\n239655616\n3.79267\nNaN\nNaN\n$16.71\n$15.97\n-4.428490\n26\n0.182704\n\n\n1/14/2011\n1\nAA\n$16.71\n$16.71\n$15.64\n$15.97\n242963398\n-4.42849\n1.380223\n239655616.0\n$16.19\n$15.79\n-2.470660\n19\n0.187852\n\n\n1/21/2011\n1\nAA\n$16.19\n$16.38\n$15.60\n$15.79\n138428495\n-2.47066\n-43.024959\n242963398.0\n$15.87\n$16.13\n1.638310\n12\n0.189994\n\n\n1/28/2011\n1\nAA\n$15.87\n$16.63\n$15.82\n$16.13\n151379173\n1.63831\n9.355500\n138428495.0\n$16.18\n$17.14\n5.933250\n5\n0.185989\n\n\n2/4/2011\n1\nAA\n$16.18\n$17.39\n$16.18\n$17.14\n154387761\n5.93325\n1.987452\n151379173.0\n$17.33\n$17.37\n0.230814\n97\n0.175029\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5/27/2011\n2\nXOM\n$80.22\n$82.63\n$80.07\n$82.63\n68230855\n3.00424\n-21.355713\n86758820.0\n$83.28\n$81.18\n-2.521610\n75\n0.568801\n\n\n6/3/2011\n2\nXOM\n$83.28\n$83.75\n$80.18\n$81.18\n78616295\n-2.52161\n15.221032\n68230855.0\n$80.93\n$79.78\n-1.420980\n68\n0.578960\n\n\n6/10/2011\n2\nXOM\n$80.93\n$81.87\n$79.72\n$79.78\n92380844\n-1.42098\n17.508519\n78616295.0\n$80.00\n$79.02\n-1.225000\n61\n0.589120\n\n\n6/17/2011\n2\nXOM\n$80.00\n$80.82\n$78.33\n$79.02\n100521400\n-1.22500\n8.811952\n92380844.0\n$78.65\n$76.78\n-2.377620\n54\n0.594786\n\n\n6/24/2011\n2\nXOM\n$78.65\n$81.12\n$76.78\n$76.78\n118679791\n-2.37762\n18.064204\n100521400.0\n$76.88\n$82.01\n6.672740\n47\n0.612139\n\n\n\n\n750 rows × 15 columns\n\n\n\n\ndf1.plot()\n\n\n\n\n\n\n\n\n\nx quarter\n\n\ndol_cols = [\n  \"open\", \n  \"high\", \n  \"low\", \n  \"close\", \n  \"next_weeks_open\", \n  \"next_weeks_close\"\n  ]\n\ndf1[dol_cols] = (\n    df1[dol_cols]\n    .replace('[\\$,]', '', regex=True)  # $, , を削除\n    .astype(float)                     # float型に変換\n)\n\n\ndf1\n\n\n\n\n\n\n\n\nquarter\nstock\nopen\nhigh\nlow\nclose\nvolume\npercent_change_price\npercent_change_volume_over_last_wk\nprevious_weeks_volume\nnext_weeks_open\nnext_weeks_close\npercent_change_next_weeks_price\ndays_to_next_dividend\npercent_return_next_dividend\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1/7/2011\n1\nAA\n15.82\n16.72\n15.78\n16.42\n239655616\n3.79267\nNaN\nNaN\n16.71\n15.97\n-4.428490\n26\n0.182704\n\n\n1/14/2011\n1\nAA\n16.71\n16.71\n15.64\n15.97\n242963398\n-4.42849\n1.380223\n239655616.0\n16.19\n15.79\n-2.470660\n19\n0.187852\n\n\n1/21/2011\n1\nAA\n16.19\n16.38\n15.60\n15.79\n138428495\n-2.47066\n-43.024959\n242963398.0\n15.87\n16.13\n1.638310\n12\n0.189994\n\n\n1/28/2011\n1\nAA\n15.87\n16.63\n15.82\n16.13\n151379173\n1.63831\n9.355500\n138428495.0\n16.18\n17.14\n5.933250\n5\n0.185989\n\n\n2/4/2011\n1\nAA\n16.18\n17.39\n16.18\n17.14\n154387761\n5.93325\n1.987452\n151379173.0\n17.33\n17.37\n0.230814\n97\n0.175029\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5/27/2011\n2\nXOM\n80.22\n82.63\n80.07\n82.63\n68230855\n3.00424\n-21.355713\n86758820.0\n83.28\n81.18\n-2.521610\n75\n0.568801\n\n\n6/3/2011\n2\nXOM\n83.28\n83.75\n80.18\n81.18\n78616295\n-2.52161\n15.221032\n68230855.0\n80.93\n79.78\n-1.420980\n68\n0.578960\n\n\n6/10/2011\n2\nXOM\n80.93\n81.87\n79.72\n79.78\n92380844\n-1.42098\n17.508519\n78616295.0\n80.00\n79.02\n-1.225000\n61\n0.589120\n\n\n6/17/2011\n2\nXOM\n80.00\n80.82\n78.33\n79.02\n100521400\n-1.22500\n8.811952\n92380844.0\n78.65\n76.78\n-2.377620\n54\n0.594786\n\n\n6/24/2011\n2\nXOM\n78.65\n81.12\n76.78\n76.78\n118679791\n-2.37762\n18.064204\n100521400.0\n76.88\n82.01\n6.672740\n47\n0.612139\n\n\n\n\n750 rows × 15 columns\n\n\n\n\ndf1.groupby(\"stock\").count()\n\n\n\n\n\n\n\n\nquarter\nopen\nhigh\nlow\nclose\nvolume\npercent_change_price\npercent_change_volume_over_last_wk\nprevious_weeks_volume\nnext_weeks_open\nnext_weeks_close\npercent_change_next_weeks_price\ndays_to_next_dividend\npercent_return_next_dividend\n\n\nstock\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAA\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nAXP\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nBA\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nBAC\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nCAT\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nCSCO\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nCVX\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nDD\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nDIS\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nGE\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nHD\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nHPQ\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nIBM\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nINTC\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nJNJ\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nJPM\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nKO\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nKRFT\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nMCD\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nMMM\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nMRK\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nMSFT\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nPFE\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nPG\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nT\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nTRV\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nUTX\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nVZ\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nWMT\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\nXOM\n25\n25\n25\n25\n25\n25\n25\n24\n24\n25\n25\n25\n25\n25\n\n\n\n\n\n\n\n\nnumcols = [\"open\", \"high\", \"low\", \"close\", \"volume\", \"percent_change_price\", \"percent_change_volume_over_last_wk\", \"previous_weeks_volume\", \"next_weeks_open\", \"next_weeks_close\", \"percent_change_next_weeks_price\", \"days_to_next_dividend\", \"percent_return_next_dividend\"]\ndfAA = df1[df1[\"stock\"] == \"AA\"][numcols]\ndfAA\n\n\n\n\n\n\n\n\nopen\nhigh\nlow\nclose\nvolume\npercent_change_price\npercent_change_volume_over_last_wk\nprevious_weeks_volume\nnext_weeks_open\nnext_weeks_close\npercent_change_next_weeks_price\ndays_to_next_dividend\npercent_return_next_dividend\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1/7/2011\n15.82\n16.72\n15.78\n16.42\n239655616\n3.792670\nNaN\nNaN\n16.71\n15.97\n-4.428490\n26\n0.182704\n\n\n1/14/2011\n16.71\n16.71\n15.64\n15.97\n242963398\n-4.428490\n1.380223\n239655616.0\n16.19\n15.79\n-2.470660\n19\n0.187852\n\n\n1/21/2011\n16.19\n16.38\n15.60\n15.79\n138428495\n-2.470660\n-43.024959\n242963398.0\n15.87\n16.13\n1.638310\n12\n0.189994\n\n\n1/28/2011\n15.87\n16.63\n15.82\n16.13\n151379173\n1.638310\n9.355500\n138428495.0\n16.18\n17.14\n5.933250\n5\n0.185989\n\n\n2/4/2011\n16.18\n17.39\n16.18\n17.14\n154387761\n5.933250\n1.987452\n151379173.0\n17.33\n17.37\n0.230814\n97\n0.175029\n\n\n2/11/2011\n17.33\n17.48\n16.97\n17.37\n114691279\n0.230814\n-25.712195\n154387761.0\n17.39\n17.28\n-0.632547\n90\n0.172712\n\n\n2/18/2011\n17.39\n17.68\n17.28\n17.28\n80023895\n-0.632547\n-30.226696\n114691279.0\n16.98\n16.68\n-1.766780\n83\n0.173611\n\n\n2/25/2011\n16.98\n17.15\n15.96\n16.68\n132981863\n-1.766780\n66.177694\n80023895.0\n16.81\n16.58\n-1.368230\n76\n0.179856\n\n\n3/4/2011\n16.81\n16.94\n16.13\n16.58\n109493077\n-1.368230\n-17.663150\n132981863.0\n16.58\n16.03\n-3.317250\n69\n0.180941\n\n\n3/11/2011\n16.58\n16.75\n15.42\n16.03\n114332562\n-3.317250\n4.419900\n109493077.0\n15.95\n16.11\n1.003130\n62\n0.187149\n\n\n3/18/2011\n15.95\n16.33\n15.43\n16.11\n130374108\n1.003130\n14.030601\n114332562.0\n16.38\n17.09\n4.334550\n55\n0.186220\n\n\n3/25/2011\n16.38\n17.24\n16.26\n17.09\n95550392\n4.334550\n-26.710607\n130374108.0\n17.13\n17.47\n1.984820\n48\n0.175541\n\n\n4/1/2011\n17.13\n17.80\n17.02\n17.47\n103320396\n1.984820\n8.131839\n95550392.0\n17.42\n17.92\n2.870260\n41\n0.171723\n\n\n4/8/2011\n17.42\n18.47\n17.42\n17.92\n129237024\n2.870260\n25.083748\n103320396.0\n18.06\n16.52\n-8.527130\n34\n0.167411\n\n\n4/15/2011\n18.06\n18.19\n16.38\n16.52\n213061090\n-8.527130\n64.860721\n129237024.0\n16.36\n16.97\n3.728610\n27\n0.181598\n\n\n4/21/2011\n16.36\n16.97\n15.88\n16.97\n85235391\n3.728610\n-59.994858\n213061090.0\n16.94\n17.00\n0.354191\n21\n0.176783\n\n\n4/29/2011\n16.94\n17.24\n16.66\n17.00\n90831895\n0.354191\n6.565939\n85235391.0\n17.27\n17.15\n-0.694847\n13\n0.176471\n\n\n5/6/2011\n17.27\n17.96\n16.83\n17.15\n225053559\n-0.694847\n147.769309\n90831895.0\n17.16\n17.10\n-0.349650\n6\n0.174927\n\n\n5/13/2011\n17.16\n17.62\n16.75\n17.10\n111630753\n-0.349650\n-50.398139\n225053559.0\n17.00\n16.26\n-4.352940\n82\n0.175439\n\n\n5/20/2011\n17.00\n17.29\n16.26\n16.26\n118281015\n-4.352940\n5.957374\n111630753.0\n15.96\n16.48\n3.258150\n75\n0.184502\n\n\n5/27/2011\n15.96\n16.48\n15.83\n16.48\n77236662\n3.258150\n-34.700711\n118281015.0\n16.73\n15.92\n-4.841600\n68\n0.182039\n\n\n6/3/2011\n16.73\n16.83\n15.77\n15.92\n77152591\n-4.841600\n-0.108849\n77236662.0\n15.92\n15.28\n-4.020100\n61\n0.188442\n\n\n6/10/2011\n15.92\n16.03\n15.17\n15.28\n94970970\n-4.020100\n23.094985\n77152591.0\n15.29\n14.72\n-3.727930\n54\n0.196335\n\n\n6/17/2011\n15.29\n15.50\n14.59\n14.72\n111273573\n-3.727930\n17.165880\n94970970.0\n14.67\n15.23\n3.817310\n47\n0.203804\n\n\n6/24/2011\n14.67\n15.60\n14.56\n15.23\n99423717\n3.817310\n-10.649299\n111273573.0\n15.22\n16.31\n7.161630\n40\n0.196980\n\n\n\n\n\n\n\n\ncols1 = [\"open\", \"high\", \"low\", \"close\", \"next_weeks_open\", \"next_weeks_close\"]\ncols2 = [\"volume\", \"previous_weeks_volume\"]\ncols3 = [\"percent_change_price\", \"percent_change_next_weeks_price\"]\ncols4 = [\"percent_change_volume_over_last_wk\"]\ncols5 = [\"days_to_next_dividend\"]\ncols6 = [\"percent_return_next_dividend\"]\n\n\ndfAA[cols1].plot()\n\n\n\n\n\n\n\n\n\ndfAA[cols2].plot()\n\n\n\n\n\n\n\n\n\ndfAA[cols3].plot()\n\n\n\n\n\n\n\n\n\ndfAA[cols4].plot()\n\n\n\n\n\n\n\n\n\ndfAA[cols5].plot()\n\n\n\n\n\n\n\n\n\ndfAA[cols6].plot()\n\n\n\n\n\n\n\n\n\n\n\ndfAA[\"open_updown\"] = dfAA[\"open\"] &lt; dfAA[\"next_weeks_open\"]\ndfAA[\"close_updown\"] = dfAA[\"close\"] &lt; dfAA[\"next_weeks_close\"]\n\n\nup = dfAA[dfAA[\"open_updown\"]]\ndown = dfAA[~dfAA[\"open_updown\"]]\nplt.scatter(x = up[\"high\"], y = up[\"low\"])\nplt.scatter(x = down[\"high\"], y = down[\"low\"])\n\n\n\n\n\n\n\n\n\nplt.scatter(x = up[cols3[0]], y = up[cols2[0]])\nplt.scatter(x = down[cols3[0]], y = down[cols2[0]])\n\n\n\n\n\n\n\n\n\nplt.scatter(x = up[cols6[0]], y = up[cols2[0]])\nplt.scatter(x = down[cols6[0]], y = down[cols2[0]])\n\n\n\n\n\n\n\n\n\nplt.scatter(x = up[cols6[0]], y = up[cols3[0]])\nplt.scatter(x = down[cols6[0]], y = down[cols3[0]])\n\n\n\n\n\n\n\n\n\nplt.scatter(x = up[cols4[0]], y = up[cols3[0]])\nplt.scatter(x = down[cols4[0]], y = down[cols3[0]])\n\n\n\n\n\n\n\n\n\ndef load_custom_file(filepath):\n    data = []\n\n    with open(filepath, 'r') as f:\n        for line in f:\n            parts = line.strip().split()\n            label = parts[0]  # 最初の数字（ラベル部分）\n\n            # 残りの \"番号:値\" ペアを辞書に変換\n            features = {}\n            for item in parts[1:]:\n                idx, val = item.split(':')\n                features[int(idx)] = float(val)\n\n            # ラベルを追加\n            features['label'] = label\n            data.append(features)\n\n    # DataFrameに変換（欠けているカラムはNaNで埋める）\n    df = pd.DataFrame(data)\n\n    # カラム順を label → feature1, feature2, ...\n    cols = ['label'] + sorted([c for c in df.columns if c != 'label'])\n    df = df[cols]\n\n    return df\n\n\nDF = load_custom_file(\"01_Data/Gas Sensor Array Drift Dataset/batch6.dat\")\nDF.plot(legend=None)\n\n\n\n\n\n\n\n\n\ndf = pd.read_csv(\n    \"01_Data/secom/secom_labels.data\",\n    sep=r'\\s+',\n    quotechar='\"',\n    names=['label', 'timestamp']\n)\ndf['timestamp'] = pd.to_datetime(df['timestamp'], format='%d/%m/%Y %H:%M:%S')\ndf\n\n\n\n\n\n\n\n\nlabel\ntimestamp\n\n\n\n\n0\n-1\n2008-07-19 11:55:00\n\n\n1\n-1\n2008-07-19 12:32:00\n\n\n2\n1\n2008-07-19 13:17:00\n\n\n3\n-1\n2008-07-19 14:43:00\n\n\n4\n-1\n2008-07-19 15:22:00\n\n\n...\n...\n...\n\n\n1562\n-1\n2008-10-16 15:13:00\n\n\n1563\n-1\n2008-10-16 20:49:00\n\n\n1564\n-1\n2008-10-17 05:26:00\n\n\n1565\n-1\n2008-10-17 06:01:00\n\n\n1566\n-1\n2008-10-17 06:07:00\n\n\n\n\n1567 rows × 2 columns\n\n\n\n\ndf1 = pd.read_csv(\"01_Data/secom/secom.data\", sep=r'\\s+', header=None)\ndf1\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n\n\n\n\n0\n3030.93\n2564.00\n2187.7333\n1411.1265\n1.3602\n100.0\n97.6133\n0.1242\n1.5005\n0.0162\n...\nNaN\nNaN\n0.5005\n0.0118\n0.0035\n2.3630\nNaN\nNaN\nNaN\nNaN\n\n\n1\n3095.78\n2465.14\n2230.4222\n1463.6606\n0.8294\n100.0\n102.3433\n0.1247\n1.4966\n-0.0005\n...\n0.0060\n208.2045\n0.5019\n0.0223\n0.0055\n4.4447\n0.0096\n0.0201\n0.0060\n208.2045\n\n\n2\n2932.61\n2559.94\n2186.4111\n1698.0172\n1.5102\n100.0\n95.4878\n0.1241\n1.4436\n0.0041\n...\n0.0148\n82.8602\n0.4958\n0.0157\n0.0039\n3.1745\n0.0584\n0.0484\n0.0148\n82.8602\n\n\n3\n2988.72\n2479.90\n2199.0333\n909.7926\n1.3204\n100.0\n104.2367\n0.1217\n1.4882\n-0.0124\n...\n0.0044\n73.8432\n0.4990\n0.0103\n0.0025\n2.0544\n0.0202\n0.0149\n0.0044\n73.8432\n\n\n4\n3032.24\n2502.87\n2233.3667\n1326.5200\n1.5334\n100.0\n100.3967\n0.1235\n1.5031\n-0.0031\n...\nNaN\nNaN\n0.4800\n0.4766\n0.1045\n99.3032\n0.0202\n0.0149\n0.0044\n73.8432\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1562\n2899.41\n2464.36\n2179.7333\n3085.3781\n1.4843\n100.0\n82.2467\n0.1248\n1.3424\n-0.0045\n...\n0.0047\n203.1720\n0.4988\n0.0143\n0.0039\n2.8669\n0.0068\n0.0138\n0.0047\n203.1720\n\n\n1563\n3052.31\n2522.55\n2198.5667\n1124.6595\n0.8763\n100.0\n98.4689\n0.1205\n1.4333\n-0.0061\n...\nNaN\nNaN\n0.4975\n0.0131\n0.0036\n2.6238\n0.0068\n0.0138\n0.0047\n203.1720\n\n\n1564\n2978.81\n2379.78\n2206.3000\n1110.4967\n0.8236\n100.0\n99.4122\n0.1208\nNaN\nNaN\n...\n0.0025\n43.5231\n0.4987\n0.0153\n0.0041\n3.0590\n0.0197\n0.0086\n0.0025\n43.5231\n\n\n1565\n2894.92\n2532.01\n2177.0333\n1183.7287\n1.5726\n100.0\n98.7978\n0.1213\n1.4622\n-0.0072\n...\n0.0075\n93.4941\n0.5004\n0.0178\n0.0038\n3.5662\n0.0262\n0.0245\n0.0075\n93.4941\n\n\n1566\n2944.92\n2450.76\n2195.4444\n2914.1792\n1.5978\n100.0\n85.1011\n0.1235\nNaN\nNaN\n...\n0.0045\n137.7844\n0.4987\n0.0181\n0.0040\n3.6275\n0.0117\n0.0162\n0.0045\n137.7844\n\n\n\n\n1567 rows × 590 columns",
    "crumbs": [
      "分析データ",
      "分析01"
    ]
  },
  {
    "objectID": "Gen/gen.html",
    "href": "Gen/gen.html",
    "title": "00_Gen",
    "section": "",
    "text": "&lt;unknown&gt;:1: SyntaxWarning: invalid escape sequence '\\m'\n\nsource\n\ngen_w\n\ndef gen_w(\n    key:Union, # PRNGKeyArray\n    N:int, # $N$\n    T:int, # $T$\n    G:Float[Array, '{N} {N}'], # $\\boldsymbol\\Gamma$\n    w0:Float[Array, '{N}'], # $\\mathbf w_{-1}$\n)-&gt;Float[Array, '{T} {N}']: # $\\{\\mathbf w_t\\}_{t=0,\\ldots,T-1}$\n\n*\\(\\!\\)** 潜在変数 \\(\\{\\mathbf w_t\\}_{t=0,\\ldots,T-1}\\) の生成 \\[\\mathbf w_{t}\\sim\\mathcal N(\\mathbf w_t\\mid\\mathbf w_{t-1},\\boldsymbol\\Gamma)\\] *\\(\\!\\)\n\nsource\n\n\ngen_xy\n\ndef gen_xy(\n    key:Union, # RPNGKeyArray\n    N:int, # $N$\n    T:int, # $T$\n    Sigma:Float[Array, '{N} {N}'], # $\\boldsymbol\\Sigma$\n    W:Float[Array, '{T} {N}'], # $\\{\\mathbf w_t\\}_{t=0,\\ldots,T-1}$\n)-&gt;Tuple: # $\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1}, \\{y_t\\}_{t=0,\\ldots,T-1}$\n\n*\\(\\!\\)** 観測変数 \\(\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1}, \\{y_t\\}_{t=0,\\ldots,T-1}\\) の生成 \\[y_t\\sim\\text{Bern}(y_t\\mid 1/2)\\] \\[\\boldsymbol\\Sigma\\mathbf w_t=2\\boldsymbol\\mu_{1,t}\\] \\[\\boldsymbol\\mu_{2,t}=-\\boldsymbol\\mu_{1,t}\\] \\[\n\\mathbf x_t\\sim\n\\begin{cases}\n\\displaystyle\\mathcal N\\left(\\boldsymbol\\mu_{1,t},\\boldsymbol\\Sigma\\right) & (y_t=1) \\\\\n\\displaystyle\\mathcal N\\left(\\boldsymbol\\mu_{2,t},\\boldsymbol\\Sigma\\right) & (y_t=0)\n\\end{cases}\n\\] *\\(\\!\\)\n\nsource\n\n\ngen_xy_logistic\n\ndef gen_xy_logistic(\n    key:Union, # PRNGKeyArray\n    N:int, # $N$\n    T:int, # $T$\n    Sigma:Float[Array, '{N} {N}'], # $\\boldsymbol\\Sigma$\n    W:Float[Array, '{T} {N}'], # $\\{\\mathbf w_t\\}_{t=0,\\ldots,T-1}$\n)-&gt;Tuple: # $\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1}, \\{y_t\\}_{t=0,\\ldots,T-1}$\n\n*\\(\\!\\)** 観測変数 \\(\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1}, \\{y_t\\}_{t=0,\\ldots,T-1}\\) の生成\n\\[\\mathbf x_t \\sim \\mathcal N(\\mathbf 0, \\boldsymbol\\Sigma)\\] \\[y_t \\sim \\text{Bern}\\bigl(y_t\\mid\\sigma(\\mathbf x_t^\\mathsf T \\mathbf w_t)\\bigr)\\] *\\(\\!\\)",
    "crumbs": [
      "データ生成",
      "00_Gen"
    ]
  },
  {
    "objectID": "analysisnote.html",
    "href": "analysisnote.html",
    "title": "実験ノート",
    "section": "",
    "text": "新たな評価基準を設けた。それによる考察を兼ねて、実験結果を整理する。\n\n\n\n次元数 \\(2\\) 、\\(w_{0}=(0,0)^T\\) で、次の４象限に分けて実験結果をまとめた。\n\n\n\n\\(\\boldsymbol\\Gamma\\)\n\\(\\boldsymbol\\Sigma\\)\n\n\n\n\n\\(2^{-4}\\mathbf I\\)\n\\(2^{-2}\\mathbf I\\)\n\n\n\\(2^{-4}\\mathbf I\\)\n\\(2^{4}\\mathbf I\\)\n\n\n\\(2^{-12}\\mathbf I\\)\n\\(2^{-2}\\mathbf I\\)\n\n\n\\(2^{-12}\\mathbf I\\)\n\\(2^{4}\\mathbf I\\)\n\n\n\n\n\n\n\n\n\nエビフライトライアングル\n\n\n\n\\(\\mathbf w_t\\) の遷移が大きい（ \\(\\boldsymbol\\Gamma\\) が大きい）ほど、(EKFよりも)変分近似が優れる\n\\(\\mathbf x\\) の分散に関しては、単純に優劣の評価ができない。\n\n\n\n\naaa\n\n\n\n\\(\\mathbf x_t\\) の分散や \\(\\mathbf w_t\\) の分散は、単純にスケールされている点に注意が必要",
    "crumbs": [
      "実験ノート"
    ]
  },
  {
    "objectID": "analysisnote.html#section",
    "href": "analysisnote.html#section",
    "title": "実験ノート",
    "section": "",
    "text": "新たな評価基準を設けた。それによる考察を兼ねて、実験結果を整理する。\n\n\n\n次元数 \\(2\\) 、\\(w_{0}=(0,0)^T\\) で、次の４象限に分けて実験結果をまとめた。\n\n\n\n\\(\\boldsymbol\\Gamma\\)\n\\(\\boldsymbol\\Sigma\\)\n\n\n\n\n\\(2^{-4}\\mathbf I\\)\n\\(2^{-2}\\mathbf I\\)\n\n\n\\(2^{-4}\\mathbf I\\)\n\\(2^{4}\\mathbf I\\)\n\n\n\\(2^{-12}\\mathbf I\\)\n\\(2^{-2}\\mathbf I\\)\n\n\n\\(2^{-12}\\mathbf I\\)\n\\(2^{4}\\mathbf I\\)\n\n\n\n\n\n\n\n\n\nエビフライトライアングル\n\n\n\n\\(\\mathbf w_t\\) の遷移が大きい（ \\(\\boldsymbol\\Gamma\\) が大きい）ほど、(EKFよりも)変分近似が優れる\n\\(\\mathbf x\\) の分散に関しては、単純に優劣の評価ができない。\n\n\n\n\naaa\n\n\n\n\\(\\mathbf x_t\\) の分散や \\(\\mathbf w_t\\) の分散は、単純にスケールされている点に注意が必要",
    "crumbs": [
      "実験ノート"
    ]
  },
  {
    "objectID": "analysisnote.html#section-1",
    "href": "analysisnote.html#section-1",
    "title": "実験ノート",
    "section": "12/10.1",
    "text": "12/10.1\n\n概要\n推定誤差共分散行列は、両者に明確な大小がある。\n\\[\\mathbf P_{t/t}^{-1}=\\mathbf P_{t/t-1}^{-1}+\\sigma_t(1-\\sigma_t)\\mathbf x_t\\mathbf x_t^T\\]\n\\[\\mathbf P_{t/t}^{-1}=\\mathbf P_{t/t-1}^{-1}+2\\lambda(\\xi_t)\\mathbf x_t\\mathbf x_t^T\\]\n\n青: \\(\\displaystyle\\sigma(x)\\{1-\\sigma(x)\\}\\)\n緑: \\(2\\lambda(x)=\\displaystyle\\frac{1}{x}\\left(\\sigma(x)-\\frac{1}{2}\\right)\\)\n\n\n\n\naaa\n\n\n\n\n実験\n\\[\\overline{\\mathbf P}=\\frac{1}{N_{\\text{seed}}T}\\sum_{s,t}\\text{seed} (s) \\text{における}\\mathbf P_{t/t}\\] \\[\\text{frob\\_error}=\\|\\overline{\\mathbf P}-\\mathbf\\Gamma\\|_F\\] \\[\\text{relative\\_error}=\\frac{\\text{frob\\_error}}{\\|\\Gamma\\|_F}\\] \\[\\mathbf\\Gamma=2^p\\mathbf I\\]\n\n\n\naaa\n\n\n\n\n備考\n\\[p(\\mathbf w_{t}\\mid\\mathbf w_{t-1}) = \\mathcal N(\\mathbf w_{t}\\mid\\mathbf w_{t-1},\\mathbf \\Gamma)\\] \\[p(\\mathbf w_t\\mid\\mathbf Y_t) = \\mathcal N(\\mathbf w_t\\mid\\hat{\\mathbf w}_{t/t},\\mathbf P_{t/t})\\]\n\\(\\mathbf Y_t\\) には \\(\\mathbf w_{t-1}\\) の情報が入っているので、次の２つの式はほとんど同じ\n\\[p(\\mathbf w_t)=\\int p(\\mathbf w_t\\mid\\mathbf Y_t)p(\\mathbf Y_t)d\\mathbf Y_t\\]\n\\[p(\\mathbf w_t\\mid\\mathbf w_{t-1})=\\int p(\\mathbf w_t\\mid\\mathbf w_{t-1}, \\mathbf Y_t)p(\\mathbf Y_t)d\\mathbf Y_t\\]\n実験では、\\(\\mathbf P_{t/t}\\) に対して期待値をとっている。",
    "crumbs": [
      "実験ノート"
    ]
  },
  {
    "objectID": "analysisnote.html#section-2",
    "href": "analysisnote.html#section-2",
    "title": "実験ノート",
    "section": "12/16.1",
    "text": "12/16.1\n\n概要\n表に対して、比較するグラフを作成。\n\n\n\n\n\n\n\n\n\\(\\!\\)\nFrobenius error\nRelative error\n\n\n\n\nnormal plot\n\n\n\n\nlog plot\n\n\n\n\n\n\n\n考察\n\\(\\boldsymbol\\Gamma\\) の大きさに合わせて、フロベニウス誤差が線形に増加しているのが正常であると考えられる。\n\n\n\n\n\n\n\n\n\\(\\!\\)\n\\(p=-4\\)\n\\(p=-12\\)\n\n\n\n\n\\[\\hat w_t^1-w_t^1\\]",
    "crumbs": [
      "実験ノート"
    ]
  },
  {
    "objectID": "analysisnote.html#section-3",
    "href": "analysisnote.html#section-3",
    "title": "実験ノート",
    "section": "12/23.1",
    "text": "12/23.1\n\n概要\nデータの生成過程を変更して実験を行ったが、結果があまり変わらなかった。\n\n\n\naaa",
    "crumbs": [
      "実験ノート"
    ]
  },
  {
    "objectID": "analysisnote.html#section-4",
    "href": "analysisnote.html#section-4",
    "title": "実験ノート",
    "section": "1/6.1",
    "text": "1/6.1\n\n概要\n濾波推定値 \\(\\mathbf w_{t/t}\\) を EKF によって推論し、誤差共分散行列 \\(\\mathbf P_{t/t}\\) を変分近似で推論する手法を試した。\n通常の EKF と比較して、性能が向上すれば、EKF の誤差共分散行列の推定が不適切であることを部分的に示すことができる。\n\\[\\hat{\\mathbf w}_{t/t}=\\hat{\\mathbf w}_{t/t-1}+\\frac{1}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\mathbf P_{t/t-1}\\mathbf x_t(y_t-\\sigma_t)\\]\n\\[\\mathbf P_{t/t}=\\mathbf P_{t/t-1}-\\frac{2\\lambda(\\xi_t)}{1+2\\lambda(\\xi_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\left(\\mathbf P_{t/t-1}\\mathbf x_t\\right)\\left(\\mathbf P_{t/t-1}\\mathbf x_t\\right)^T \\]\n\\[\\xi_t=\\sqrt{\\mathbf x_t^T\\left(\\mathbf P_{t/t-1}+\\hat{\\mathbf w}_{t/t-1}\\hat{\\mathbf w}_{t/t-1}^T\\right)\\mathbf x_t}\\]\n\n\n結果\nwEXP_PVA がここで定義した手法\n\nこの手法はどのパラメータにおいても、変分近似に劣る\nEKF のばらつきが大きいパラメータにおいては、この手法はばらつきがそれほど大きくない\nEKF のばらつきは、誤差共分散行列によって引き起こされていると考えられる\n\n\n\n\n\\(\\!\\)\n\\[p=-4\\]\n\n\n\n\n\\[q=-2\\]\n\n\n\n\\[q=2\\]\n\n\n\n\\[q=4\\]",
    "crumbs": [
      "実験ノート"
    ]
  },
  {
    "objectID": "EKF/ekf.html",
    "href": "EKF/ekf.html",
    "title": "Extended Kalman Filter",
    "section": "",
    "text": "濾波推定値 \\(\\hat{\\mathbf w}_{t/t}\\) \\[\\hat{\\mathbf w}_{t/t}=\\hat{\\mathbf w}_{t/t-1}+\\frac{1}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\mathbf P_{t/t-1}\\mathbf x_t(y_t-\\sigma_t)\\]\n推定誤差共分散行列 \\(\\mathbf P_{t/t}\\) \\[\\sigma_t=\\sigma(\\hat{\\mathbf w}_{t/t-1}^T\\mathbf x_t)\\] \\[\\mathbf P_{t/t}=\\mathbf P_{t/t-1}-\\frac{\\sigma_t(1-\\sigma_t)}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}(\\mathbf P_{t/t-1}\\mathbf x_t)(\\mathbf P_{t/t-1}\\mathbf x_t)^T\\] \\[\\mathbf P_{t/t}^{-1}=\\mathbf P_{t/t-1}^{-1}+\\sigma_t(1-\\sigma_t)\\mathbf x_t\\mathbf x_t^T\\]\n各変数の情報の利用\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\!\\)\n\\(\\mathbf P_{t/t}\\)\n\\(\\hat{\\mathbf w}_{t/t}\\)\n\\(\\mathbf P_{t/t-1}\\)\n\\(\\hat{\\mathbf w}_{t/t-1}\\)\n\\(\\mathbf x_t\\)\n\\(y_t\\)\n\n\n\n\n\\(\\mathbf P_{t/t}\\)\n\\(\\!\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\n\n\\(\\hat{\\mathbf w}_{t/t}\\)\n\\(\\!\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)",
    "crumbs": [
      "非線形カルマンフィルタ",
      "Extended Kalman Filter"
    ]
  },
  {
    "objectID": "EKF/ekf.html#概要",
    "href": "EKF/ekf.html#概要",
    "title": "Extended Kalman Filter",
    "section": "",
    "text": "濾波推定値 \\(\\hat{\\mathbf w}_{t/t}\\) \\[\\hat{\\mathbf w}_{t/t}=\\hat{\\mathbf w}_{t/t-1}+\\frac{1}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\mathbf P_{t/t-1}\\mathbf x_t(y_t-\\sigma_t)\\]\n推定誤差共分散行列 \\(\\mathbf P_{t/t}\\) \\[\\sigma_t=\\sigma(\\hat{\\mathbf w}_{t/t-1}^T\\mathbf x_t)\\] \\[\\mathbf P_{t/t}=\\mathbf P_{t/t-1}-\\frac{\\sigma_t(1-\\sigma_t)}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}(\\mathbf P_{t/t-1}\\mathbf x_t)(\\mathbf P_{t/t-1}\\mathbf x_t)^T\\] \\[\\mathbf P_{t/t}^{-1}=\\mathbf P_{t/t-1}^{-1}+\\sigma_t(1-\\sigma_t)\\mathbf x_t\\mathbf x_t^T\\]\n各変数の情報の利用\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\!\\)\n\\(\\mathbf P_{t/t}\\)\n\\(\\hat{\\mathbf w}_{t/t}\\)\n\\(\\mathbf P_{t/t-1}\\)\n\\(\\hat{\\mathbf w}_{t/t-1}\\)\n\\(\\mathbf x_t\\)\n\\(y_t\\)\n\n\n\n\n\\(\\mathbf P_{t/t}\\)\n\\(\\!\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\n\n\\(\\hat{\\mathbf w}_{t/t}\\)\n\\(\\!\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)",
    "crumbs": [
      "非線形カルマンフィルタ",
      "Extended Kalman Filter"
    ]
  },
  {
    "objectID": "EKF/ekf.html#ラプラス近似による導出",
    "href": "EKF/ekf.html#ラプラス近似による導出",
    "title": "Extended Kalman Filter",
    "section": "ラプラス近似による導出",
    "text": "ラプラス近似による導出\n\n1. \\(p(\\mathbf w_t\\mid\\mathbf Y_t)\\)\n\\[\np(\\mathbf w_t\\mid \\mathbf Y_t)=\\frac{p(y_t\\mid\\mathbf w_t)p(\\mathbf w_t\\mid\\mathbf Y_{t-1})}{p(y_t\\mid\\mathbf Y_{t-1})}\n\\]\n\\[p(\\mathbf w_t\\mid\\mathbf Y_{t-1})=\\mathcal N(\\mathbf w_t\\mid\\hat{\\mathbf w}_{t/t-1},\\mathbf P_{t/t-1})\\]\nよって、\n\\[\n\\begin{equation*}\np(\\mathbf w_t\\mid \\mathbf Y_t)=\n\\begin{cases}\n\\sigma(\\mathbf w_t^T\\mathbf x_t)\\mathcal N(\\mathbf w_t\\mid\\hat{\\mathbf w}_{t/t-1},\\mathbf P_{t/t-1}) &( y_t=1) \\\\\n\\{1-\\sigma(\\mathbf w_t^T\\mathbf x_t)\\}\\mathcal N(\\mathbf w_t\\mid\\hat{\\mathbf w}_{t/t-1},\\mathbf P_{t/t-1}) & (y_t=0)\n\\end{cases}\n\\end{equation*}\n\\]\n\n\n2. \\(\\hat{\\mathbf w}_{t/t}\\)\n\\(\\mathbf w_{t}\\) をMAP推定する。 \\(\\ln p(\\mathbf w_t\\mid\\mathbf Y_t)\\) の微分を \\(\\mathbf 0\\) と置く。\n\\[\n\\begin{split}\n&\\phantom{=}\\frac{\\partial}{\\partial \\mathbf w_t}\\ln p(\\mathbf w_t\\mid\\mathbf Y_t) \\\\\n&= \\frac{\\partial}{\\partial \\mathbf w_t}\\ln\\left[\\sigma(\\mathbf w_t^T\\mathbf x_t)^{y_t}\\{1-\\sigma(\\mathbf w_t^T\\mathbf x_t)\\}^{1-y_t}\\mathcal N(\\mathbf w_t\\mid\\hat{\\mathbf w}_{t/t-1},\\mathbf P_{t/t-1})\\right] \\\\\n&= \\frac{\\partial}{\\partial \\mathbf w_t}y_t\\ln\\sigma(\\mathbf w_t^T\\mathbf x_t)+\\frac{\\partial}{\\partial\\mathbf w_t}(1-y_t)\\ln\\{1-\\sigma(\\mathbf w_t^T\\mathbf x_t)\\} \\\\\n&\\phantom{=} +\\frac{\\partial}{\\partial\\mathbf w_t}\\ln\\mathcal N(\\mathbf w_t\\mid\\hat{\\mathbf w}_{t/t-1},\\mathbf P_{t/t-1}) \\\\\n&= \\left\\{y_t-\\sigma(\\mathbf w_t^T\\mathbf x_t)\\right\\}\\mathbf x_t-\\mathbf P_{t/t-1}^{-1}(\\mathbf w_t-\\hat{\\mathbf w}_{t/t-1})\n\\end{split}\n\\]\nここで、\\(\\sigma(\\mathbf w_t^T\\mathbf x_t)\\) をテイラー展開で一次近似する。\n\\(\\sigma_t=\\sigma(\\hat{\\mathbf w}_{t/t-1}^T\\mathbf x_t)\\) とする。\n\\[\n\\begin{split}\n\\sigma(\\mathbf w_t^T\\mathbf x_t) &\\simeq \\sigma_t+\\left.\\frac{\\partial\\sigma(\\mathbf w_t^T\\mathbf x_t)}{\\partial \\mathbf w_t}\\right|_{\\mathbf w_t=\\hat{\\mathbf w}_{t/t-1}}(\\mathbf w_t-\\hat{\\mathbf w}_{t/t-1}) \\\\\n&\\phantom{00}=\\sigma_t+\\sigma_t\\{1-\\sigma_t\\}(\\mathbf w_t-\\hat{\\mathbf w}_{t/t-1})^T\\mathbf x_t\n\\end{split}\n\\]\n\\(\\sigma(\\mathbf w_t^T\\mathbf x_t)\\) を \\(\\sigma_t\\) に置き換え、\\(\\mathbf 0\\) とおく。\n\\[\n\\begin{split}\n&\\phantom{=}\\frac{\\partial}{\\partial \\mathbf w_t}\\ln p(\\mathbf w_t\\mid\\mathbf Y_t) \\\\\n&=\\left[ y_t-\\sigma_t-\\sigma_t\\left\\{1-\\sigma_t\\right\\}(\\mathbf w_t-\\hat{\\mathbf w}_{t/t-1})^T\\mathbf x_t \\right]\\mathbf x_t-\\mathbf P_{t/t-1}^{-1}(\\mathbf w_t-\\hat{\\mathbf w}_{t/t-1}) \\\\\n&=(y_t-\\sigma_t)\\mathbf x_t-\\left[\\mathbf P_{t/t-1}^{-1}+\\sigma_t(1-\\sigma_t)\\mathbf x_t\\mathbf x_t^T\\right](\\mathbf w_t-\\hat{\\mathbf w}_{t/t-1}) \\\\\n&=\\mathbf 0\n\\end{split}\n\\]\n\\[\n\\begin{split}\n\\mathbf w_t &= \\hat{\\mathbf w}_{t/t-1}+\\left[\\mathbf P_{t/t-1}^{-1}+\\sigma_t\\left\\{1-\\sigma_t\\right\\}\\mathbf x_t\\mathbf x_t^T\\right]^{-1}\\mathbf x_t(y_t-\\sigma_t) \\\\\n&=\\hat{\\mathbf w}_{t/t-1}+\\left[\\mathbf P_{t/t-1}-\\frac{\\sigma_t(1-\\sigma_t)\\mathbf P_{t/t-1}\\mathbf x_t\\mathbf x_t^T\\mathbf P_{t/t-1}}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\right]\\mathbf x_t(y_t-\\sigma_t) \\\\\n&=\\hat{\\mathbf w}_{t/t-1}+\\left[\\mathbf P_{t/t-1}\\mathbf x_t-\\frac{\\sigma_t(1-\\sigma_t)\\mathbf P_{t/t-1}\\mathbf x_t\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\right](y_t-\\sigma_t) \\\\\n&=\\hat{\\mathbf w}_{t/t-1}+\\left[1-\\frac{\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\right]\\mathbf P_{t/t-1}\\mathbf x_t(y_t-\\sigma_t) \\\\\n&=\\hat{\\mathbf w}_{t/t-1}+\\frac{1}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\mathbf P_{t/t-1}\\mathbf x_t(y_t-\\sigma_t)\n\\end{split}\n\\]\nよって \\(\\mathbf w_t\\) のMAP推定値 \\(\\hat{\\mathbf w}_{t/t}\\) は\n\\[\\hat{\\mathbf w}_{t/t}=\\hat{\\mathbf w}_{t/t-1}+\\frac{1}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\mathbf P_{t/t-1}\\mathbf x_t(y_t-\\sigma_t)\\]\nとなる。\n\n\n3. \\(\\mathbf P_{t/t}\\)\n\\(\\hat{\\mathbf w}_{t/t-1}\\) を \\(p(\\mathbf w_t\\mid\\mathbf Y_t)\\) のピークとすると \\(\\mathbf P_{t/t}\\) が得られる。\n（ \\(\\hat{\\mathbf w}_{t/t}\\) をピークとするのが本来のラプラス近似）\n\\[\n\\begin{split}\n\\mathbf P_{t/t}^{-1} &= \\left.-\\frac{\\partial^2}{\\partial\\mathbf w_t^2} \\ln p(\\mathbf w_t\\mid\\mathbf Y_t)\\right|_{\\mathbf w_t=\\hat{\\mathbf w}_{t/t-1}} \\\\\n&= \\left. -\\frac{\\partial}{\\partial\\mathbf w_t}\\left[\\left\\{y_t-\\sigma(\\mathbf w_t^T\\mathbf x_t)\\right\\}\\mathbf x_t-\\mathbf P_{t/t-1}^{-1}(\\mathbf w_t-\\hat{\\mathbf w}_{t/t-1})\\right]\\right|_{\\mathbf w_t=\\hat{\\mathbf w}_{t/t-1}} \\\\\n&= \\mathbf P_{t/t-1}^{-1}+\\sigma_t(1-\\sigma_t)\\mathbf x_t\\mathbf x_t^T\n\\end{split}\n\\]\nSherman-Morrison の公式によって、 \\(\\mathbf P_{t/t}\\) が得られる。\n\\[\n\\mathbf P_{t/t}=\\mathbf P_{t/t-1}-\\frac{\\sigma_t(1-\\sigma_t)}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}(\\mathbf P_{t/t-1}\\mathbf x_t)(\\mathbf P_{t/t-1}\\mathbf x_t)^T\n\\]",
    "crumbs": [
      "非線形カルマンフィルタ",
      "Extended Kalman Filter"
    ]
  },
  {
    "objectID": "EKF/ekf.html#関数等",
    "href": "EKF/ekf.html#関数等",
    "title": "Extended Kalman Filter",
    "section": "関数等",
    "text": "関数等\n\nsource\n\nPtt\n\ndef Ptt(\n    Ptm:Float[Array, 'N N'], # $\\mathbf P_{t/t-1}$\n    w:Float[Array, 'N'], # $\\hat{\\mathbf w}_{t/t-1}$\n    x:Float[Array, 'N'], # $\\mathbf x_t$\n)-&gt;Float[Array, 'N N']: # $\\mathbf P_{t/t}$\n\n*\\(\\!\\)** 推定誤差共分散行列 \\(\\mathbf P_{t/t}\\) \\[\\sigma_t=\\sigma(\\hat{\\mathbf w}_{t/t-1}^T\\mathbf x_t)\\] \\[\\mathbf P_{t/t}=\\mathbf P_{t/t-1}-\\frac{\\sigma_t(1-\\sigma_t)}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}(\\mathbf P_{t/t-1}\\mathbf x_t)(\\mathbf P_{t/t-1}\\mathbf x_t)^T\\] *\\(\\!\\)\n\nsource\n\n\nwtt\n\ndef wtt(\n    Ptm:Float[Array, 'N N'], # $\\mathbf P_{t/t-1}$\n    w:Float[Array, 'N'], # $\\hat{\\mathbf w}_{t/t-1}$\n    x:Float[Array, 'N'], # $\\mathbf x_t$\n    y:Float[Array, 'N'], # $y_t$\n)-&gt;Float[Array, 'N']: # $\\hat{\\mathbf w}_{t/t}$\n\n*\\(\\!\\)** 濾波推定値 \\(\\hat{\\mathbf w}_{t/t}\\) \\[\\hat{\\mathbf w}_{t/t}=\\hat{\\mathbf w}_{t/t-1}+\\frac{1}{1+\\sigma_t(1-\\sigma_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\mathbf P_{t/t-1}\\mathbf x_t(y_t-\\sigma_t)\\] *\\(\\!\\)\n\nsource\n\n\nEKF_out\n\ndef EKF_out(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\n*\\(\\!\\)** EKF 関数の返り値\n\n\n\n\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nW\nFloat[Array, ‘T N’]\n\\(\\{\\hat{\\mathbf w}_{t/t}\\}_{t=0,\\ldots,T-1}\\)\n\n\nP\nFloat[Array, ‘T N N’]\n\\(\\{\\mathbf P_{t/t}\\}_{t=0,\\ldots,T-1}\\)\n\n\n\n*\\(\\!\\)\n\nsource\n\n\nEKF\n\ndef EKF(\n    N:int, # $N$\n    T:int, # $T$\n    x:Float[Array, '{T} {N}'], # $\\{ \\mathbf x_t \\}_{t=0,\\ldots,T-1}$\n    y:Float[Array, '{T} {N}'], # $\\{ y_t \\}_{t=0,\\ldots,T-1}$\n    G:Float[Array, '{N} {N}'], # $\\boldsymbol\\Gamma$\n    w0:Float[Array, '{N}'], # $\\hat{\\mathbf w}_{0/-1}$\n    P0:Float[Array, '{N} {N}'], # $\\mathbf P_{0/-1}$\n)-&gt;EKF_out:\n\n*\\(\\!\\)** 拡張カルマンフィルタ *\\(\\!\\)\n\n# assume sp.losi, sp.dxlosi exist (sigmoid and its derivative)\n\n# --- helper: Mackay's K(s) and derivative K'(s) (eq.9 and eq.68 in paper) ---\n@jax.jit\ndef K_of_s(s: Float[Array, \"\"]):\n  # K(s) = (1 + s^2 / 8)^(-1/2)\n  return (1.0 + (s**2) / 8.0) ** (-0.5)\n\n@jax.jit\ndef Kprime_of_s(s: Float[Array, \"\"]):\n  # K'(s) = - (s / 8) * (1 + s^2 / 8)^(-3/2)\n  return -(s / 8.0) * (1.0 + (s**2) / 8.0) ** (-1.5)\n\n# --- Nonstationary EKF runner ---\nclass NS_EKF_Out(NamedTuple):\n  W: Float[Array, \"T N\"]\n  P: Float[Array, \"T N N\"]\n  q: Float[Array, \"T\"]   # tracked q_t per time step\n\n@partial(jax.jit, static_argnames=['N','T','Nw'])\ndef EKF_nonstationary(\n    N: int,\n    T: int,\n    x: Float[Array, \"{T} {N}\"],  # inputs sequence\n    y: Float[Array, \"{T}\"],      # scalar class labels (0/1) per t\n    w0: Float[Array, \"{N}\"],     # initial w_{0/-1}\n    P0: Float[Array, \"{N} {N}\"], # initial P_{0/-1}\n    q0: float = 1e-6,            # initial state-noise variance\n    eta_q: float = 1e-3,         # learning rate for q updates\n    Nw: int = 50,                # window size for q gradient estimation\n    q_min: float = 0.0,\n    q_max: float = 1.0\n) -&gt; NS_EKF_Out:\n  r\"\"\"\n  Nonstationary EKF:\n  - uses Q_t = q_t * I\n  - updates q_t by gradient-ascent (average gradient over window of length Nw)\n    based on Appendix E (eq.70) in the provided paper. See: dynamic logistic regression.pdf. :contentReference[oaicite:1]{index=1}\n  \"\"\"\n\n  I = jnp.eye(N)\n\n  class Carry(NamedTuple):\n    Ptm: Float[Array, \"{N} {N}\"]  # P_{t/t-1}\n    wtm: Float[Array, \"{N}\"]      # w_{t/t-1}\n    q_t: Float[Array, \"\"]         # current scalar q_t\n    buf_Ptm: Float[Array, \"{Nw} {N} {N}\"]  # circular buffer of past Ptm (for gradient)\n    buf_x: Float[Array, \"{Nw} {N}\"]        # buffer of past x\n    buf_y: Float[Array, \"{Nw}\"]            # buffer of past y\n    buf_idx: int                          # next write index (0..Nw-1)\n    buf_count: int                        # how many entries filled (&lt;= Nw)\n\n  class Input(NamedTuple):\n    xt: Float[Array, \"{N}\"]\n    yt: Float[Array, \"\"]\n\n  class Output(NamedTuple):\n    wtt_: Float[Array, \"{N}\"]\n    Ptt_: Float[Array, \"{N} {N}\"]\n    q_: Float[Array, \"\"]\n\n  # initialize buffers with zeros\n  init_buf_Ptm = jnp.zeros((Nw, N, N))\n  init_buf_x = jnp.zeros((Nw, N))\n  init_buf_y = jnp.zeros((Nw,))\n\n  def compute_q_gradient_from_buffer(buf_Ptm, buf_x, buf_y, buf_count, q_current, w_current):\n    \"\"\"\n    Compute average gradient of log-evidence w.r.t q over buffer entries (use eq.70-like form).\n    We follow the derivation in appendix E: grad ≈ (z - ~y) * a * K'(s) * (x^T x) / (2 s^2)\n    where s^2 = x^T (Ptm + q I) x, ~y = sigmoid(K(s) * a), a = w^T x (activation using previous w).\n    \"\"\"\n    def per_sample_grad(carry, elems):\n      # elems: (Ptm_i, x_i, y_i)\n      Ptm_i, x_i, y_i = elems\n      Pprior = Ptm_i + q_current * I      # P_{t/t-1} + Q_t\n      s2 = x_i @ (Pprior @ x_i)           # scalar\n      # prevent tiny s2 -&gt; numerical issues\n      s2_safe = jnp.maximum(s2, 1e-12)\n      s = jnp.sqrt(s2_safe)\n      K = K_of_s(s)\n      Kp = Kprime_of_s(s)\n      a = w_current @ x_i                 # activation using current w (approx)\n      y_tilde = sp.losi(K * a)            # moderated prediction ~y\n      xTx = x_i @ x_i\n      grad = (y_i - y_tilde) * a * Kp * xTx / (2.0 * s2_safe)\n      return carry, grad\n\n    # only iterate over the first buf_count entries\n    elems = (buf_Ptm[:buf_count], buf_x[:buf_count], buf_y[:buf_count])\n    _, grads = lax.scan(per_sample_grad, None, elems)\n    # mean gradient\n    mean_grad = jnp.mean(grads) if buf_count &gt; 0 else 0.0\n    return mean_grad\n\n  def step(carry: Carry, inputs: Input) -&gt; Tuple[Carry, Output]:\n    Ptm, wtm, q_t, buf_Ptm, buf_x, buf_y, buf_idx, buf_count = carry\n    xt, yt = inputs\n\n    # EKF update using current Ptm and wtm (same functions as user's originals)\n    Ptt_ = Ptt(Ptm, wtm, xt)   # P_{t/t} (uses sp.dxlosi etc.)\n    wtt_ = wtt(Ptm, wtm, xt, yt)\n\n    # next predicted P_{(t+1)/t} = P_{t/t} + Q_t where Q_t = q_t * I\n    Pnext = Ptt_ + q_t * I\n\n    # update circular buffers: write current Ptm, xt, yt\n    buf_Ptm = buf_Ptm.at[buf_idx].set(Ptm)\n    buf_x   = buf_x.at[buf_idx].set(xt)\n    buf_y   = buf_y.at[buf_idx].set(yt)\n    buf_idx_next = (buf_idx + 1) % buf_Ptm.shape[0]\n    buf_count_next = jnp.minimum(buf_count + 1, buf_Ptm.shape[0])\n\n    # compute q gradient and update q every step (could be done every M steps)\n    grad_q = compute_q_gradient_from_buffer(buf_Ptm, buf_x, buf_y, buf_count_next, q_t, wtm)\n    q_new = q_t + eta_q * grad_q\n    q_new = jnp.clip(q_new, q_min, q_max)\n\n    new_carry = Carry(Pnext, wtt_, q_new, buf_Ptm, buf_x, buf_y, buf_idx_next, buf_count_next)\n    out = Output(wtt_, Ptt_, q_new)\n    return new_carry, out\n\n  # initial carry: P0 is prior P_{0/-1} already; w0 is w_{0/-1}\n  init_carry = Carry(P0, w0, jnp.array(q0), init_buf_Ptm, init_buf_x, init_buf_y, 0, 0)\n\n  _, outputs = lax.scan(step, init_carry, Input(x, y), length=T)\n\n  W = outputs.wtt_\n  P = outputs.Ptt_\n  q_seq = outputs.q_\n  return NS_EKF_Out(W, P, q_seq)",
    "crumbs": [
      "非線形カルマンフィルタ",
      "Extended Kalman Filter"
    ]
  },
  {
    "objectID": "wEXP_PVA/wexp_pva.html",
    "href": "wEXP_PVA/wexp_pva.html",
    "title": "w:EXP, P:VA",
    "section": "",
    "text": "source\n\nwEXP_PVA_out\n\ndef wEXP_PVA_out(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\n*\\(\\!\\)** wEXP_PVA 関数の返り値\n\n\n\n\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nW\nFloat[Array, ‘T N’]\n\\(\\{\\hat{\\mathbf w}_{t/t}\\}_{t=0,\\ldots,T-1}\\)\n\n\nP\nFloat[Array, ‘T N N’]\n\\(\\{\\mathbf P_{t/t}\\}_{t=0,\\ldots,T-1}\\)\n\n\nXi\nFloat[Array, ‘T’]\n\\(\\{\\xi_t\\}_{t=0,\\ldots,T-1}\\)\n\n\n\n*\\(\\!\\)\n\nsource\n\n\nwEXP_PVA\n\ndef wEXP_PVA(\n    N:int, # $N$\n    T:int, # $T$\n    x:Float[Array, '{T} {N}'], # $\\{ \\mathbf x_t \\}_{t=0,\\ldots,T-1}$\n    y:Float[Array, '{T}'], # $\\{ y_t \\}_{t=0,\\ldots,T-1}$\n    G:Float[Array, '{N} {N}'], # $\\boldsymbol\\Gamma$\n    w0:Float[Array, '{N}'], # $\\hat{\\mathbf w}_{0/-1}$\n    P0:Float[Array, '{N} {N}'], # $\\mathbf P_{0/-1}$\n)-&gt;wEXP_PVA_out:\n\n*\\(\\!\\)** \\(\\mathbf w_{t/t}\\) を EKF によって推論し、\\(\\mathbf P_{t/t}\\) を VA によって推論する手法 \\(\\xi_t\\) には一段予測推定値 \\(\\hat{\\mathbf w}_{t/t-1}\\) を使う \\[\\xi_t=\\sqrt{\\mathbf x_t^T\\left(\\mathbf P_{t/t-1}+\\hat{\\mathbf w}_{t/t-1}\\hat{\\mathbf w}_{t/t-1}^T\\right)\\mathbf x_t}\\] *\\(\\!\\)",
    "crumbs": [
      "EKFとVAの合成",
      "w:EXP, P:VA"
    ]
  },
  {
    "objectID": "Exp/keybatch.html",
    "href": "Exp/keybatch.html",
    "title": "key によるバッチ化",
    "section": "",
    "text": "---\nskip_showdoc: true\n---\n\n\nN=2\nT=1000 \nG =  1/2**7 * jnp.identity(N, dtype=jnp.float32)\nSigma = 1.5 * jnp.identity(N, dtype=jnp.float32)\nw0 = 0*jnp.ones((N,), dtype=jnp.float32)/jnp.sqrt(N)\nP0 = G\npropy1 = 0.5\n\nbatched_exper = jax.vmap(\n  lambda key: Comp.RMS(key, N, T, G, w0, Sigma, P0, propy1)\n)\n\nmaster_key = jrd.PRNGKey(0)\nkeys = jrd.split(master_key, 1000)\n\nW_norms, RMS_EKF, RMS_VA, RMS_EM = batched_exper(keys)\n\n\nplt.scatter(W_norms.reshape(-1), RMS_EKF.reshape(-1))\nplt.scatter(W_norms.reshape(-1), RMS_VA.reshape(-1), marker=\"x\")\nplt.scatter(W_norms.reshape(-1), RMS_EM.reshape(-1), marker=\".\")\n\n\n\n\n\n\n\n\n\n# bin の定義\nbins = jnp.arange(0.1, 12, 0.1)\nbin_edges = jnp.arange(0.0, 12.1, 0.1)  # 例: [0.0, 0.1, 0.2, ..., 12.0]\n\n# 各要素が属するビンを計算 (1~len(bins) のインデックス)\nbin_idx = jnp.digitize(W_norms.ravel(), bin_edges) - 1  # shape (T*N,)\n\n# フラット化\nekf_flat = RMS_EKF.ravel()\nva_flat  = RMS_VA.ravel()\nem_flat = RMS_EM.ravel()\n\n# 各 bin ごとの総和とカウントを計算\nsum_ekf = jnp.bincount(bin_idx, weights=ekf_flat, length=len(bins))\nsum_va  = jnp.bincount(bin_idx, weights=va_flat,  length=len(bins))\nsum_em  = jnp.bincount(bin_idx, weights=em_flat,  length=len(bins))\ncounts  = jnp.bincount(bin_idx, length=len(bins))\n\n# 平均を計算（ゼロ除算防止）\nmean_ekf = jnp.where(counts &gt; 0, sum_ekf / counts, jnp.nan)\nmean_va  = jnp.where(counts &gt; 0, sum_va / counts, jnp.nan)\nmean_em  = jnp.where(counts &gt; 0, sum_em / counts, jnp.nan)\n\n# 最終結果をまとめる\ndf_source = jnp.stack([bins, mean_ekf, mean_va, mean_em], axis=1)\n\n# Pandas DataFrame に変換（必要なら）\ndf = pd.DataFrame(jnp.array(df_source), columns=[\"bin\", \"EKF_RMS\", \"VA_RMS\", \"EM_RMS\"]).set_index(\"bin\")\n\n\ndf[0.8:10].head(20)\n\n\n\n\n\n\n\n\nEKF_RMS\nVA_RMS\nEM_RMS\n\n\nbin\n\n\n\n\n\n\n\n0.8\n0.742320\n0.743473\n0.743350\n\n\n0.9\n0.839010\n0.841791\n0.841518\n\n\n1.0\n0.924905\n0.927862\n0.927469\n\n\n1.1\n1.016297\n1.020453\n1.019893\n\n\n1.2\n1.105977\n1.110465\n1.109501\n\n\n1.3\n1.174655\n1.180493\n1.179403\n\n\n1.4\n1.252368\n1.259346\n1.257725\n\n\n1.5\n1.327946\n1.335311\n1.333957\n\n\n1.6\n1.379003\n1.375262\n1.373536\n\n\n1.7\n1.458880\n1.461715\n1.460669\n\n\n1.8\n1.502239\n1.492858\n1.491333\n\n\n1.9\n1.553879\n1.537835\n1.536580\n\n\n2.0\n1.609895\n1.585574\n1.583595\n\n\n2.1\n1.650254\n1.615584\n1.614009\n\n\n2.2\n1.710323\n1.670204\n1.669090\n\n\n2.3\n1.770196\n1.712925\n1.711877\n\n\n2.4\n1.830160\n1.768064\n1.767073\n\n\n2.5\n1.889573\n1.808915\n1.808709\n\n\n2.6\n1.922787\n1.830989\n1.830768\n\n\n2.7\n1.968957\n1.869247\n1.869909\n\n\n\n\n\n\n\n\ndf[:2.7].plot()\n\n\n\n\n\n\n\n\n\nN=10\nT=1000 \nG =  1/2**9 * jnp.identity(N, dtype=jnp.float32)\nSigma = 0.5 * jnp.identity(N, dtype=jnp.float32)\nw0 = 0*jnp.ones((N,), dtype=jnp.float32)/jnp.sqrt(N)\nP0 = G\npropy1 = 0.5\n\nbatched_exper = jax.vmap(\n  lambda key: Comp.losi_error(key, N, T, G, w0, Sigma, P0, propy1)\n)\n\nmaster_key = jrd.PRNGKey(0)\nkeys = jrd.split(master_key, 1000)\n\nRMS_EKF, RMS_VA, RMS_EM = batched_exper(keys)\n\n\nRMS_EKF.sum(), RMS_VA.sum(), RMS_EM.sum()\n\n(Array(1.0641768e+07, dtype=float32),\n Array(8.087362e+06, dtype=float32),\n Array(8.100394e+06, dtype=float32))\n\n\n\nNs = [2, 4, 8]\nGs = jnp.array([1/2**4, 1/2**6, 1/2**8, 1/2**10, 1/2**12])\nSigmas = jnp.array([1/2**2, 1/2, 1, 2, 4, 8])\npropy1s = jnp.array([0.5, 0.1])\n\nimport pandas as pd\n\n# 最初に空の DataFrame を用意\ndf = pd.DataFrame(columns=[\"N\", \"G\", \"Sigma\", \"propy1\", \"err_EKF_sc\", \"err_VA_sc\", \"err_EM_sc\"])\n\nfor N in Ns:\n  print(\"N\", N)\n  for G_ in Gs:\n    print(\"G\", G_)\n    for Sigma_ in Sigmas:\n      for propy1 in propy1s:\n        T = 1000\n        G = G_ * jnp.identity(N, dtype=jnp.float32)\n        Sigma = Sigma_ * jnp.identity(N, dtype=jnp.float32)\n        w0 = 0*jnp.ones((N,), dtype=jnp.float32)/jnp.sqrt(N)\n        P0 = G\n        batched_exper = jax.vmap(\n          lambda key: Comp.losi_error(key, N, T, G, w0, Sigma, P0, propy1),\n          in_axes=(0,)\n        )\n        master_key = jrd.PRNGKey(0)\n        keys = jrd.split(master_key, 1000)\n\n        err_EKF, err_VA, err_EM = batched_exper(keys)\n\n        err_EKF_sc = jnp.sqrt(err_EKF.mean())\n        err_VA_sc = jnp.sqrt(err_VA.mean())\n        err_EM_sc = jnp.sqrt(err_EM.mean())\n\n        # pandas df に追加\n        df.loc[len(df)] = [\n            int(N),\n            float(G_),\n            float(Sigma_),\n            float(propy1),\n            float(err_EKF_sc),\n            float(err_VA_sc),\n            float(err_EM_sc)\n        ]\n\nprint(df.head())\n\nN 2\nG 0.0625\nG 0.015625\nG 0.00390625\nG 0.0009765625\nG 0.00024414062\nN 4\nG 0.0625\nG 0.015625\nG 0.00390625\nG 0.0009765625\nG 0.00024414062\nN 8\nG 0.0625\nG 0.015625\nG 0.00390625\nG 0.0009765625\nG 0.00024414062\n     N       G  Sigma  propy1  err_EKF_sc  err_VA_sc  err_EM_sc\n0  2.0  0.0625   0.25     0.5    0.092954   0.093325   0.093123\n1  2.0  0.0625   0.25     0.1    0.092736   0.093197   0.092990\n2  2.0  0.0625   0.50     0.5    0.093420   0.093336   0.093043\n3  2.0  0.0625   0.50     0.1    0.093356   0.093240   0.092941\n4  2.0  0.0625   1.00     0.5    0.093443   0.091697   0.091294\n\n\n\n\n\n\n\n\n\n\n\n\nN\nG\nSigma\npropy1\nerr_EKF_sc\nerr_VA_sc\nerr_EM_sc\n\n\n\n\n2\n2.0\n0.062500\n0.50\n0.5\n0.093420\n0.093336\n0.093043\n\n\n4\n2.0\n0.062500\n1.00\n0.5\n0.093443\n0.091697\n0.091294\n\n\n6\n2.0\n0.062500\n2.00\n0.5\n0.093836\n0.089228\n0.088805\n\n\n8\n2.0\n0.062500\n4.00\n0.5\n0.094327\n0.086147\n0.085870\n\n\n10\n2.0\n0.062500\n8.00\n0.5\n0.096139\n0.082455\n0.082723\n\n\n18\n2.0\n0.015625\n2.00\n0.5\n0.093420\n0.093336\n0.093043\n\n\n20\n2.0\n0.015625\n4.00\n0.5\n0.093443\n0.091697\n0.091294\n\n\n22\n2.0\n0.015625\n8.00\n0.5\n0.093836\n0.089228\n0.088805\n\n\n34\n2.0\n0.003906\n8.00\n0.5\n0.093420\n0.093336\n0.093043\n\n\n48\n2.0\n0.000244\n0.25\n0.5\n0.039164\n0.039163\n0.039163\n\n\n60\n4.0\n0.062500\n0.25\n0.5\n0.100617\n0.099913\n0.099700\n\n\n62\n4.0\n0.062500\n0.50\n0.5\n0.093656\n0.091329\n0.091214\n\n\n64\n4.0\n0.062500\n1.00\n0.5\n0.085952\n0.080761\n0.080898\n\n\n66\n4.0\n0.062500\n2.00\n0.5\n0.078222\n0.070136\n0.070658\n\n\n68\n4.0\n0.062500\n4.00\n0.5\n0.072354\n0.060668\n0.061745\n\n\n70\n4.0\n0.062500\n8.00\n0.5\n0.064038\n0.051949\n0.053414\n\n\n76\n4.0\n0.015625\n1.00\n0.5\n0.100617\n0.099913\n0.099700\n\n\n78\n4.0\n0.015625\n2.00\n0.5\n0.093656\n0.091329\n0.091214\n\n\n80\n4.0\n0.015625\n4.00\n0.5\n0.085952\n0.080761\n0.080898\n\n\n82\n4.0\n0.015625\n8.00\n0.5\n0.078222\n0.070136\n0.070658\n\n\n92\n4.0\n0.003906\n4.00\n0.5\n0.100617\n0.099913\n0.099700\n\n\n94\n4.0\n0.003906\n8.00\n0.5\n0.093656\n0.091329\n0.091214\n\n\n120\n8.0\n0.062500\n0.25\n0.5\n0.096732\n0.091938\n0.092006\n\n\n122\n8.0\n0.062500\n0.50\n0.5\n0.083484\n0.076024\n0.076319\n\n\n124\n8.0\n0.062500\n1.00\n0.5\n0.071028\n0.062117\n0.062546\n\n\n126\n8.0\n0.062500\n2.00\n0.5\n0.059638\n0.050017\n0.050485\n\n\n128\n8.0\n0.062500\n4.00\n0.5\n0.048867\n0.039920\n0.040344\n\n\n130\n8.0\n0.062500\n8.00\n0.5\n0.038852\n0.031403\n0.031772\n\n\n132\n8.0\n0.015625\n0.25\n0.5\n0.120174\n0.119479\n0.119283\n\n\n134\n8.0\n0.015625\n0.50\n0.5\n0.109672\n0.107326\n0.107210\n\n\n136\n8.0\n0.015625\n1.00\n0.5\n0.096732\n0.091938\n0.092006\n\n\n138\n8.0\n0.015625\n2.00\n0.5\n0.083484\n0.076024\n0.076319\n\n\n140\n8.0\n0.015625\n4.00\n0.5\n0.071028\n0.062117\n0.062546\n\n\n142\n8.0\n0.015625\n8.00\n0.5\n0.059638\n0.050017\n0.050485\n\n\n146\n8.0\n0.003906\n0.50\n0.5\n0.125066\n0.124960\n0.124792\n\n\n148\n8.0\n0.003906\n1.00\n0.5\n0.120174\n0.119479\n0.119283\n\n\n150\n8.0\n0.003906\n2.00\n0.5\n0.109672\n0.107326\n0.107210\n\n\n152\n8.0\n0.003906\n4.00\n0.5\n0.096732\n0.091938\n0.092006\n\n\n154\n8.0\n0.003906\n8.00\n0.5\n0.083484\n0.076024\n0.076319\n\n\n156\n8.0\n0.000977\n0.25\n0.5\n0.104002\n0.103998\n0.103986\n\n\n162\n8.0\n0.000977\n2.00\n0.5\n0.125066\n0.124960\n0.124792\n\n\n164\n8.0\n0.000977\n4.00\n0.5\n0.120174\n0.119479\n0.119283\n\n\n166\n8.0\n0.000977\n8.00\n0.5\n0.109672\n0.107326\n0.107210\n\n\n168\n8.0\n0.000244\n0.25\n0.5\n0.076621\n0.076618\n0.076616\n\n\n170\n8.0\n0.000244\n0.50\n0.5\n0.090635\n0.090629\n0.090625\n\n\n172\n8.0\n0.000244\n1.00\n0.5\n0.104002\n0.103998\n0.103986\n\n\n178\n8.0\n0.000244\n8.00\n0.5\n0.125066\n0.124960\n0.124792\n\n\n\n\n\n\n\n\ndf.groupby(\"propy1\").mean()\n\n\n\n\n\n\n\n\nN\nG\nSigma\nerr_EKF_sc\nerr_VA_sc\nerr_EM_sc\n\n\npropy1\n\n\n\n\n\n\n\n\n\n\n0.1\n4.666667\n0.01665\n2.625\n0.090087\n0.087966\n0.087953\n\n\n0.5\n4.666667\n0.01665\n2.625\n0.090186\n0.088121\n0.088114\n\n\n\n\n\n\n\n\ndf1 = df[df[\"propy1\"] == 0.5][[\"N\", \"G\", \"Sigma\", \"err_EKF_sc\", \"err_VA_sc\", \"err_EM_sc\"]]\n\n\ndf1.shape\n\n(90, 7)\n\n\n損失関数と同じ評価関数\n\\[E=\\|\\hat{\\mathbf w}_{t} - \\mathbf w_t\\|^2\\]\n新たに導入した評価関数: \\[E=\\sqrt{\\frac{1}{T}\\sum_t^T\\left(\\left[\\sigma(\\mathbf w_t^T\\mathbf x_t) - \\sigma(\\hat{\\mathbf w}_{t-1}^T\\mathbf x_t)\\right]^2\\right)}\\]\n\n次元数 \\(N\\) に関しての比較\n90 個のデータのうち、変分近似が拡張カルマンフィルタよりも \\(E\\) が大きかったデータは - \\(N=2\\) : 20/30 - \\(N=4\\) : 18/30 - \\(N=8\\) : 5/30\n\ndf1[(df1[\"err_EKF_sc\"] &lt; df1[\"err_VA_sc\"])].groupby(\"N\").count()\n\n\n\n\n\n\n\n\nG\nSigma\nerr_EKF_sc\nerr_VA_sc\nerr_EM_sc\n\n\nN\n\n\n\n\n\n\n\n\n\n2.0\n20\n20\n20\n20\n20\n\n\n4.0\n18\n18\n18\n18\n18\n\n\n8.0\n5\n5\n5\n5\n5\n\n\n\n\n\n\n\n遷移行列 \\(\\boldsymbol\\Gamma=pI\\) に関しての比較 90 個のデータのうち、変分近似が拡張カルマンフィルタよりも \\(E\\) が大きかったデータは [1/24, 1/26, 1/28, 1/210, 1/2**12] - \\(p = 1/2^{12}\\) : 13/18 - \\(p = 1/2^{10}\\) : 14/18 - \\(p = 1/2^8\\) : 10/18 - \\(p = 1/2^6\\) : 5/18 - \\(p = 1/2^4\\) : 1/18\n\ndf1[(df1[\"err_EKF_sc\"] &lt; df1[\"err_VA_sc\"])].groupby(\"G\").count()\n\n\n\n\n\n\n\n\nN\nSigma\nerr_EKF_sc\nerr_VA_sc\nerr_EM_sc\n\n\nG\n\n\n\n\n\n\n\n\n\n0.000244\n13\n13\n13\n13\n13\n\n\n0.000977\n14\n14\n14\n14\n14\n\n\n0.003906\n10\n10\n10\n10\n10\n\n\n0.015625\n5\n5\n5\n5\n5\n\n\n0.062500\n1\n1\n1\n1\n1\n\n\n\n\n\n\n\n\\(\\mathbf x_t\\) の共分散行列 \\(\\Sigma=qI\\) に関しての比較 [1/2**2, 1/2, 1, 2, 4, 8] - \\(q = 1/2^2\\) : 9/15 - \\(q = 1/2\\) : 9/15 - \\(q = 1\\) : 8/15 - \\(q = 2\\) : 7/15 - \\(q = 4\\) : 6/15 - \\(q = 8\\) : 4/15\n\ndf1[(df1[\"err_EKF_sc\"] &lt; df1[\"err_VA_sc\"])].groupby(\"Sigma\").count()\n\n\n\n\n\n\n\n\nN\nG\nerr_EKF_sc\nerr_VA_sc\nerr_EM_sc\n\n\nSigma\n\n\n\n\n\n\n\n\n\n0.25\n9\n9\n9\n9\n9\n\n\n0.50\n9\n9\n9\n9\n9\n\n\n1.00\n8\n8\n8\n8\n8\n\n\n2.00\n7\n7\n7\n7\n7\n\n\n4.00\n6\n6\n6\n6\n6\n\n\n8.00\n4\n4\n4\n4\n4\n\n\n\n\n\n\n\n\ndf1[[\"G\", \"err_EKF_sc\", \"err_VA_sc\", \"err_EM_sc\"]].groupby(\"G\").mean().plot()\n\n\n\n\n\n\n\n\n\ndf1[[\"Sigma\", \"err_EKF_sc\", \"err_VA_sc\", \"err_EM_sc\"]].groupby(\"Sigma\").mean().plot()\n\n\n\n\n\n\n\n\n\ndf1[[\"N\", \"err_EKF_sc\", \"err_VA_sc\", \"err_EM_sc\"]].groupby(\"N\").mean().plot()",
    "crumbs": [
      "実験関数",
      "key によるバッチ化"
    ]
  },
  {
    "objectID": "Exp/index.html",
    "href": "Exp/index.html",
    "title": "実験関数",
    "section": "",
    "text": "実験用の関数等。Jax による並列化など。\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\n\n\n\n\n\n実験\n\n\nTest\n\n\n\n\n\n\n評価\n\n\nTest\n\n\n\n\n\n\nkey によるバッチ化\n\n\nTest\n\n\n\n\n\n\n実験関数\n\n\nYAML ファイルの生成等\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "実験関数"
    ]
  },
  {
    "objectID": "MinimizeRegrex/index.html",
    "href": "MinimizeRegrex/index.html",
    "title": "リグレット最小化",
    "section": "",
    "text": "リグレット最小化。\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\n\n\n\n\n\nRegret 最小化の概要\n\n\n概要\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "リグレット最小化"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KalmanPaper",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "KalmanPaper"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "KalmanPaper",
    "section": "Developer Guide",
    "text": "Developer Guide\nIf you are new to using nbdev here are some useful pointers to get you started.\n\nInstall KalmanPaper in Development mode\n# make sure KalmanPaper package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to KalmanPaper\n$ nbdev_prepare",
    "crumbs": [
      "KalmanPaper"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "KalmanPaper",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/SuzuSys/KalmanPaper.git\nor from conda\n$ conda install -c SuzuSys KalmanPaper\nor from pypi\n$ pip install KalmanPaper\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repository’s pages. Additionally you can find package manager specific guidelines on conda and pypi respectively.",
    "crumbs": [
      "KalmanPaper"
    ]
  },
  {
    "objectID": "VA/index.html",
    "href": "VA/index.html",
    "title": "変分近似",
    "section": "",
    "text": "変分近似を取り入れた手法。\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\n\n\n\n\n\n変分近似の概要\n\n\n概要\n\n\n\n\n\n\nVariational Approximation\n\n\n変分近似\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "変分近似"
    ]
  },
  {
    "objectID": "VA/va.html",
    "href": "VA/va.html",
    "title": "Variational Approximation",
    "section": "",
    "text": "濾波推定値 \\(\\hat{\\mathbf w}_{t/t}\\) \\[\\hat{\\mathbf w}_{t/t}=\\mathbf P_{t/t}\\left(\\mathbf P_{t/t-1}^{-1}\\hat{\\mathbf w}_{t/t-1}+(y_t-1/2)\\mathbf x_t\\right)\\]\n推定誤差共分散行列 \\(\\mathbf P_{t/t}\\)\n\\[\\mathbf P_{t/t}=\\mathbf P_{t/t-1}-\\frac{2\\lambda(\\xi_t)}{1+2\\lambda(\\xi_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\left(\\mathbf P_{t/t-1}\\mathbf x_t\\right)\\left(\\mathbf P_{t/t-1}\\mathbf x_t\\right)^T \\]\n\\[\\mathbf P_{t/t}^{-1}=\\mathbf P_{t/t-1}^{-1}+2\\lambda(\\xi_t)\\mathbf x_t\\mathbf x_t^T\\]\n一段予測推定値 \\(\\hat{\\mathbf w}_{t/t-1}\\) を使う変分パラメータ (pre) \\[\\xi_t=\\sqrt{\\mathbf x_t^T\\left(\\mathbf P_{t/t-1}+\\hat{\\mathbf w}_{t/t-1}\\hat{\\mathbf w}_{t/t-1}^T\\right)\\mathbf x_t}\\]\n濾波推定値 \\(\\hat{\\mathbf w}_{t/t}\\) を使う変分パラメータ (EM) \\[\\xi_t=\\sqrt{\\mathbf x_t^T\\left(\\mathbf P_{t/t}+\\hat{\\mathbf w}_{t/t}\\hat{\\mathbf w}_{t/t}^T\\right)\\mathbf x_t}\\]\n各変数の情報の利用\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\!\\)\n\\(\\mathbf P_{t/t}\\)\n\\(\\hat{\\mathbf w}_{t/t}\\)\n\\(\\mathbf P_{t/t-1}\\)\n\\(\\hat{\\mathbf w}_{t/t-1}\\)\n\\(\\mathbf x_t\\)\n\\(y_t\\)\n\\(\\xi_t\\)\n\n\n\n\n\\(\\mathbf P_{t/t}\\)\n\\(\\!\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\n\n\\(\\hat{\\mathbf w}_{t/t}\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\n\n\\(\\xi_t\\) (pre)\n\\(\\!\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\!\\)\n\n\n\\(\\xi_t\\) (EM)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\!\\)",
    "crumbs": [
      "変分近似",
      "Variational Approximation"
    ]
  },
  {
    "objectID": "VA/va.html#概要",
    "href": "VA/va.html#概要",
    "title": "Variational Approximation",
    "section": "",
    "text": "濾波推定値 \\(\\hat{\\mathbf w}_{t/t}\\) \\[\\hat{\\mathbf w}_{t/t}=\\mathbf P_{t/t}\\left(\\mathbf P_{t/t-1}^{-1}\\hat{\\mathbf w}_{t/t-1}+(y_t-1/2)\\mathbf x_t\\right)\\]\n推定誤差共分散行列 \\(\\mathbf P_{t/t}\\)\n\\[\\mathbf P_{t/t}=\\mathbf P_{t/t-1}-\\frac{2\\lambda(\\xi_t)}{1+2\\lambda(\\xi_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\left(\\mathbf P_{t/t-1}\\mathbf x_t\\right)\\left(\\mathbf P_{t/t-1}\\mathbf x_t\\right)^T \\]\n\\[\\mathbf P_{t/t}^{-1}=\\mathbf P_{t/t-1}^{-1}+2\\lambda(\\xi_t)\\mathbf x_t\\mathbf x_t^T\\]\n一段予測推定値 \\(\\hat{\\mathbf w}_{t/t-1}\\) を使う変分パラメータ (pre) \\[\\xi_t=\\sqrt{\\mathbf x_t^T\\left(\\mathbf P_{t/t-1}+\\hat{\\mathbf w}_{t/t-1}\\hat{\\mathbf w}_{t/t-1}^T\\right)\\mathbf x_t}\\]\n濾波推定値 \\(\\hat{\\mathbf w}_{t/t}\\) を使う変分パラメータ (EM) \\[\\xi_t=\\sqrt{\\mathbf x_t^T\\left(\\mathbf P_{t/t}+\\hat{\\mathbf w}_{t/t}\\hat{\\mathbf w}_{t/t}^T\\right)\\mathbf x_t}\\]\n各変数の情報の利用\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\!\\)\n\\(\\mathbf P_{t/t}\\)\n\\(\\hat{\\mathbf w}_{t/t}\\)\n\\(\\mathbf P_{t/t-1}\\)\n\\(\\hat{\\mathbf w}_{t/t-1}\\)\n\\(\\mathbf x_t\\)\n\\(y_t\\)\n\\(\\xi_t\\)\n\n\n\n\n\\(\\mathbf P_{t/t}\\)\n\\(\\!\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\n\n\\(\\hat{\\mathbf w}_{t/t}\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\n\n\\(\\xi_t\\) (pre)\n\\(\\!\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\!\\)\n\n\n\\(\\xi_t\\) (EM)\n\\(\\bigcirc\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\!\\)\n\\(\\bigcirc\\)\n\\(\\!\\)\n\\(\\!\\)",
    "crumbs": [
      "変分近似",
      "Variational Approximation"
    ]
  },
  {
    "objectID": "VA/va.html#関数等",
    "href": "VA/va.html#関数等",
    "title": "Variational Approximation",
    "section": "関数等",
    "text": "関数等\n\nsource\n\nlam\n\ndef lam(\n    x:Float[Array, ''], # $x$\n)-&gt;Float[Array, '']: # $\\lambda(x)$\n\n*\\(\\!\\)** Lambda 関数 \\[\\lambda(x)=\\frac{1}{2x}\\left[\\sigma(x)-\\frac{1}{2}\\right]\\] *\\(\\!\\)\n\nsource\n\n\nPtt\n\ndef Ptt(\n    Ptm:Float[Array, 'N N'], # $\\mathbf P_{t/t-1}$\n    x:Float[Array, 'N'], # $\\mathbf x_t$\n    xi:Float[Array, ''], # $\\xi_t$\n)-&gt;Float[Array, 'N N']: # $\\mathbf P_{t/t}$\n\n*\\(\\!\\)** 推定誤差共分散行列 \\(\\mathbf P_{t/t}\\)\n\\[\\mathbf P_{t/t}=\\mathbf P_{t/t-1}-\\frac{2\\lambda(\\xi_t)}{1+2\\lambda(\\xi_t)\\mathbf x_t^T\\mathbf P_{t/t-1}\\mathbf x_t}\\left(\\mathbf P_{t/t-1}\\mathbf x_t\\right)\\left(\\mathbf P_{t/t-1}\\mathbf x_t\\right)^T \\]\n\\[\\mathbf P_{t/t}^{-1}=\\mathbf P_{t/t-1}^{-1}+2\\lambda(\\xi_t)\\mathbf x_t\\mathbf x_t^T\\] *\\(\\!\\)\n\nsource\n\n\nwtt\n\ndef wtt(\n    Ptm:Float[Array, 'N N'], # $\\mathbf P_{t/t-1}$\n    Ptt_:Float[Array, 'N N'], # $\\mathbf P_{t/t}$\n    w:Float[Array, 'N'], # $\\hat{\\mathbf w}_{t/t-1}$\n    x:Float[Array, 'N'], # $\\mathbf x_t$\n    y:Float[Array, ''], # $y_t$\n)-&gt;Float[Array, 'N']: # $\\hat{\\mathbf w}_{t/t}$\n\n*\\(\\!\\)** 濾波推定値 \\(\\hat{\\mathbf w}_{t/t}\\) \\[\\hat{\\mathbf w}_{t/t}=\\mathbf P_{t/t}\\left(\\mathbf P_{t/t-1}^{-1}\\hat{\\mathbf w}_{t/t-1}+(y_t-1/2)\\mathbf x_t\\right)\\] *\\(\\!\\)\n\nsource\n\n\nxit\n\ndef xit(\n    Cov:Float[Array, 'N N'], # $\\boldsymbol\\Sigma$\n    w:Float[Array, 'N'], # $\\hat{\\mathbf w}$\n    x:Float[Array, 'N'], # $\\mathbf x_t$\n)-&gt;Float[Array, '']: # $\\xi_t$\n\n*\\(\\!\\)** 変分パラメータ \\(\\xi_t\\) \\[\\xi_t=\\sqrt{\\mathbf x_t^T\\mathbb E[\\mathbf w\\mathbf w^T]\\mathbf x_t}=\\sqrt{\\mathbf x_t^T\\left(\\boldsymbol \\Sigma+\\hat{\\mathbf w}\\hat{\\mathbf w}^T\\right)\\mathbf x_t}\\] *\\(\\!\\)\n\nsource\n\n\nVApre_out\n\ndef VApre_out(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\n*\\(\\!\\)** VApre 関数の返り値\n\n\n\n\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nW\nFloat[Array, ‘T N’]\n\\(\\{\\hat{\\mathbf w}_{t/t}\\}_{t=0,\\ldots,T-1}\\)\n\n\nP\nFloat[Array, ‘T N N’]\n\\(\\{\\mathbf P_{t/t}\\}_{t=0,\\ldots,T-1}\\)\n\n\nXi\nFloat[Array, ‘T’]\n\\(\\{\\xi_t\\}_{t=0,\\ldots,T-1}\\)\n\n\n\n*\\(\\!\\)\n\nsource\n\n\nVApre\n\ndef VApre(\n    N:int, # $N$\n    T:int, # $T$\n    x:Float[Array, '{T} {N}'], # $\\{ \\mathbf x_t \\}_{t=0,\\ldots,T-1}$\n    y:Float[Array, '{T}'], # $\\{ y_t \\}_{t=0,\\ldots,T-1}$\n    G:Float[Array, '{N} {N}'], # $\\boldsymbol\\Gamma$\n    w0:Float[Array, '{N}'], # $\\hat{\\mathbf w}_{0/-1}$\n    P0:Float[Array, '{N} {N}'], # $\\mathbf P_{0/-1}$\n)-&gt;VApre_out:\n\n*\\(\\!\\)** 一段予測推定値 \\(\\hat{\\mathbf w}_{t/t-1}\\) を使う変分近似法 \\[\\xi_t=\\sqrt{\\mathbf x_t^T\\left(\\mathbf P_{t/t-1}+\\hat{\\mathbf w}_{t/t-1}\\hat{\\mathbf w}_{t/t-1}^T\\right)\\mathbf x_t}\\] *\\(\\!\\)\n\nsource\n\n\nVAEM_out\n\ndef VAEM_out(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\n*\\(\\!\\)** VAEM 関数の返り値\n\n\n\n\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nW\nFloat[Array, ‘T N’]\n\\(\\{\\hat{\\mathbf w}_{t/t}\\}_{t=0,\\ldots,T-1}\\)\n\n\nP\nFloat[Array, ‘T N N’]\n\\(\\{\\mathbf P_{t/t}\\}_{t=0,\\ldots,T-1}\\)\n\n\nXi\nFloat[Array, ‘T’]\n\\(\\{\\xi_t\\}_{t=0,\\ldots,T-1}\\)\n\n\nIters\nInt[Array, ‘T’]\n\\(\\{\\mathrm{Iter}_t\\}_{t=0,\\ldots,T-1}\\)\n\n\n\n*\\(\\!\\)\n\nsource\n\n\nVAEM\n\ndef VAEM(\n    N:int, # $N$\n    T:int, # $T$\n    x:Float[Array, '{T} {N}'], # $\\{ \\mathbf x_t \\}_{t=0,\\ldots,T-1}$\n    y:Float[Array, '{T}'], # $\\{ y_t \\}_{t=0,\\ldots,T-1}$\n    G:Float[Array, '{N} {N}'], # $\\boldsymbol\\Gamma$\n    w0:Float[Array, '{N}'], # $\\hat{\\mathbf w}_{0/-1}$\n    P0:Float[Array, '{N} {N}'], # $\\mathbf P_{0/-1}$\n    epsilon:Float[Array, ''], # $\\epsilon\\ge |\\xi\\\\^{\\text{new}}_t-\\xi\\\\^{\\text{old}}_t|$\n    max_iter:int=100, # 繰り返し回数の上限\n)-&gt;VAEM_out:\n\n*\\(\\!\\)** 濾波推定値 \\(\\hat{\\mathbf w}_{t/t}\\) を使う変分近似法。EMアルゴリズムを使う。 \\[\\xi_t=\\sqrt{\\mathbf x_t^T\\left(\\mathbf P_{t/t}+\\hat{\\mathbf w}_{t/t}\\hat{\\mathbf w}_{t/t}^T\\right)\\mathbf x_t}\\] *\\(\\!\\)",
    "crumbs": [
      "変分近似",
      "Variational Approximation"
    ]
  },
  {
    "objectID": "VA/summary.html",
    "href": "VA/summary.html",
    "title": "変分近似の概要",
    "section": "",
    "text": "EM アルゴリズムの目的は、潜在変数を持つモデルについて最尤解を見出すことである。\n全ての観測データの集合を \\(\\mathbf X\\) 、全ての潜在変数の集合を \\(\\mathbf Z\\) 、全てのモデルパラメータの集合を \\(\\boldsymbol\\theta\\) で表す。\n最尤解 \\(\\hat{\\boldsymbol\\theta}\\) は次式で表される。\n\\[\\hat{\\boldsymbol\\theta}=\\arg\\max_{\\boldsymbol\\theta}p(\\mathbf X\\mid\\boldsymbol\\theta)=\\arg\\max_{\\boldsymbol\\theta}\\sum_{\\mathbf Z}p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\]\n対数尤度関数は以下のように書ける。\n\\[\\ln p(\\mathbf X\\mid\\boldsymbol\\theta) = \\ln\\left\\{ \\sum_{\\mathbf Z} p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta) \\right\\}\\]\nこのように、潜在変数に関する総和が対数の中にあり、同時分布 \\(p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\) が指数型分布族に属する場合でも、周辺分布 \\(p(\\mathbf X\\mid\\boldsymbol\\theta)\\) は指数型分布族にならない。\n\\(\\{\\mathbf X,\\mathbf Z\\}\\) という組を完全データ集合と呼び、実際の観測データ \\(\\mathbf X\\) は不完全と呼ぶことにする。完全データ集合に関する対数尤度関数 \\(\\ln p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\) の最大化は簡単にできると仮定する。\n実際には、完全データ集合 \\(\\{\\mathbf X,\\mathbf Z\\}\\) は与えられず、不完全データ \\(\\mathbf X\\) だけが与えられる。潜在変数 \\(\\mathbf Z\\) についての知識は事後確率分布 \\(p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta)\\) によるものだけである。\n\n\n\n\n\n\n\n\\(\\!\\)\n数式\n\n\n\n\n目的 （指数型分布族ではない）\n\\(\\arg\\max_{\\boldsymbol\\theta}p(\\mathbf X\\mid\\boldsymbol\\theta)\\)\n\n\n簡単　（指数型分布族である）\n\\(\\arg\\max_{\\boldsymbol\\theta}p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\)\n\n\n既知\n\\(p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta),\\ p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\)\n\n\n\nEMアルゴリズムでは、次の２ステップを踏む。\nEステップ\n\\[\n\\begin{split}\n\\mathcal Q(\\boldsymbol\\theta,\\boldsymbol\\theta^{\\text{old}}) &=\\mathbb E_{\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta^{\\text{old}}}\\left[\\ln p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\right] \\\\\n&= \\sum_{\\mathbf Z} p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta^{\\text{old}})\\ln p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\n\\end{split}\n\\]\nMステップ\n\\[\n\\boldsymbol\\theta^{\\text{new}}=\\arg\\max_{\\boldsymbol\\theta}\\mathcal Q(\\boldsymbol\\theta,\\boldsymbol\\theta^{\\text{old}})\n\\]\n\n\n\nパラメータの事前分布 \\(p(\\boldsymbol\\theta)\\) が既知の場合、MAP 解を計算できる。\n\n\n\n\n\n\n\n\\(\\!\\)\n数式\n\n\n\n\n目的 （指数型分布族ではない）\n\\(\\arg\\max_{\\boldsymbol\\theta}p(\\boldsymbol\\theta\\mid\\mathbf X)\\)\n\n\n簡単　（指数型分布族である）\n\\(\\arg\\max_{\\boldsymbol\\theta}p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\)\n\n\n既知\n\\(p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta),\\ p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta),\\ p(\\boldsymbol\\theta)\\)\n\n\n\n\\[\n\\begin{split}\n\\boldsymbol\\theta^{\\text{new}} &=\\arg\\max_{\\boldsymbol\\theta}\\left(\\mathcal Q(\\boldsymbol\\theta,\\boldsymbol\\theta^{\\text{old}})+\\ln p(\\boldsymbol\\theta)\\right) \\\\\n&= \\arg\\max_{\\boldsymbol\\theta}\\mathbb E_{\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta^{\\text{old}}}\\left[\\ln p(\\mathbf X,\\mathbf Z,\\boldsymbol\\theta)\\right] \\\\\n&= \\arg\\max_{\\boldsymbol\\theta}\\mathbb E_{\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta^{\\text{old}}}\\left[\\ln p(\\boldsymbol\\theta\\mid\\mathbf X,\\mathbf Z)\\right]\n\\end{split}\n\\]",
    "crumbs": [
      "変分近似",
      "変分近似の概要"
    ]
  },
  {
    "objectID": "VA/summary.html#em-アルゴリズム",
    "href": "VA/summary.html#em-アルゴリズム",
    "title": "変分近似の概要",
    "section": "",
    "text": "EM アルゴリズムの目的は、潜在変数を持つモデルについて最尤解を見出すことである。\n全ての観測データの集合を \\(\\mathbf X\\) 、全ての潜在変数の集合を \\(\\mathbf Z\\) 、全てのモデルパラメータの集合を \\(\\boldsymbol\\theta\\) で表す。\n最尤解 \\(\\hat{\\boldsymbol\\theta}\\) は次式で表される。\n\\[\\hat{\\boldsymbol\\theta}=\\arg\\max_{\\boldsymbol\\theta}p(\\mathbf X\\mid\\boldsymbol\\theta)=\\arg\\max_{\\boldsymbol\\theta}\\sum_{\\mathbf Z}p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\]\n対数尤度関数は以下のように書ける。\n\\[\\ln p(\\mathbf X\\mid\\boldsymbol\\theta) = \\ln\\left\\{ \\sum_{\\mathbf Z} p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta) \\right\\}\\]\nこのように、潜在変数に関する総和が対数の中にあり、同時分布 \\(p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\) が指数型分布族に属する場合でも、周辺分布 \\(p(\\mathbf X\\mid\\boldsymbol\\theta)\\) は指数型分布族にならない。\n\\(\\{\\mathbf X,\\mathbf Z\\}\\) という組を完全データ集合と呼び、実際の観測データ \\(\\mathbf X\\) は不完全と呼ぶことにする。完全データ集合に関する対数尤度関数 \\(\\ln p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\) の最大化は簡単にできると仮定する。\n実際には、完全データ集合 \\(\\{\\mathbf X,\\mathbf Z\\}\\) は与えられず、不完全データ \\(\\mathbf X\\) だけが与えられる。潜在変数 \\(\\mathbf Z\\) についての知識は事後確率分布 \\(p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta)\\) によるものだけである。\n\n\n\n\n\n\n\n\\(\\!\\)\n数式\n\n\n\n\n目的 （指数型分布族ではない）\n\\(\\arg\\max_{\\boldsymbol\\theta}p(\\mathbf X\\mid\\boldsymbol\\theta)\\)\n\n\n簡単　（指数型分布族である）\n\\(\\arg\\max_{\\boldsymbol\\theta}p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\)\n\n\n既知\n\\(p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta),\\ p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\)\n\n\n\nEMアルゴリズムでは、次の２ステップを踏む。\nEステップ\n\\[\n\\begin{split}\n\\mathcal Q(\\boldsymbol\\theta,\\boldsymbol\\theta^{\\text{old}}) &=\\mathbb E_{\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta^{\\text{old}}}\\left[\\ln p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\right] \\\\\n&= \\sum_{\\mathbf Z} p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta^{\\text{old}})\\ln p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\n\\end{split}\n\\]\nMステップ\n\\[\n\\boldsymbol\\theta^{\\text{new}}=\\arg\\max_{\\boldsymbol\\theta}\\mathcal Q(\\boldsymbol\\theta,\\boldsymbol\\theta^{\\text{old}})\n\\]\n\n\n\nパラメータの事前分布 \\(p(\\boldsymbol\\theta)\\) が既知の場合、MAP 解を計算できる。\n\n\n\n\n\n\n\n\\(\\!\\)\n数式\n\n\n\n\n目的 （指数型分布族ではない）\n\\(\\arg\\max_{\\boldsymbol\\theta}p(\\boldsymbol\\theta\\mid\\mathbf X)\\)\n\n\n簡単　（指数型分布族である）\n\\(\\arg\\max_{\\boldsymbol\\theta}p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)\\)\n\n\n既知\n\\(p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta),\\ p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta),\\ p(\\boldsymbol\\theta)\\)\n\n\n\n\\[\n\\begin{split}\n\\boldsymbol\\theta^{\\text{new}} &=\\arg\\max_{\\boldsymbol\\theta}\\left(\\mathcal Q(\\boldsymbol\\theta,\\boldsymbol\\theta^{\\text{old}})+\\ln p(\\boldsymbol\\theta)\\right) \\\\\n&= \\arg\\max_{\\boldsymbol\\theta}\\mathbb E_{\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta^{\\text{old}}}\\left[\\ln p(\\mathbf X,\\mathbf Z,\\boldsymbol\\theta)\\right] \\\\\n&= \\arg\\max_{\\boldsymbol\\theta}\\mathbb E_{\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta^{\\text{old}}}\\left[\\ln p(\\boldsymbol\\theta\\mid\\mathbf X,\\mathbf Z)\\right]\n\\end{split}\n\\]",
    "crumbs": [
      "変分近似",
      "変分近似の概要"
    ]
  },
  {
    "objectID": "VA/summary.html#一般のemアルゴリズム",
    "href": "VA/summary.html#一般のemアルゴリズム",
    "title": "変分近似の概要",
    "section": "一般のEMアルゴリズム",
    "text": "一般のEMアルゴリズム\n潜在変数についての分布 \\(q(\\mathbf Z)\\) を導入する。 \\(q(\\mathbf Z)\\) の設定の仕方に関わらず、次の分解が成り立つ。\n\\[\\ln p(\\mathbf X\\mid\\boldsymbol\\theta)=\\mathcal L(q,\\boldsymbol\\theta)+\\mathrm{KL}(q\\|p)\\tag{1}\\]\nただし、\n\\[\\mathcal L(q,\\boldsymbol\\theta)=\\sum_{\\mathbf Z}q(\\mathbf Z)\\ln\\left\\{ \\frac{p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)}{q(\\mathbf Z)} \\right\\}\\] \\[\\mathrm{KL}(q\\|p)=-\\sum_{\\mathbf Z}q(\\mathbf Z)\\ln\\left\\{ \\frac{p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta)}{q(\\mathbf Z)} \\right\\}\\]\n\\[\n\\begin{split}\n\\because\\ln p(\\mathbf X\\mid\\boldsymbol\\theta) &=\\mathcal L(q,\\boldsymbol\\theta)+\\mathrm{KL}(q\\|p) \\\\\n&= \\sum_{\\mathbf Z}q(\\mathbf Z)\\left(\\ln\\left\\{ \\frac{p(\\mathbf X,\\mathbf Z\\mid\\boldsymbol\\theta)}{q(\\mathbf Z)} \\right\\}-\\ln\\left\\{ \\frac{p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta)}{q(\\mathbf Z)} \\right\\}\\right) \\\\\n&= \\sum_{\\mathbf Z}q(\\mathbf Z)\\left(\\ln\\left\\{ \\frac{p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta)p(\\mathbf X\\mid\\boldsymbol\\theta)}{q(\\mathbf Z)} \\right\\}-\\ln\\left\\{ \\frac{p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta)}{q(\\mathbf Z)} \\right\\}\\right) \\\\\n&= \\sum_{\\mathbf Z}q(\\mathbf Z)\\ln p(\\mathbf X\\mid\\boldsymbol\\theta)\n\\end{split}\n\\]\n\\(\\mathcal L(q,\\boldsymbol\\theta)\\) は分布 \\(q(\\mathbf Z)\\) の汎関数であり、かつパラメータ \\(\\boldsymbol\\theta\\) の関数である。\n\\(\\mathrm{KL}(q\\|p)\\ge 0\\) 、等号は \\(q(\\mathbf Z)=p(\\mathbf Z\\mid\\mathbf X,\\boldsymbol\\theta)\\) のときのみ成立する。よって \\((1)\\) より、 \\[\\mathcal L(q,\\boldsymbol\\theta)\\le\\ln p(\\mathbf X\\mid\\boldsymbol\\theta)\\] が成り立つ。つまり、 \\(\\mathcal L(q,\\boldsymbol\\theta)\\) は \\(q\\) と \\(\\boldsymbol\\theta\\) によらず常に \\(\\ln p(\\mathbf X\\mid\\boldsymbol\\theta)\\) の下界をなす。",
    "crumbs": [
      "変分近似",
      "変分近似の概要"
    ]
  },
  {
    "objectID": "VA/summary.html#局所的変分推論法",
    "href": "VA/summary.html#局所的変分推論法",
    "title": "変分近似の概要",
    "section": "局所的変分推論法",
    "text": "局所的変分推論法\n次の積分を計算したいとする。\n\\[\nI=\\int\\sigma(a)p(a)da\n\\]\n積分をそのまま求めるのは不可能なため、変分下界 \\(\\sigma(a)\\ge f(a,\\xi)\\) の形で用いる。ここで、 \\(\\xi\\) は変分パラメータである。\n\\[\nI\\ge\\int f(a,\\xi)p(a)da=\\mathcal L(\\xi)\n\\]\n\\(\\mathcal L(\\xi)\\) は単に \\(\\xi\\) をパラメータとする関数である。 \\(\\mathcal L(\\xi)\\) を最大化する値 \\(\\xi^*\\) を求める。\nただし、最適化したこの下界は一般に正確ではない。なぜなら \\(\\sigma(a)\\ge f(a,\\xi)\\) は厳密に最適化できるが、選んだ \\(\\xi\\) は \\(a\\) の値に依存しており、下界が正しいのはある \\(a\\) の値についてだけだからである。\n\\(\\mathcal L(\\xi)\\) は全ての \\(a\\) の値について積分して得られるから、 \\(\\xi^*\\) の値は分布 \\(p(a)\\) による重みで平均化してしまった値を表している。",
    "crumbs": [
      "変分近似",
      "変分近似の概要"
    ]
  },
  {
    "objectID": "MinimizeRegrex/summary.html",
    "href": "MinimizeRegrex/summary.html",
    "title": "Regret 最小化の概要",
    "section": "",
    "text": "\\(y_t\\) は \\(t\\) ごとに存在するパラメータ \\(\\theta_t\\in[0,1]\\) をもつベルヌーイ分布に従う値とする。\nベルヌーイ分布の確率質量関数 \\(p(y_t\\mid\\theta_t)\\) は\n\\[p(y_t\\mid\\mathbf w_t,\\mathbf x_t)=\\theta_t^{y_t}(1-\\theta_t)^{1-y_t}\\tag{1}\\]\nである。\nロジスティックシグモイド関数の逆関数として知られるロジット変換 \\(a\\) は\n\\[a(\\theta)=\\ln\\frac{\\theta}{1-\\theta}\\tag{2}\\]\nと定義され、これを \\(\\theta_t\\) について表すと\n\\[\n\\begin{split}\ne^{a_t} &=\\frac{\\theta_t}{1-\\theta_t} \\\\\n\\theta_t &= e^{a_t}(1-\\theta_t) \\\\\n\\end{split}\\tag{3}\n\\]\nとなる。これを \\((1)\\) に適用すると、\n\\[\n\\begin{split}\np(y_t\\mid a_t) &= \\theta_t^{y_t}(1-\\theta_t)^{1-y_t} \\\\\n&= e^{a_ty_t}(1-\\theta_t)^{y_t}(1-\\theta_t)^{1-y_t} \\\\\n&= e^{a_ty_t}(1-\\theta_t) \\\\\n&= \\exp\\{ y_ta_t - \\ln (1+e^{a_t}) \\}\n\\end{split}\\tag{4}\n\\]\nとなる。この変換によって確率質量関数のパラメータは \\(\\theta_t\\in[0,1]\\) から \\(a_t\\in(-\\infty,+\\infty)\\) となる。",
    "crumbs": [
      "リグレット最小化",
      "Regret 最小化の概要"
    ]
  },
  {
    "objectID": "MinimizeRegrex/summary.html#設定-確率質量関数",
    "href": "MinimizeRegrex/summary.html#設定-確率質量関数",
    "title": "Regret 最小化の概要",
    "section": "",
    "text": "\\(y_t\\) は \\(t\\) ごとに存在するパラメータ \\(\\theta_t\\in[0,1]\\) をもつベルヌーイ分布に従う値とする。\nベルヌーイ分布の確率質量関数 \\(p(y_t\\mid\\theta_t)\\) は\n\\[p(y_t\\mid\\mathbf w_t,\\mathbf x_t)=\\theta_t^{y_t}(1-\\theta_t)^{1-y_t}\\tag{1}\\]\nである。\nロジスティックシグモイド関数の逆関数として知られるロジット変換 \\(a\\) は\n\\[a(\\theta)=\\ln\\frac{\\theta}{1-\\theta}\\tag{2}\\]\nと定義され、これを \\(\\theta_t\\) について表すと\n\\[\n\\begin{split}\ne^{a_t} &=\\frac{\\theta_t}{1-\\theta_t} \\\\\n\\theta_t &= e^{a_t}(1-\\theta_t) \\\\\n\\end{split}\\tag{3}\n\\]\nとなる。これを \\((1)\\) に適用すると、\n\\[\n\\begin{split}\np(y_t\\mid a_t) &= \\theta_t^{y_t}(1-\\theta_t)^{1-y_t} \\\\\n&= e^{a_ty_t}(1-\\theta_t)^{y_t}(1-\\theta_t)^{1-y_t} \\\\\n&= e^{a_ty_t}(1-\\theta_t) \\\\\n&= \\exp\\{ y_ta_t - \\ln (1+e^{a_t}) \\}\n\\end{split}\\tag{4}\n\\]\nとなる。この変換によって確率質量関数のパラメータは \\(\\theta_t\\in[0,1]\\) から \\(a_t\\in(-\\infty,+\\infty)\\) となる。",
    "crumbs": [
      "リグレット最小化",
      "Regret 最小化の概要"
    ]
  },
  {
    "objectID": "MinimizeRegrex/summary.html#設定-ロジスティック誤差関数",
    "href": "MinimizeRegrex/summary.html#設定-ロジスティック誤差関数",
    "title": "Regret 最小化の概要",
    "section": "設定: ロジスティック誤差関数",
    "text": "設定: ロジスティック誤差関数\n\\((4)\\) から導出される負の対数尤度 \\(-\\ln p(y_t\\mid a_t)\\) によるロジスティック誤差関数を\n\\[E(y_t,a_t)=-y_ta_t+\\ln(1+e^{a_t})\\tag{5}\\]\nと定義する。",
    "crumbs": [
      "リグレット最小化",
      "Regret 最小化の概要"
    ]
  },
  {
    "objectID": "MinimizeRegrex/summary.html#設定-a_t-の系列変化が滑らか",
    "href": "MinimizeRegrex/summary.html#設定-a_t-の系列変化が滑らか",
    "title": "Regret 最小化の概要",
    "section": "設定: \\(a_t\\) の系列変化が滑らか",
    "text": "設定: \\(a_t\\) の系列変化が滑らか\n\\(a_t\\) の系列の変化が滑らかであるという事前知識を考慮した式\n\\[\\lambda \\sum_{t=1}^{T+1}(a_t-a_{t-1})^2\\tag{6}\\]\nを導入する。\\(\\lambda\\) は予測する系列の滑らかさの度合いを決める係数である。",
    "crumbs": [
      "リグレット最小化",
      "Regret 最小化の概要"
    ]
  },
  {
    "objectID": "MinimizeRegrex/summary.html#設定-リグレット",
    "href": "MinimizeRegrex/summary.html#設定-リグレット",
    "title": "Regret 最小化の概要",
    "section": "設定: リグレット",
    "text": "設定: リグレット\nリグレットとは、オフライン予測の結果とオンライン予測の予測結果それぞれの損失を比較し、相対的に評価する指標である。\nオンライン予測の予測結果の系列を \\(a_1,a_2,\\ldots,a_T\\) とし、損失関数を \\(l(y_t,a_t)\\) とする。オフライン予測の予測結果の系列を \\(\\hat a_1,\\hat a_2,\\ldots,\\hat a_T\\) とする。\nリグレット \\(R\\) は\n\\[R=\\sum_{t=1}^T l(y_t,a_t)-\\min_{\\hat a_1,\\ldots,\\hat a_T}\\left\\{\\sum_{t=1}^Tl(y_t,\\hat a_t)+\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2\\right\\}\\tag{7}\\]\nで定義される。\\((12)\\) の第２項はスムーザの目的関数であり、オフライン予測の最適な損失を表している。なお、ここで \\(\\hat a_0,\\hat a_{T+1}\\) が使われているが、両方とも \\(0\\) として扱われる。第１項はオンライン予測の損失であるため、「オンライン予測の損失からスムーザの損失を引いたもの」がリグレットとなる。",
    "crumbs": [
      "リグレット最小化",
      "Regret 最小化の概要"
    ]
  },
  {
    "objectID": "MinimizeRegrex/summary.html#目的",
    "href": "MinimizeRegrex/summary.html#目的",
    "title": "Regret 最小化の概要",
    "section": "目的",
    "text": "目的\n損失関数 \\(l\\) として \\((12)\\) の \\(E(y_t,a_t)\\) を用い、ミニマックス問題\n\\[\\min_{a_t}\\max_{y_t}\\cdots\\min_{a_T}\\max_{y_T}\\sum_{t=1}^T l(y_t,a_t)-\\min_{\\hat a_1,\\ldots,\\hat a_T}\\left\\{\\sum_{t=1}^Tl(y_t,\\hat a_t)+\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2\\right\\}\\tag{8}\\]\nを解く。",
    "crumbs": [
      "リグレット最小化",
      "Regret 最小化の概要"
    ]
  },
  {
    "objectID": "MinimizeRegrex/summary.html#本研究との兼ね合い",
    "href": "MinimizeRegrex/summary.html#本研究との兼ね合い",
    "title": "Regret 最小化の概要",
    "section": "本研究との兼ね合い",
    "text": "本研究との兼ね合い\n\\(\\theta_t\\) は \\(\\sigma_t=\\sigma(\\mathbf w_t^T\\mathbf x_t)\\) と対応する。\n\\(a_t\\) は \\(\\mathbf w_t^T\\mathbf x_t\\) と対応する。\n\\((12)\\) は、本研究では\n\\[E(y_t,\\mathbf w_t)=-y_t\\mathbf w_t^T\\mathbf x_t+\\ln(1+e^{\\mathbf w_t^T\\mathbf x_t})\\tag{10}\\]\nと表される。",
    "crumbs": [
      "リグレット最小化",
      "Regret 最小化の概要"
    ]
  },
  {
    "objectID": "MinimizeRegrex/summary.html#損失関数の導出",
    "href": "MinimizeRegrex/summary.html#損失関数の導出",
    "title": "Regret 最小化の概要",
    "section": "損失関数の導出",
    "text": "損失関数の導出\n\\(f(a)\\) を\n\\[f(a)=\\ln\\left(e^{a/2}+e^{-a/2}\\right)\\tag{11}\\]\nとおく。ここで、\\(f(a)=g(a^2)\\) とおくと、\n\\[g(a^2)=\\ln\\left(e^{\\sqrt {a^2}/2}+e^{-\\sqrt {a^2}/2}\\right)\\]\nとなる。 \\(g'(a^2)\\) は\n\\[g'(a^2)=\\frac{1}{4a}\\tanh\\frac{a}{2}\\tag{12}\\]\nとなる。\n\\[g''(a^2)\\le 0\\tag{13}\\]\nとなるため、 \\(g(a^2)\\) は凹関数である。これにより、\n\\[g(a^2)\\le g(\\xi^2)+g'(\\xi^2)(a^2-\\xi^2)\\tag{14}\\]\nであるから、 \\(g'(a^2)=\\phi(a)\\) とすると\n\\[f(a)\\le f(\\xi)+\\phi(\\xi)(a^2-\\xi^2)\\tag{15}\\]\nが成り立つ。\n\\[\n\\begin{split}\n\\ln(1+e^a) &= \\ln(e^{a/2}+e^{-a/2})+\\ln(e^{a/2}) \\\\\n&= f(a) + \\frac{a}{2}\n\\end{split} \\tag{16}\n\\]\nであるから、 \\((5)\\), \\((15)\\) より、\n\\[\n\\begin{split}\nE(y_t,a_t) &=-y_ta_t+\\ln(1+e^{a_t}) \\\\\n&= -y_ta_t+f(a_t)+\\frac{a_t}{2} \\\\\n&\\le -y_ta_t+\\frac{a_t}{2}+f(\\xi_t)+\\phi(\\xi_t)(a_t^2-\\xi_t^2)\n\\end{split} \\tag{17}\n\\]\n目的は、損失関数 \\(l\\) として \\(E(y_t,a_t)\\) を用いることであるから\n\\[l(y_t, a_t)=-a_ty_t+\\frac{a_t}{2}+f(\\xi_t)+\\phi(\\xi_t)(a_t^2-\\xi_t^2)\\tag{18}\\]\nとなる。",
    "crumbs": [
      "リグレット最小化",
      "Regret 最小化の概要"
    ]
  },
  {
    "objectID": "MinimizeRegrex/summary.html#オフライン予測による損失",
    "href": "MinimizeRegrex/summary.html#オフライン予測による損失",
    "title": "Regret 最小化の概要",
    "section": "オフライン予測による損失",
    "text": "オフライン予測による損失\n\\((8)\\) より\n\\[\nR =\\sum_{t=1}^T l(y_t,a_t)-\\min_{\\hat a_1,\\ldots,\\hat a_T}\\left\\{\\sum_{t=1}^Tl(y_t,\\hat a_t)+\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2\\right\\}\n\\]\nであった。この第２項に注目したとき、オフライン予測を行った際の損失 \\(L\\) は\n\\[\nL =\\sum_{t=1}^Tl(y_t,\\hat a_t)+\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2 \\tag {19}\n\\]\nとなる。\n最小化問題を解くために、\\(L\\) をベクトルや行列を用いて表現する。\n\\[\n\\begin{align}\n\\hat{\\mathbf a} &=\\begin{pmatrix}\\hat a_1 & \\cdots & \\hat a_T \\end{pmatrix}^T \\\\\n\\mathbf y &= \\begin{pmatrix}y_1 & \\cdots & y_T\\end{pmatrix}^T \\\\\n\\mathbf f &= \\begin{pmatrix}f(\\xi_1) & \\cdots & f(\\xi_T)\\end{pmatrix}^T \\\\\n\\boldsymbol \\xi &= \\begin{pmatrix}\\xi_1 & \\cdots & \\xi_T\\end{pmatrix}^T \\\\\n\\mathbf\\Phi &=\\mathrm {diag}(\\phi(\\xi_t),\\ldots,\\phi(\\xi_T)) \\\\\n\\mathbf K &= \\begin{pmatrix}2 & -1 \\\\ -1 & 2 & -1 \\\\ & \\ddots & \\ddots & \\ddots \\\\ & & -1 & 2 & -1 \\\\ & & & -1 & 2\\end{pmatrix}\n\\end{align}\n\\]\n\\[\n\\begin{split}\n\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2 &= \\lambda\\left\\{\\begin{pmatrix}\\hat{\\mathbf a} \\\\ \\hat a_{T+1}\\end{pmatrix}-\\begin{pmatrix}\\hat a_0 \\\\ \\hat{\\mathbf a}\\end{pmatrix}\\right\\}^T\\left\\{\\begin{pmatrix}\\hat{\\mathbf a} \\\\ \\hat a_{T+1}\\end{pmatrix}-\\begin{pmatrix}\\hat a_0 \\\\ \\hat{\\mathbf a}\\end{pmatrix}\\right\\} \\\\\n&= \\lambda \\begin{pmatrix}\\hat a_0 \\\\ \\hat{\\mathbf a} \\\\ \\hat a_{T+1}\\end{pmatrix}^T\\left\\{\\begin{pmatrix}\\mathbf 0^T \\\\ \\mathbf I\\end{pmatrix}-\\begin{pmatrix}\\mathbf I \\\\ \\mathbf 0^T\\end{pmatrix}\\right\\}\\left\\{\\begin{pmatrix}\\mathbf 0 & \\mathbf I\\end{pmatrix}-\\begin{pmatrix}\\mathbf I & \\mathbf 0\\end{pmatrix}\\right\\}\\begin{pmatrix}\\hat a_0 \\\\ \\hat{\\mathbf a} \\\\ \\hat a_{T+1}\\end{pmatrix} \\\\\n&= \\lambda \\begin{pmatrix}\\hat a_0 \\\\ \\hat{\\mathbf a} \\\\ \\hat a_{T+1}\\end{pmatrix}^T\\left\\{\\begin{pmatrix}0 & \\mathbf 0^T \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}-\\begin{pmatrix}\\mathbf 0^T & 0 \\\\ \\mathbf I & \\mathbf 0\\end{pmatrix}-\\begin{pmatrix}\\mathbf 0 & \\mathbf I \\\\ 0 & \\mathbf 0^T\\end{pmatrix}+\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ \\mathbf 0^T & 0\\end{pmatrix}\\right\\}\\begin{pmatrix}\\hat a_0 \\\\ \\hat{\\mathbf a} \\\\ \\hat a_{T+1}\\end{pmatrix} \\\\\n&= \\lambda \\begin{pmatrix}\\hat a_0 \\\\ \\hat{\\mathbf a} \\\\ \\hat a_{T+1}\\end{pmatrix}^T\\begin{pmatrix}1 & -1 \\\\ -1 & 2 & -1 \\\\ & \\ddots & \\ddots & \\ddots \\\\ & & -1 & 2 & -1 \\\\ & & & -1 & 1\\end{pmatrix}\\begin{pmatrix}\\hat a_0 \\\\ \\hat{\\mathbf a} \\\\ \\hat a_{T+1}\\end{pmatrix}\n\\end{split}\n\\]\nここで、 \\(\\hat a_0, \\hat a_{T+1}\\) は \\(0\\) であるため、\n\\[\n\\begin{split}\n\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2 &= \\lambda \\begin{pmatrix}0 & \\hat{\\mathbf a}^T & 0\\end{pmatrix}\\begin{pmatrix}1 & -1 \\\\ -1 & 2 & -1 \\\\ & \\ddots & \\ddots & \\ddots \\\\ & & -1 & 2 & -1 \\\\ & & & -1 & 1\\end{pmatrix}\\begin{pmatrix}0 \\\\ \\hat{\\mathbf a} \\\\ 0\\end{pmatrix} \\\\\n&= \\hat{\\mathbf a}^T\\begin{pmatrix}-1 & 2 & -1 \\\\ & \\ddots & \\ddots & \\ddots \\\\ & & -1 & 2 & -1\\end{pmatrix}\\begin{pmatrix}0 \\\\ \\hat{\\mathbf a} \\\\ 0\\end{pmatrix} \\\\\n&= \\hat{\\mathbf a}^T\\mathbf K\\hat{\\mathbf a}\n\\end{split}\n\\]\n\\[\n\\begin{split}\nL =&\\sum_{t=1}^Tl(y_t,\\hat a_t)+\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2 \\\\\n=& \\sum_{t=1}^T\\left\\{-a_ty_t+\\frac{a_t}{2}+f(\\xi_t)+\\phi(\\xi_t)(a_t^2-\\xi_t^2)\\right\\}+\\lambda\\hat{\\mathbf a}^T\\mathbf K\\hat{\\mathbf a} \\\\\n=& -\\hat{\\mathbf a}^T\\mathbf y+\\frac{1}{2}\\hat{\\mathbf a}^T\\mathbf 1+\\mathbf f^T\\mathbf 1+\\hat{\\mathbf a}^T\\mathbf\\Phi\\hat{\\mathbf a}-\\boldsymbol\\xi^T\\mathbf\\Phi\\boldsymbol\\xi+\\lambda\\hat{\\mathbf a}^T\\mathbf K\\hat{\\mathbf a} \\\\\n=& \\hat{\\mathbf a}^T(\\mathbf\\Phi+\\lambda\\mathbf K)\\hat{\\mathbf a}+\\left(-\\mathbf y+\\frac{1}{2}\\mathbf 1\\right)^T\\hat{\\mathbf a}+\\mathbf f^T\\mathbf 1-\\boldsymbol\\xi^T\\mathbf\\Phi\\boldsymbol\\xi \\\\\n=& \\left\\{\\hat{\\mathbf a}+\\frac{1}{2}(\\mathbf\\Phi+\\lambda\\mathbf K)^{-1}\\left(-\\mathbf y+\\frac{1}{2}\\mathbf 1\\right)\\right\\}^T(\\mathbf\\Phi+\\lambda\\mathbf K)\\left\\{\\hat{\\mathbf a}+\\frac{1}{2}(\\mathbf\\Phi+\\lambda\\mathbf K)^{-1}\\left(-\\mathbf y+\\frac{1}{2}\\mathbf 1\\right)\\right\\} \\\\\n&+ -\\frac{1}{4}\\left(-\\mathbf y+\\frac{1}{2}\\mathbf 1\\right)^T(\\mathbf\\Phi+\\lambda\\mathbf K)^{-1}\\left(-\\mathbf y+\\frac{1}{2}\\mathbf 1\\right)+\\mathbf f^T\\mathbf 1-\\boldsymbol\\xi^T\\mathbf\\Phi\\boldsymbol\\xi\n\\end{split}\n\\]\n\\(L\\) を最小にする \\(\\hat{\\mathbf a}\\) は\n\\[\\mathbf{\\hat a}=\\frac{1}{2}(\\mathbf\\Phi+\\lambda\\mathbf K)^{-1}\\left(\\mathbf y-\\frac{1}{2}\\mathbf 1\\right)\\tag{20}\\]\nであり、その時の損失 \\(L^*\\) は\n\\[ L^* =-\\frac{1}{4}\\left(\\mathbf y-\\frac{1}{2}\\mathbf 1\\right)^T\\left(\\mathbf \\Phi+\\lambda \\mathbf K\\right)^{-1}\\left(\\mathbf y-\\frac{1}{2}\\mathbf 1\\right)+\\mathbf f^T\\mathbf 1 - \\boldsymbol\\xi^T\\mathbf\\Phi\\boldsymbol\\xi\\tag{24} \\]\nとなる。",
    "crumbs": [
      "リグレット最小化",
      "Regret 最小化の概要"
    ]
  },
  {
    "objectID": "MinimizeRegrex/summary.html#ある時点での-minimax-損失",
    "href": "MinimizeRegrex/summary.html#ある時点での-minimax-損失",
    "title": "Regret 最小化の概要",
    "section": "ある時点での minimax 損失",
    "text": "ある時点での minimax 損失\nある時点における損失 \\(V\\) を\n\\[V(a,y)=-ay+\\frac{a}{2}+\\phi(\\xi)a^2+\\alpha\\left(x-\\frac{1}{2}\\right)\\tag{27}\\]\nとする。\\(\\alpha\\) は任意の定数である。\nここで、ある時点における minimax 損失 \\(V^*\\) を\n\\[V^*=\\min_a\\max_yV(a,y)\\tag{28}\\]\nとする。\n\\[\\forall y^0\\in\\{0,1\\},\\ V^*=V(\\alpha,y^0)=\\phi(\\xi)\\alpha^2\\tag{29}\\]",
    "crumbs": [
      "リグレット最小化",
      "Regret 最小化の概要"
    ]
  },
  {
    "objectID": "MinimizeRegrex/summary.html#オンライン予測式の導出",
    "href": "MinimizeRegrex/summary.html#オンライン予測式の導出",
    "title": "Regret 最小化の概要",
    "section": "オンライン予測式の導出",
    "text": "オンライン予測式の導出\n\\((8)\\) , \\((18)\\) より\n\\[R=\\sum_{t=1}^T l(y_t,a_t)-\\min_{\\hat a_1,\\ldots,\\hat a_T}\\left\\{\\sum_{t=1}^Tl(y_t,\\hat a_t)+\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2\\right\\}\\]\n\\[l(a_t,y_t)=-a_ty_t+\\frac{a_t}{2}+f(\\xi_t)+\\phi(\\xi_t)(a_t^2-\\xi_t^2)\\]\nであり、　\\((9)\\) より、minimax リグレット \\(R^*\\) は\n\\[R^*=\\min_{a_t}\\max_{y_t}\\cdots\\min_{a_T}\\max_{y_T}\\sum_{t=1}^T l(y_t,a_t)-\\min_{\\hat a_1,\\ldots,\\hat a_T}\\left\\{\\sum_{t=1}^Tl(y_t,\\hat a_t)+\\lambda \\sum_{t=1}^{T+1}\\left(\\hat a_t-\\hat a_{t-1}\\right)^2\\right\\}\\]\nであった。\\(R\\) の第二項は \\(-L^*\\) であらわせるため、\n\\[\n\\begin{align}\n\\mathbf Y_t &=\\begin{pmatrix}y_1 & \\cdots & y_t\\end{pmatrix}\\tag{30} \\\\\nV(\\mathbf Y_T) &= -L^* \\tag{31}\\\\\nV(\\mathbf Y_{t-1}) &= \\min_{a_t}\\max_{y_t}\\left\\{-a_ty_t+\\frac{y_t}{2}-f(\\xi_t)+\\phi(\\xi_t)(a_t^2-\\xi_t^2)\\right\\}+V(\\mathbf Y_t) \\tag{32}\n\\end{align}\n\\]\nこのように定義すると、\\(R^*\\) は\n\\[R^*=V(\\mathbf Y_0)\\tag{33}\\]\nとなる\n予測の式を立てる際に試行 \\(t\\) におけるある実数値を \\(d_t\\) 、大きさ \\(t\\times t\\) の行列を \\(\\mathbf R_t\\) とおき、\n\\[\n\\begin{align}\nd_t &= \\frac{c_t}{16}\\tag{34} \\\\\n\\mathbf R_t &= \\begin{pmatrix}\\mathbf A_t & \\mathbf b_t \\\\ \\mathbf b_t^T & c_t\\tag{35}\\end{pmatrix} \\\\\n\\mathbf R_T &= \\left(\\mathbf \\Phi_T+\\lambda\\mathbf K_T\\right)^{-1}\\tag{36} \\\\\n\\mathbf R_{t-1} &= \\mathbf A_t + \\phi(\\xi_t)\\mathbf b_t\\mathbf b_t^T\\tag{37}\n\\end{align}\n\\]\nと定義する。\n\n定理 1\n\\[\nV(\\mathbf Y_t)=\\frac{1}{4}\\left(\\mathbf Y_t-\\frac{1}{2}\\mathbf 1_t\\right)^T\\mathbf R_t\\left(\\mathbf Y_t-\\frac{1}{2}\\mathbf 1_t\\right)-\\mathbf F_t^T\\mathbf 1_t+\\Xi_t^T\\mathbf\\Phi_t\\Xi_t+\\sum_{s=t+1}^Td_s\\tag{38}\n\\]\n\\[\na_t=\\frac{1}{2}\\left(\\mathbf Y_{t-1}-\\frac{1}{2}\\mathbf 1_{t-1}\\right)^T\\mathbf b_t\\tag{39}\n\\]\n\n証明\n\\((38)\\) の証明に帰納法を用いる。\nThe basis\n\\(V(\\mathbf Y_T)\\) を証明する。\\((31)\\) を再掲する。\n\\[V(\\mathbf Y_T)=-L^*\\]\n\\((24)\\) を再掲する。\n\\[L^* =-\\frac{1}{4}\\left(\\mathbf Y-\\frac{1}{2}\\mathbf 1\\right)^T\\left(\\mathbf \\Phi+\\lambda \\mathbf K\\right)^{-1}\\left(\\mathbf Y-\\frac{1}{2}\\mathbf 1\\right)+\\mathbf F^T\\mathbf 1 - \\mathbf\\Xi^T\\mathbf\\Phi\\mathbf\\Xi\\]\nこれらの式に現在の記法に倣って添え字を加え、\\((36)\\) を使うと\n\\[V(\\mathbf Y_T)=\\frac{1}{4}\\left(\\mathbf Y_T-\\frac{1}{2}\\mathbf 1_T\\right)^T\\mathbf R_T\\left(\\mathbf Y_T-\\frac{1}{2}\\mathbf 1_T\\right)-\\mathbf F_T^T\\mathbf 1_T + \\mathbf\\Xi_T^T\\mathbf\\Phi_T\\mathbf\\Xi_T\\tag{40}\\]\nとなり、 \\((38)\\) が成り立つ。\nThe steps\n\\(V(\\mathbf Y_t)\\) が成り立つと仮定したとき \\(V(\\mathbf Y_{t-1})\\) が成立することを証明する。\n\\((32)\\) に \\((38)\\) の \\(V(\\mathbf Y_t)\\) を代入すると\n\\[\n\\begin{split}\nV(\\mathbf Y_{t-1}) =& \\min_{a_t}\\max_{y_t}\\left\\{-a_ty_t+\\frac{y_t}{2}-f(\\xi_t)+\\phi(\\xi_t)(a_t^2-\\xi_t^2)\\right\\} \\\\\n&+\\frac{1}{4}\\left(\\mathbf Y_t-\\frac{1}{2}\\mathbf 1_t\\right)^T\\mathbf R_t\\left(\\mathbf Y_t-\\frac{1}{2}\\mathbf 1_t\\right)-\\mathbf F_t^T\\mathbf 1_t+\\Xi_t^T\\mathbf\\Phi_t\\Xi_t+\\sum_{s=t+1}^Td_s \\\\\n\\end{split}\\tag{41}\n\\]\nとなる。\\((35)\\) の \\(\\mathbf R_t\\) の定義より\n\\[\n\\begin{split}\n\\left(\\mathbf Y_t-\\frac{1}{2}\\mathbf 1_t\\right)^T\\mathbf R_t\\left(\\mathbf Y_t-\\frac{1}{2}\\mathbf 1_t\\right) =& \\left\\{\\begin{pmatrix}\\mathbf Y_{t-1} \\\\ y_t\\end{pmatrix}-\\frac{1}{2}\\begin{pmatrix}\\mathbf 1_{t-1} \\\\ 1\\end{pmatrix}\\right\\}^T\\begin{pmatrix}\\mathbf A_t & \\mathbf b_t \\\\ \\mathbf b_t^T & c_t\\end{pmatrix}\\left\\{\\begin{pmatrix}\\mathbf Y_{t-1} \\\\ y_t\\end{pmatrix}-\\frac{1}{2}\\begin{pmatrix}\\mathbf 1_{t-1} \\\\ 1\\end{pmatrix}\\right\\} \\\\\n=&\\left\\{\\begin{pmatrix}\\mathbf Y_{t-1} \\\\ y_t\\end{pmatrix}-\\frac{1}{2}\\begin{pmatrix}\\mathbf 1_{t-1} \\\\ 1\\end{pmatrix}\\right\\}^T\\begin{pmatrix}\\displaystyle\\mathbf A_t\\left(\\mathbf Y_{t-1}-\\frac{1}{2}\\mathbf 1_{t-1}\\right)+\\mathbf b_t\\left(y_t-\\frac{1}{2}\\right) \\\\\\displaystyle \\mathbf b_t^T\\left(\\mathbf Y_{t-1}-\\frac{1}{2}\\mathbf 1_{t-1}\\right)+c_t\\left(y_t-\\frac{1}{2}\\right)\\end{pmatrix} \\\\\n=&\\left(\\mathbf Y_{t-1}-\\frac{1}{2}\\mathbf 1_{t-1}\\right)^T\\mathbf A_t\\left(\\mathbf Y_{t-1}-\\frac{1}{2}\\mathbf 1_{t-1}\\right) \\\\\n&+2\\left(y_t-\\frac{1}{2}\\right)\\left(\\mathbf Y_{t-1}-\\frac{1}{2}\\mathbf 1_{t-1}\\right)^T\\mathbf b_t \\\\\n&+c_t\\left(y_t-\\frac{1}{2}\\right)^2\n\\end{split}\\tag{42}\n\\]\nが成り立ち、\n\\[\\mathbf F_t^T\\mathbf 1_t=\\mathbf F_{t-1}^T\\mathbf 1_{t-1}+f(\\xi_t)\\tag{43}\\]\n\\[\n\\mathbf\\Xi_t^T\\mathbf\\Phi_t\\mathbf\\Xi_t = \\mathbf\\Xi_t^T\\begin{pmatrix}\\mathbf\\Phi_{t-1}\\mathbf\\Xi_{t-1} \\\\ \\phi(\\xi_t)\\xi_t\\end{pmatrix}=\\mathbf\\Xi_{t-1}^T\\mathbf\\Phi_{t-1}\\mathbf\\Xi_{t-1}+\\phi(\\xi_t)\\xi_t^2\\tag{44}\n\\]\n\\[\n\\begin{align}\nV(\\mathbf Y_{t-1}) &= \\frac{1}{4}\\left(\\mathbf Y_{t-1}-\\frac{1}{2}\\mathbf 1_{t-1}\\right)^T\\mathbf A_t\\left(\\mathbf Y_{t-1}-\\frac{1}{2}\\mathbf 1_{t-1}\\right)+\\mathbf F_{t-1}^T\\mathbf 1_{t-1}+\\mathbf\\Xi_{t-1}^T\\mathbf\\Phi_{t-1}\\mathbf\\Xi_{t-1}\n\\end{align}\n\\]\n\\(f(\\xi_t)\\) の \\(\\pm\\) は？ \\(L^*\\) の証明をして、 \\(\\mathbf F_t^T\\mathbf 1_t\\) の正負が反対にならないか確かめる。",
    "crumbs": [
      "リグレット最小化",
      "Regret 最小化の概要"
    ]
  },
  {
    "objectID": "Exp/comp.html",
    "href": "Exp/comp.html",
    "title": "評価",
    "section": "",
    "text": "N = 2\nG = 1/2**8 * jnp.identity(N, dtype=jnp.float32)\nSigma = 5.0 * jnp.identity(N, dtype=jnp.float32)\nw0 = jnp.ones((N,), dtype=jnp.float32)/jnp.sqrt(N)\npropy1 = 0.5\n\nW_norm, RMS_Wtt_EKF, RMS_Wtt_VA, RMS_Wtt_EM = RMS(\n  key=jrd.PRNGKey(0), \n  N=2, \n  T=1000, \n  G=G,\n  w0=w0,\n  Sigma=Sigma,\n  P0=G,\n  propy1=propy1)\n\n\nplt.scatter(W_norm, RMS_Wtt_EKF, label=\"EKF\")\nplt.scatter(W_norm, RMS_Wtt_VA, marker='x', label=\"VA\")\nplt.scatter(W_norm, RMS_Wtt_EM, marker='.', label=\"EM\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nN = 2\nG = 1/2**8 * jnp.identity(N, dtype=jnp.float32)\nSigma = 5.0 * jnp.identity(N, dtype=jnp.float32)\nw0 = jnp.ones((N,), dtype=jnp.float32)/jnp.sqrt(N)\npropy1 = 0.5\n\nRMS_Wtt_EKF, RMS_Wtt_VA, RMS_Wtt_EM = losi_error(\n  key=jrd.PRNGKey(0), \n  N=2, \n  T=1000, \n  G=G,\n  w0=w0,\n  Sigma=Sigma,\n  P0=G,\n  propy1=propy1)\n\n\nplt.plot(RMS_Wtt_EKF, label=\"EKF\")\nplt.plot(RMS_Wtt_VA, label=\"VA\")\nplt.plot(RMS_Wtt_EM, label=\"EM\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nsum(RMS_Wtt_EKF), sum(RMS_Wtt_VA), sum(RMS_Wtt_EM)\n\n(Array(10.609799, dtype=float32),\n Array(11.298924, dtype=float32),\n Array(11.056256, dtype=float32))\n\n\n\njnp.array([1,2,3])[:-1]\n\nArray([1, 2], dtype=int32)",
    "crumbs": [
      "実験関数",
      "評価"
    ]
  },
  {
    "objectID": "Exp/exp.html",
    "href": "Exp/exp.html",
    "title": "実験",
    "section": "",
    "text": "N=2\nG = 1/2**9 * jnp.identity(N, dtype=jnp.float32)\nSigma = 10* jnp.identity(N, dtype=jnp.float32)\nw0 = 0*jnp.ones((N,), dtype=jnp.float32)\npropy1 = 0.5\n\nX, Y, W, \\\n  (Wtt_EKF, Ptt_EKF), \\\n    (Wtt_VA, Ptt_VA, Xit_VA), \\\n      (Wtt_EM, Ptt_EM, Xit_EM) \\\n        = exper(\n  key=jrd.PRNGKey(422), # 822 522\n  N=N, \n  T=500, \n  G=G,\n  w0=w0,\n  Sigma=Sigma,\n  P0=G,\n  propy1=propy1)\n\n\nplt.plot(W[:,0], label=r\"$(w_0)_t$\")\nplt.plot(W[:,1], label=r\"$(w_1)_t$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.scatter(X[Y==1][100:300,0], X[Y==1][100:300,1], label=r\"$\\mathbf{x}_t\\ (y_t=1)$\")\nplt.scatter(X[Y==0][100:300,0], X[Y==0][100:300,1], label=r\"$\\mathbf{x}_t\\ (y_t=0)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(W[:,0], label=r\"$(w_0)_t$ (True Weights)\")\nplt.plot(Wtt_EKF[:,0], \"-\", label=r\"$(\\hat{w}_0)_t$, (DLR)\")\nplt.plot(Wtt_VA[:,0], \"--\", label=r\"$(\\hat{w}_0)_t$, (FU)\")\nplt.plot(Wtt_EM[:,0], \":\", label=r\"$(\\hat{w}_0)_t$, (FP)\")\nplt.xlabel(\"time\")\nplt.ylabel(\"weights\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(W[:,1], label=r\"$(w_1)_t$\")\nplt.plot(Wtt_EKF[:,1], label=r\"$(\\hat{w}_1)_t$, (EKF)\")\nplt.plot(Wtt_VA[:,1], label=r\"$(\\hat{w}_1)_t$, (VA)\")\nplt.plot(Wtt_EM[:,1], label=r\"$(\\hat{w}_1)_t$, (EM)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(Ptt_EKF[:,0,0], label=r\"$(P_{1,1})_t$, (EKF)\")\nplt.plot(Ptt_VA[:,0,0], label=r\"$(P_{1,1})_t$, (VA)\")\nplt.plot(Ptt_EM[:,0,0], label=r\"$(P_{1,1})_t$, (EM)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(Ptt_EKF[:,1,1], label=r\"$(P_{2,2})_t$, (EKF)\")\nplt.plot(Ptt_VA[:,1,1], label=r\"$(P_{2,2})_t$, (VA)\")\nplt.plot(Ptt_EM[:,1,1], label=r\"$(P_{2,2})_t$, (EM)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(simple.losi(jnp.sum(W*X, axis=1)), 'o', label=r\"$(w_0)_t$\")\nplt.plot(simple.losi(jnp.sum(Wtt_EKF*X, axis=1)), 'o', label=r\"$(\\hat{w}_0)_t$, (EKF)\")\nplt.plot(simple.losi(jnp.sum(Wtt_VA*X, axis=1)), 'o', label=r\"$(\\hat{w}_0)_t$, (VA)\")\nplt.plot(simple.losi(jnp.sum(Wtt_EM*X, axis=1)), 'o', label=r\"$(\\hat{w}_0)_t$, (EM)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\ntrue_line = simple.losi(jnp.sum(W*X, axis=1))\nplt.plot(simple.losi(jnp.sum(Wtt_EKF*X, axis=1)) - true_line, label=r\"$(\\hat{w}_0)_t$, (EKF)\")\nplt.plot(simple.losi(jnp.sum(Wtt_VA*X, axis=1)) - true_line, label=r\"$(\\hat{w}_0)_t$, (VA)\")\nplt.plot(simple.losi(jnp.sum(Wtt_EM*X, axis=1)) - true_line, label=r\"$(\\hat{w}_0)_t$, (EM)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nprint(jnp.sum((simple.losi(jnp.sum(Wtt_EKF*X, axis=1)) - true_line)**2))\nprint(jnp.sum((simple.losi(jnp.sum(Wtt_VA*X, axis=1)) - true_line)**2))\nprint(jnp.sum((simple.losi(jnp.sum(Wtt_EM*X, axis=1)) - true_line)**2))\n\n7.2249694\n7.6888556\n7.6575623\n\n\n\nimport pandas as pd\n\n\ndf1 = pd.read_csv(\"data.csv\", sep=\"\\t\")\ndf1\n\n\n\n\n\n\n\n\nN\nG\nSigma\npropy1\nerr_EKF_sc\nerr_VA_sc\nerr_EM_sc\n\n\n\n\n2\n2.0\n0.062500\n0.50\n0.5\n0.093420\n0.093336\n0.093043\n\n\n4\n2.0\n0.062500\n1.00\n0.5\n0.093443\n0.091697\n0.091294\n\n\n6\n2.0\n0.062500\n2.00\n0.5\n0.093836\n0.089228\n0.088805\n\n\n8\n2.0\n0.062500\n4.00\n0.5\n0.094327\n0.086147\n0.085870\n\n\n10\n2.0\n0.062500\n8.00\n0.5\n0.096139\n0.082455\n0.082723\n\n\n18\n2.0\n0.015625\n2.00\n0.5\n0.093420\n0.093336\n0.093043\n\n\n20\n2.0\n0.015625\n4.00\n0.5\n0.093443\n0.091697\n0.091294\n\n\n22\n2.0\n0.015625\n8.00\n0.5\n0.093836\n0.089228\n0.088805\n\n\n34\n2.0\n0.003906\n8.00\n0.5\n0.093420\n0.093336\n0.093043\n\n\n48\n2.0\n0.000244\n0.25\n0.5\n0.039164\n0.039163\n0.039163\n\n\n60\n4.0\n0.062500\n0.25\n0.5\n0.100617\n0.099913\n0.099700\n\n\n62\n4.0\n0.062500\n0.50\n0.5\n0.093656\n0.091329\n0.091214\n\n\n64\n4.0\n0.062500\n1.00\n0.5\n0.085952\n0.080761\n0.080898\n\n\n66\n4.0\n0.062500\n2.00\n0.5\n0.078222\n0.070136\n0.070658\n\n\n68\n4.0\n0.062500\n4.00\n0.5\n0.072354\n0.060668\n0.061745\n\n\n70\n4.0\n0.062500\n8.00\n0.5\n0.064038\n0.051949\n0.053414\n\n\n76\n4.0\n0.015625\n1.00\n0.5\n0.100617\n0.099913\n0.099700\n\n\n78\n4.0\n0.015625\n2.00\n0.5\n0.093656\n0.091329\n0.091214\n\n\n80\n4.0\n0.015625\n4.00\n0.5\n0.085952\n0.080761\n0.080898\n\n\n82\n4.0\n0.015625\n8.00\n0.5\n0.078222\n0.070136\n0.070658\n\n\n92\n4.0\n0.003906\n4.00\n0.5\n0.100617\n0.099913\n0.099700\n\n\n94\n4.0\n0.003906\n8.00\n0.5\n0.093656\n0.091329\n0.091214\n\n\n120\n8.0\n0.062500\n0.25\n0.5\n0.096732\n0.091938\n0.092006\n\n\n122\n8.0\n0.062500\n0.50\n0.5\n0.083484\n0.076024\n0.076319\n\n\n124\n8.0\n0.062500\n1.00\n0.5\n0.071028\n0.062117\n0.062546\n\n\n126\n8.0\n0.062500\n2.00\n0.5\n0.059638\n0.050017\n0.050485\n\n\n128\n8.0\n0.062500\n4.00\n0.5\n0.048867\n0.039920\n0.040344\n\n\n130\n8.0\n0.062500\n8.00\n0.5\n0.038852\n0.031403\n0.031772\n\n\n132\n8.0\n0.015625\n0.25\n0.5\n0.120174\n0.119479\n0.119283\n\n\n134\n8.0\n0.015625\n0.50\n0.5\n0.109672\n0.107326\n0.107210\n\n\n136\n8.0\n0.015625\n1.00\n0.5\n0.096732\n0.091938\n0.092006\n\n\n138\n8.0\n0.015625\n2.00\n0.5\n0.083484\n0.076024\n0.076319\n\n\n140\n8.0\n0.015625\n4.00\n0.5\n0.071028\n0.062117\n0.062546\n\n\n142\n8.0\n0.015625\n8.00\n0.5\n0.059638\n0.050017\n0.050485\n\n\n146\n8.0\n0.003906\n0.50\n0.5\n0.125066\n0.124960\n0.124792\n\n\n148\n8.0\n0.003906\n1.00\n0.5\n0.120174\n0.119479\n0.119283\n\n\n150\n8.0\n0.003906\n2.00\n0.5\n0.109672\n0.107326\n0.107210\n\n\n152\n8.0\n0.003906\n4.00\n0.5\n0.096732\n0.091938\n0.092006\n\n\n154\n8.0\n0.003906\n8.00\n0.5\n0.083484\n0.076024\n0.076319\n\n\n156\n8.0\n0.000977\n0.25\n0.5\n0.104002\n0.103998\n0.103986\n\n\n162\n8.0\n0.000977\n2.00\n0.5\n0.125066\n0.124960\n0.124792\n\n\n164\n8.0\n0.000977\n4.00\n0.5\n0.120174\n0.119479\n0.119283\n\n\n166\n8.0\n0.000977\n8.00\n0.5\n0.109672\n0.107326\n0.107210\n\n\n168\n8.0\n0.000244\n0.25\n0.5\n0.076621\n0.076618\n0.076616\n\n\n170\n8.0\n0.000244\n0.50\n0.5\n0.090635\n0.090629\n0.090625\n\n\n172\n8.0\n0.000244\n1.00\n0.5\n0.104002\n0.103998\n0.103986\n\n\n178\n8.0\n0.000244\n8.00\n0.5\n0.125066\n0.124960\n0.124792\n\n\n\n\n\n\n\n\ndf1[(df1[\"err_EKF_sc\"] &lt; df1[\"err_VA_sc\"])].groupby(\"N\").count()\n\n\n\n\n\n\n\n\nG\nSigma\npropy1\nerr_EKF_sc\nerr_VA_sc\nerr_EM_sc\n\n\nN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf1[\"err_EKF_sc\"] &gt; df1[\"err_VA_sc\"]\n\n2      True\n4      True\n6      True\n8      True\n10     True\n18     True\n20     True\n22     True\n34     True\n48     True\n60     True\n62     True\n64     True\n66     True\n68     True\n70     True\n76     True\n78     True\n80     True\n82     True\n92     True\n94     True\n120    True\n122    True\n124    True\n126    True\n128    True\n130    True\n132    True\n134    True\n136    True\n138    True\n140    True\n142    True\n146    True\n148    True\n150    True\n152    True\n154    True\n156    True\n162    True\n164    True\n166    True\n168    True\n170    True\n172    True\n178    True\ndtype: bool",
    "crumbs": [
      "実験関数",
      "実験"
    ]
  },
  {
    "objectID": "wEXP_PVA/index.html",
    "href": "wEXP_PVA/index.html",
    "title": "EKFとVAの混合",
    "section": "",
    "text": "EKFとVAの混合。\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\n\n\n\n\n\nw:EXP, P:VA\n\n\n\\(w\\) の推定を拡張カルマンフィルタによって行い、 \\(P\\) の推定を変分近似によって行う。\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "EKFとVAの合成"
    ]
  },
  {
    "objectID": "EKF/index.html",
    "href": "EKF/index.html",
    "title": "非線形カルマンフィルタ",
    "section": "",
    "text": "拡張カルマンフィルタなど。\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\n\n\n\n\n\n非線形カルマンフィルタの概要\n\n\n概要\n\n\n\n\n\n\nExtended Kalman Filter\n\n\nDynamic Logistic Regression で導出された拡張カルマンフィルタ\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "非線形カルマンフィルタ"
    ]
  },
  {
    "objectID": "EKF/summary.html",
    "href": "EKF/summary.html",
    "title": "非線形カルマンフィルタの概要",
    "section": "",
    "text": "任意の行列\\(\\mathbf A\\)に対して、次の逆行列の公式が成り立つ：\n\\[\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ \\mathbf A & \\mathbf I\\end{pmatrix}^{-1}=\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ -\\mathbf A & \\mathbf I\\end{pmatrix}\\tag{1}\\]\n\n\n\n定義\n区分行列 \\(\\mathbf M\\) を\n\\[\\mathbf M=\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D  \\end{pmatrix}\\tag{2}\\]\nとしたとき、区画 \\(\\mathbf D\\) に関する Schur 補行列とは\n\\[\\mathbf M/\\mathbf D=\\mathbf A-\\mathbf B\\mathbf D^{-1}\\mathbf C\\tag{3}\\]\nで与えられる。区画 \\(\\mathbf A\\) に関する Schur 補行列とは\n\\[\\mathbf M/\\mathbf A=\\mathbf D-\\mathbf C\\mathbf A^{-1}\\mathbf B\\tag{4}\\]\nで与えられる。\n背景\nSchur 補行列はブロック三角行列を掛けるという形でガウス消去法を施した結果として生じる。\n\\[\n\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\\end{pmatrix}\n\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ \\mathbf -\\mathbf D^{-1}\\mathbf C & \\mathbf I\\end{pmatrix}\n=\n\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf B \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\n\\tag{5}\n\\]\n\\[\n\\begin{pmatrix}\\mathbf I & -\\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\n\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\\end{pmatrix}\n=\n\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf 0 \\\\ \\mathbf C & \\mathbf D\\end{pmatrix}\n\\tag{6}\n\\]\n\\[\n\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ -\\mathbf C\\mathbf A^{-1} & \\mathbf I\\end{pmatrix}\n\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\\end{pmatrix}\n=\n\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf 0 & \\mathbf M/\\mathbf A\\end{pmatrix}\n\\tag{7}\n\\]\n\\[\n\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\\end{pmatrix}\n\\begin{pmatrix}\\mathbf I & -\\mathbf A^{-1}\\mathbf B \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\n=\n\\begin{pmatrix}\\mathbf A & \\mathbf 0 \\\\ \\mathbf C & \\ \\mathbf M/\\mathbf A\\end{pmatrix}\n\\tag{8}\n\\]\n\n\n\n定理\n\\[\n\\begin{pmatrix}\n\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\mathbf I & \\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf A-\\mathbf B\\mathbf D^{-1}\\mathbf C & \\mathbf 0 \\\\ \\mathbf 0 & \\mathbf D\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf I & \\mathbf 0 \\\\ \\mathbf D^{-1}\\mathbf C & \\mathbf I\n\\end{pmatrix}\n\\tag{9}\\]\n特に\n\\[\n\\begin{pmatrix}\n\\mathbf A & \\mathbf b \\\\ \\mathbf b^T & c\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\mathbf I & c^{-1}\\mathbf b \\\\ \\mathbf 0^T & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf A-c^{-1}\\mathbf b\\mathbf b^T & \\mathbf 0 \\\\ \\mathbf 0^T & c\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf I & \\mathbf 0 \\\\ c^{-1}\\mathbf b^T & 1\n\\end{pmatrix}\n\\tag{10}\\]\n証明\n\\(\\mathbf M\\) , \\(\\mathbf N\\) をそれぞれ次のように定義する。 \\(\\mathbf N\\) は \\(\\mathbf M\\) に \\((5)\\) の操作を施したときの右側の行列である。\n\\[\\mathbf M=\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\\end{pmatrix},\\ \\mathbf N=\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf B \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\\tag{11}\\]\n\\[\\mathbf M\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ -\\mathbf D^{-1}\\mathbf C & \\mathbf I\\end{pmatrix}=\\mathbf N\\tag{12}\\]\n\\((6)\\) の左辺右側の行列と \\(\\mathbf N\\) の、右側のブロック要素はそれぞれ \\(\\mathbf B, \\mathbf D\\) であり、\\((6)\\) の左辺左側の行列は \\(\\mathbf B, \\mathbf D\\) しか使われていないから、\\((6)\\) の左辺左側の行列をそのまま使って、\n\\[\\begin{pmatrix}\\mathbf I & -\\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\\mathbf N=\\begin{pmatrix}\\mathbf N/\\mathbf D & \\mathbf 0 \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\\tag{13}\\]\nと表せる。\nここで、\n\\[\\mathbf N/\\mathbf D=\\mathbf M/\\mathbf D-\\mathbf B\\mathbf D^{-1}\\mathbf O=\\mathbf M/\\mathbf D\\tag{14}\\]\nであるから、\n\\[\\begin{pmatrix}\\mathbf I & -\\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\\mathbf N=\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf 0 \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\\tag{15}\\]\nが成り立つ。 \\((12)\\) と \\((15)\\) から、\n\\[\\begin{pmatrix}\\mathbf I & -\\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\\mathbf M\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ -\\mathbf D^{-1}\\mathbf C & \\mathbf I\\end{pmatrix}=\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf 0 \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\\tag{16}\\]\nである。 \\((1)\\) を用いると、\n\\[\\mathbf M=\\begin{pmatrix}\\mathbf I & \\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf 0 \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ \\mathbf D^{-1}\\mathbf C & \\mathbf I\\end{pmatrix}\\tag{17}\\]\nが成り立つ。\n\n\n\n定理\n区分行列 \\(\\mathbf M\\) を\n\\[\\mathbf M=\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D  \\end{pmatrix}\\tag{18}\\]\nとしたとき、\n\\[\n\\begin{split}\n\\mathbf M^{-1} &=\\begin{pmatrix}\\mathbf A^{-1}+\\mathbf A^{-1}\\mathbf B(\\mathbf M/\\mathbf A)^{-1}\\mathbf C\\mathbf A^{-1} & -\\mathbf A^{-1}\\mathbf B(\\mathbf M/\\mathbf A)^{-1} \\\\ -(\\mathbf M/\\mathbf A)^{-1}\\mathbf C\\mathbf A^{-1} & (\\mathbf M/\\mathbf A)^{-1}\\end{pmatrix} \\\\\n&=\\begin{pmatrix}(\\mathbf M/\\mathbf D)^{-1} & -(\\mathbf M/\\mathbf D)^{-1}\\mathbf B\\mathbf D^{-1} \\\\ -\\mathbf D^{-1}\\mathbf C(\\mathbf M/\\mathbf D)^{-1} & \\mathbf D^{-1}+\\mathbf D^{-1}\\mathbf C(\\mathbf M/\\mathbf D)^{-1}\\mathbf B\\mathbf D^{-1}\\end{pmatrix}\n\\end{split}\n\\tag{19}\\]\nが成り立つ。\n\n\n\n\\((59)\\) の行列式は、右辺の左右の行列の行列式は \\(1\\) になるから\n\\[\n\\det\\begin{pmatrix}\n\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\n\\end{pmatrix}\n=\n\\det\\left(\\mathbf A-\\mathbf B\\mathbf D^{-1}\\mathbf C\\right)\\det\\mathbf D\n\\tag{20}\\]\n特に、\n\\[\n\\begin{split}\n\\det\\begin{pmatrix}\n\\mathbf A & \\mathbf b \\\\ \\mathbf b^T & c\n\\end{pmatrix}\n&=\n\\det\\left(\\mathbf A-c^{-1}\\mathbf b\\mathbf b^T\\right)\\det c \\\\\n&=\n\\det\\left(c\\mathbf A-\\mathbf b\\mathbf b^T\\right)\n\\end{split}\n\\tag{21}\\]\n\n\n\n定理\n対称な行列 \\(\\mathbf M\\) を\n\\[\\mathbf M=\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf B^T & \\mathbf C\\end{pmatrix}\\tag{22}\\]\nとすると、\n\\[\\text{If}\\ \\mathbf C\\succ 0, \\text{then}\\ (\\mathbf M\\succeq 0\\iff \\mathbf M/\\mathbf C\\succeq 0)\\tag{23}\\]\n\\[\\text{If}\\ \\mathbf A\\succ 0, \\text{then}\\ (\\mathbf M\\succeq 0\\iff \\mathbf M/\\mathbf A\\succeq 0)\\tag{24}\\]\nが成り立つ。\n定理\n\\(\\mathbb E\\) を任意の期待値： \\(\\mathbb E_{\\mathbf x,\\mathbf y}, \\mathbb E_{\\mathbf x\\mid\\mathbf y}, \\mathbb E_{\\mathbf y\\mid\\mathbf x}\\) であるとする。\n\\[\n\\begin{pmatrix} \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf f(\\mathbf x,\\mathbf y)^T] & \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\\\ \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]^T & \\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\end{pmatrix}\\succeq 0\n\\tag{25}\\]\n証明\n\\(\\mathbf h(\\mathbf x,\\mathbf y)\\) を\n\\[\\mathbf h(\\mathbf x,\\mathbf y)=\\begin{pmatrix}\\mathbf f(\\mathbf x,\\mathbf y) \\\\ \\mathbf g(\\mathbf x,\\mathbf y)\\end{pmatrix}\\tag{26}\\]\nとすると、任意のベクトル \\(\\mathbf u\\) に対して\n\\[\n\\begin{split}\n&\\phantom{=}\\mathbf u^T\\begin{pmatrix} \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf f(\\mathbf x,\\mathbf y)^T] & \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\\\ \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]^T & \\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\end{pmatrix}\\mathbf u \\\\\n&= \\mathbf u^T\\mathbb E[\\mathbf h(\\mathbf x,\\mathbf y)\\mathbf h(\\mathbf x,\\mathbf y)^T]\\mathbf u \\\\\n&= \\mathbb E[(\\mathbf h(\\mathbf x,\\mathbf y)\\mathbf u)^2] \\\\\n&\\succeq 0\n\\end{split}\n\\tag{27}\\]\n定理\n\\(\\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]\\succ 0\\) のとき、\n\\[\\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf f(\\mathbf x,\\mathbf y)^T]\\succeq\\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]\\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]^{-1}\\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]^T\\tag{28}\\]\nが成り立つ。\n証明\n\\[\\mathbf M=\\begin{pmatrix} \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf f(\\mathbf x,\\mathbf y)^T] & \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\\\ \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]^T & \\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\end{pmatrix}\\tag{29}\\]\nとすると、\\((59)\\) より \\(\\mathbf M\\succeq 0\\) であり、よって \\((59)\\) より \\(\\mathbf M/\\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]\\succeq 0\\) である。\n\n\n\n\\(\\mathbf w\\) を未知変数、 \\(y\\) を観測変数とする。 Fisher 情報行列を\n\\[\n\\begin{split}\nI(\\mathbf w) &=-\\mathbb E_{y\\mid \\mathbf w}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y\\mid\\mathbf w)\\right] \\\\\n&= -\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y\\mid\\mathbf w)\\right)p(y\\mid\\mathbf w)dy \\\\\n&\\in\\mathbb R^{n\\times n}\n\\end{split}\n\\tag{30}\\]\nとする。各要素は\n\\[\nI_{ij}=-\\mathbb E_{y\\mid\\mathbf w}\\left[\\frac{\\partial^2}{\\partial w_i\\partial w_j}\\ln p(y\\mid\\mathbf w)\\right]\n\\tag{31}\\]\nとなる。\n\n\n\n\\[\n\\begin{split}\nI(\\mathbf w) &=-\\mathbb E_{y\\mid \\mathbf w}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y\\mid\\mathbf w)\\right] \\\\\n&= -\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y\\mid\\mathbf w)\\right)p(y\\mid\\mathbf w)dy \\\\\n&= -\\int\\left(\\frac{\\partial}{\\partial\\mathbf w}\\left[\\frac{1}{p(y\\mid\\mathbf w)}\\frac{\\partial}{\\partial\\mathbf w}p(y\\mid\\mathbf w)\\right]\\right)p(y\\mid\\mathbf w)dy \\\\\n&= -\\int\\left(-\\left[\\frac{1}{p(y\\mid\\mathbf w)}\\right]^2\\left[\\frac{\\partial}{\\partial\\mathbf w}p(y\\mid\\mathbf w)\\right]\\left[\\frac{\\partial}{\\partial\\mathbf w}p(y\\mid\\mathbf w)\\right]^T+\\frac{1}{p(y\\mid\\mathbf w)}\\frac{\\partial^2}{\\partial\\mathbf w^2}p(y\\mid\\mathbf w)\\right)p(y\\mid\\mathbf w)dy \\\\\n&= \\int\\left(\\frac{1}{p(y\\mid\\mathbf w)}\\frac{\\partial}{\\partial \\mathbf w}p(y\\mid\\mathbf w)\\right)\\left(\\frac{1}{p(y\\mid\\mathbf w)}\\frac{\\partial}{\\partial \\mathbf w}p(y\\mid\\mathbf w)\\right)^Tp(y\\mid\\mathbf w)dy-\\int\\frac{\\partial^2}{\\partial\\mathbf w^2}p(y\\mid\\mathbf w)dy \\\\\n&= \\int\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^Tp(y\\mid\\mathbf w)dy-\\underbrace{\\frac{\\partial^2}{\\partial\\mathbf w^2}\\int p(y\\mid\\mathbf w)dy}_\\mathbf O \\\\\n&= \\mathbb E_{y\\mid\\mathbf w}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^T\\right]\n\\end{split}\n\\tag{32}\\]\nであるから、Fisher 情報行列は\n\\[\nI(\\mathbf w) =-\\mathbb E_{y\\mid \\mathbf w}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y\\mid\\mathbf w)\\right] = \\mathbb E_{y\\mid\\mathbf w}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^T\\right]\n\\tag{33}\\]\nと表せる。\n\n\n\n定理\n\\(I(\\mathbf w)\\succ 0\\) のとき、\n\\[\\mathbb E_{y\\mid\\mathbf w}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right]\\succeq I^{-1}(\\mathbf w)\\tag{34}\\]\nが成り立つ。ただし、 \\(\\mathbf f(y)\\) は不偏推定値とする。つまり、次式が成り立つとする。\n\\[\\mathbb E_{y\\mid\\mathbf w}[\\mathbf f(y)]=\\mathbf w\\tag{35}\\]\n証明\nSchur 補行列の正定値性 \\((57)\\) より、\n\\[\n\\begin{split}\n&\\phantom{=}\\mathbb E_{y\\mid\\mathbf w}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right] \\\\\n&\\succeq \\mathbb E_{y\\mid\\mathbf w}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^T\\right]I^{-1}(\\mathbf w)\\mathbb E_{y\\mid\\mathbf w}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^T\\right]^T\n\\end{split}\n\\tag{36}\\]\nここで、\n\\[\n\\begin{split}\n\\mathbb E_{y\\mid\\mathbf w}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^T\\right] &= \\int\\left(\\mathbf w-\\mathbf f(y)\\right)\\left(\\frac{1}{p(y\\mid\\mathbf w)}\\frac{\\partial}{\\partial\\mathbf w}p(y\\mid\\mathbf w)\\right)^Tp(y\\mid\\mathbf w)dy \\\\\n&= \\int \\left(\\mathbf w - \\mathbf f(y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}p(y\\mid\\mathbf w)\\right)^Tdy \\\\\n&= \\mathbf w\\left( \\frac{\\partial}{\\partial \\mathbf w} \\int p(y\\mid\\mathbf w) dy \\right)^T-\\frac{\\partial}{\\partial \\mathbf w^T}\\int \\mathbf f(y) p(y\\mid\\mathbf w)dy \\\\\n&= \\underbrace{\\mathbf w\\left(\\frac{\\partial}{\\partial \\mathbf w} 1\\right)^T}_\\mathbf O-\\frac{\\partial}{\\partial\\mathbf w^T}\\mathbf w \\\\\n&= -\\mathbf I\n\\end{split}\n\\tag{37}\\]\nが成り立つ。 \\(\\mathbf I\\) は単位行列を表す。\n\n\n\n\\(\\mathbf w\\) を未知変数、 \\(y\\) を観測変数とする。 ベイズ情報行列を\n\\[\n\\begin{split}\nJ &=-\\mathbb E_{\\mathbf w, y}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w, y)\\right] \\\\\n&= -\\int\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w, y)\\right)p(\\mathbf w, y)dyd\\mathbf w \\\\\n&\\in\\mathbb R^{n\\times n}\n\\end{split}\n\\tag{38}\\]\nとする。各要素は\n\\[\nJ_{ij}=-\\mathbb E_{\\mathbf w,y}\\left[\\frac{\\partial^2}{\\partial w_i\\partial w_j}\\ln p(\\mathbf w,y)\\right]\n\\tag{39}\\]\nとなる。\n\n\n\n\\[\n\\begin{split}\nJ &=-\\mathbb E_{\\mathbf w,y}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w,y)\\right] \\\\\n&= -\\int\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w,y)\\right)p(\\mathbf w,y)d\\mathbf wdy \\\\\n&= -\\int\\int\\left(\\frac{\\partial}{\\partial\\mathbf w}\\left[\\frac{1}{p(\\mathbf w,y)}\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right]\\right)p(\\mathbf w,y)d\\mathbf wdy \\\\\n&= -\\int\\int\\left(-\\left[\\frac{1}{p(\\mathbf w,y)}\\right]^2\\left[\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right]\\left[\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right]^T+\\frac{1}{p(\\mathbf w,y)}\\frac{\\partial^2}{\\partial\\mathbf w^2}p(\\mathbf w,y)\\right)p(\\mathbf w,y)d\\mathbf wdy \\\\\n&= \\int\\int\\left(\\frac{1}{p(\\mathbf w,y)}\\frac{\\partial}{\\partial \\mathbf w}p(\\mathbf w,y)\\right)\\left(\\frac{1}{p(\\mathbf w,y)}\\frac{\\partial}{\\partial \\mathbf w}p(\\mathbf w,y)\\right)^Tp(\\mathbf w,y)d\\mathbf wdy-\\int\\int\\frac{\\partial^2}{\\partial\\mathbf w^2}p(\\mathbf w,y)d\\mathbf wdy \\\\\n&= \\int\\int\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)^Tp(\\mathbf w,y)d\\mathbf wdy-\\underbrace{\\frac{\\partial^2}{\\partial\\mathbf w^2}\\int\\int p(\\mathbf w,y)d\\mathbf wdy}_\\mathbf O \\\\\n&= \\mathbb E_{\\mathbf w,y}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)^T\\right]\n\\end{split}\n\\tag{40}\\]\nであり、\n\\[\n\\begin{split}\nJ &=-\\mathbb E_{\\mathbf w,y}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w,y)\\right] \\\\\n&= -\\int\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w\\mid y)\\right)p(\\mathbf w,y)d\\mathbf wdy -\\underbrace{\\int\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y)\\right)p(\\mathbf w,y)d\\mathbf wdy}_\\mathbf O \\\\\n&= \\mathbb E_{\\mathbf w,y}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w\\mid y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w\\mid y)\\right)^T\\right]\n\\end{split}\n\\tag{41}\\]\nであるから、ベイズ情報行列は\n\\[\n\\begin{split}\nJ &=-\\mathbb E_{\\mathbf w,y}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w,y)\\right] \\\\\n&= \\mathbb E_{\\mathbf w,y}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)^T\\right] \\\\\n&= \\mathbb E_{\\mathbf w,y}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w\\mid y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w\\mid y)\\right)^T\\right]\n\\end{split}\\tag{42}\n\\]\nと表せる。\n\n\n\n定理\n\\(J\\succ 0\\) のとき、\n\\[\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right]\\succeq J^{-1}\\tag{43}\\]\nが成り立つ。ただし、次式が成り立つとする。\n\\[\\lim_{\\mathbf w_i\\to\\pm\\infty}\\mathbb E_{y\\mid\\mathbf w}[\\mathbf f(y)-\\mathbf w]p(\\mathbf w)=\\lim_{\\mathbf w_i\\to\\pm\\infty}\\int (\\mathbf f(y)-\\mathbf w)p(\\mathbf w,y)dy=\\mathbf 0,\\ i=1,\\ldots,n\\tag{44}\\]\n証明\nSchur 補行列の正定値性より、\n\\[\n\\begin{split}\n&\\phantom{=}\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right] \\\\\n&\\succeq \\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(\\mathbf w,y)\\right)^T\\right]J^{-1}\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(\\mathbf w,y)\\right)^T\\right]^T\n\\end{split}\n\\tag{45}\\]\nここで、\n\\[\n\\begin{split}\n\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(\\mathbf w,y)\\right)^T\\right] &= \\int\\int\\left(\\mathbf w-\\mathbf f(y)\\right)\\left(\\frac{1}{p(\\mathbf w,y)}\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right)^Tp(\\mathbf w,y)d\\mathbf wdy \\\\\n&= \\int\\int \\left(\\mathbf w - \\mathbf f(y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right)^Td\\mathbf wdy\n\\end{split}\n\\tag{46}\\]\nが成り立つ。\\(ij\\) 要素に対して部分積分すると、\n\\[\n\\begin{split}\n& \\left\\{\\int\\int \\left(\\mathbf w - \\mathbf f(y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right)^Td\\mathbf wdy\\right\\}_{ij} \\\\\n&= \\int\\int(w_i-f_i(y))\\left(\\frac{\\partial}{\\partial w_j}p(\\mathbf w,y)\\right)d\\mathbf wdy \\\\\n&= \\int\\int\\left[(w_i-f_i(y))p(\\mathbf w,y)\\right]_{w_j=-\\infty}^{w_j=\\infty}d\\mathbf w_kdy-\\int\\int\\frac{\\partial}{\\partial w_j}(w_i-f_i(y))p(\\mathbf w,y)d\\mathbf wdy \\\\\n&= \\int\\left[\\lim_{w_j\\to\\infty}\\int(w_i-f_i(y))p(\\mathbf w,y)dy-\\lim_{w_j\\to-\\infty}\\int(w_i-f_i(y))p(\\mathbf w,y)dy\\right]d\\mathbf w_k - I_{ij} \\\\\n&= -I_{ij}\n\\end{split}\n\\tag{47}\\]\nとなる。\\(\\mathbf w_k\\) は \\(k\\neq j\\) となる全ての \\(k\\) を添字とする \\(w\\) を表す。 \\(I_{ij}\\) とは単位行列 \\(\\mathbf I\\) の \\(ij\\) 要素を表す。\n\n\n\n定理\n\\[\\mathbf w - \\mathbf f(y)=\\begin{pmatrix}\\mathbf w_a-\\mathbf f_a(y) \\\\ \\mathbf w_b-\\mathbf f_b(y)\\end{pmatrix}\\tag{48}\\]\nとおくと、ベイズ情報行列は\n\\[J=\\begin{pmatrix}\\mathbf A &\\mathbf B \\\\\\mathbf C &\\mathbf D\\end{pmatrix}\\tag{49}\\]\nと表せる。ただし、例えば \\(\\mathbf A\\) は\n\\[\\mathbf A=\\mathbb E_{\\mathbf w_a,y}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w_a}\\ln p(\\mathbf w_a\\mid y)\\right)\\left(\\frac{\\partial}{\\partial \\mathbf w_a}\\ln p(\\mathbf w_a\\mid y)\\right)^T\\right]\\tag{50}\\]\nと表す。このとき、\\(J\\succ 0\\) ならば、次を得る。\n\\[\\mathbb E_{\\mathbf w_b,y}\\left[(\\mathbf w_b-\\mathbf f_b(y))(\\mathbf w_b-\\mathbf f_b(y))^T\\right]\\succeq (J/\\mathbf A)^{-1}\\tag{51}\\]\n証明\n次の式において、\\(\\cdot\\) は省略を意味する。\n\\[\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right]=\\begin{pmatrix}\\cdot & \\cdot \\\\ \\cdot & \\mathbb E_{\\mathbf w_b,y}\\left[(\\mathbf w_b-\\mathbf f_b(y))(\\mathbf w_b-\\mathbf f_b(y))^T\\right]\\end{pmatrix}\\tag{52}\\]\n\\[J^{-1}=\\begin{pmatrix}\\cdot & \\cdot \\\\ \\cdot & (J/\\mathbf A)^{-1}\\end{pmatrix}\\tag{53}\\]\n任意の \\(\\mathbf x\\) について、\n\\[\\mathbf x^T(\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right]-J^{-1})\\mathbf x\\ge 0\\tag{54}\\]\nであるから、\n\\[\\mathbf x=\\begin{pmatrix}\\mathbf 0 \\\\ \\mathbf x_b\\end{pmatrix}\\tag{55}\\]\nとして、\n\\[\n\\begin{split}\n\\phantom{=}&\\, \\mathbf x^T(\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right]-J^{-1})\\mathbf x \\\\\n=&\\, \\mathbf x_b^T (\\mathbb E_{\\mathbf w_b,y}\\left[(\\mathbf w_b-\\mathbf f_b(y))(\\mathbf w_b-\\mathbf f_b(y))^T\\right]-(J/\\mathbf A)^{-1})\\mathbf x_b \\\\\n\\ge&\\, 0\n\\end{split}\n\\tag{56}\\]\nが成り立つ。",
    "crumbs": [
      "非線形カルマンフィルタ",
      "非線形カルマンフィルタの概要"
    ]
  },
  {
    "objectID": "EKF/summary.html#クラメルラオ不等式",
    "href": "EKF/summary.html#クラメルラオ不等式",
    "title": "非線形カルマンフィルタの概要",
    "section": "",
    "text": "任意の行列\\(\\mathbf A\\)に対して、次の逆行列の公式が成り立つ：\n\\[\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ \\mathbf A & \\mathbf I\\end{pmatrix}^{-1}=\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ -\\mathbf A & \\mathbf I\\end{pmatrix}\\tag{1}\\]\n\n\n\n定義\n区分行列 \\(\\mathbf M\\) を\n\\[\\mathbf M=\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D  \\end{pmatrix}\\tag{2}\\]\nとしたとき、区画 \\(\\mathbf D\\) に関する Schur 補行列とは\n\\[\\mathbf M/\\mathbf D=\\mathbf A-\\mathbf B\\mathbf D^{-1}\\mathbf C\\tag{3}\\]\nで与えられる。区画 \\(\\mathbf A\\) に関する Schur 補行列とは\n\\[\\mathbf M/\\mathbf A=\\mathbf D-\\mathbf C\\mathbf A^{-1}\\mathbf B\\tag{4}\\]\nで与えられる。\n背景\nSchur 補行列はブロック三角行列を掛けるという形でガウス消去法を施した結果として生じる。\n\\[\n\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\\end{pmatrix}\n\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ \\mathbf -\\mathbf D^{-1}\\mathbf C & \\mathbf I\\end{pmatrix}\n=\n\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf B \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\n\\tag{5}\n\\]\n\\[\n\\begin{pmatrix}\\mathbf I & -\\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\n\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\\end{pmatrix}\n=\n\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf 0 \\\\ \\mathbf C & \\mathbf D\\end{pmatrix}\n\\tag{6}\n\\]\n\\[\n\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ -\\mathbf C\\mathbf A^{-1} & \\mathbf I\\end{pmatrix}\n\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\\end{pmatrix}\n=\n\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf 0 & \\mathbf M/\\mathbf A\\end{pmatrix}\n\\tag{7}\n\\]\n\\[\n\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\\end{pmatrix}\n\\begin{pmatrix}\\mathbf I & -\\mathbf A^{-1}\\mathbf B \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\n=\n\\begin{pmatrix}\\mathbf A & \\mathbf 0 \\\\ \\mathbf C & \\ \\mathbf M/\\mathbf A\\end{pmatrix}\n\\tag{8}\n\\]\n\n\n\n定理\n\\[\n\\begin{pmatrix}\n\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\mathbf I & \\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf A-\\mathbf B\\mathbf D^{-1}\\mathbf C & \\mathbf 0 \\\\ \\mathbf 0 & \\mathbf D\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf I & \\mathbf 0 \\\\ \\mathbf D^{-1}\\mathbf C & \\mathbf I\n\\end{pmatrix}\n\\tag{9}\\]\n特に\n\\[\n\\begin{pmatrix}\n\\mathbf A & \\mathbf b \\\\ \\mathbf b^T & c\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\mathbf I & c^{-1}\\mathbf b \\\\ \\mathbf 0^T & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf A-c^{-1}\\mathbf b\\mathbf b^T & \\mathbf 0 \\\\ \\mathbf 0^T & c\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf I & \\mathbf 0 \\\\ c^{-1}\\mathbf b^T & 1\n\\end{pmatrix}\n\\tag{10}\\]\n証明\n\\(\\mathbf M\\) , \\(\\mathbf N\\) をそれぞれ次のように定義する。 \\(\\mathbf N\\) は \\(\\mathbf M\\) に \\((5)\\) の操作を施したときの右側の行列である。\n\\[\\mathbf M=\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\\end{pmatrix},\\ \\mathbf N=\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf B \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\\tag{11}\\]\n\\[\\mathbf M\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ -\\mathbf D^{-1}\\mathbf C & \\mathbf I\\end{pmatrix}=\\mathbf N\\tag{12}\\]\n\\((6)\\) の左辺右側の行列と \\(\\mathbf N\\) の、右側のブロック要素はそれぞれ \\(\\mathbf B, \\mathbf D\\) であり、\\((6)\\) の左辺左側の行列は \\(\\mathbf B, \\mathbf D\\) しか使われていないから、\\((6)\\) の左辺左側の行列をそのまま使って、\n\\[\\begin{pmatrix}\\mathbf I & -\\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\\mathbf N=\\begin{pmatrix}\\mathbf N/\\mathbf D & \\mathbf 0 \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\\tag{13}\\]\nと表せる。\nここで、\n\\[\\mathbf N/\\mathbf D=\\mathbf M/\\mathbf D-\\mathbf B\\mathbf D^{-1}\\mathbf O=\\mathbf M/\\mathbf D\\tag{14}\\]\nであるから、\n\\[\\begin{pmatrix}\\mathbf I & -\\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\\mathbf N=\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf 0 \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\\tag{15}\\]\nが成り立つ。 \\((12)\\) と \\((15)\\) から、\n\\[\\begin{pmatrix}\\mathbf I & -\\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\\mathbf M\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ -\\mathbf D^{-1}\\mathbf C & \\mathbf I\\end{pmatrix}=\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf 0 \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\\tag{16}\\]\nである。 \\((1)\\) を用いると、\n\\[\\mathbf M=\\begin{pmatrix}\\mathbf I & \\mathbf B\\mathbf D^{-1} \\\\ \\mathbf 0 & \\mathbf I\\end{pmatrix}\\begin{pmatrix}\\mathbf M/\\mathbf D & \\mathbf 0 \\\\ \\mathbf 0 & \\mathbf D\\end{pmatrix}\\begin{pmatrix}\\mathbf I & \\mathbf 0 \\\\ \\mathbf D^{-1}\\mathbf C & \\mathbf I\\end{pmatrix}\\tag{17}\\]\nが成り立つ。\n\n\n\n定理\n区分行列 \\(\\mathbf M\\) を\n\\[\\mathbf M=\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D  \\end{pmatrix}\\tag{18}\\]\nとしたとき、\n\\[\n\\begin{split}\n\\mathbf M^{-1} &=\\begin{pmatrix}\\mathbf A^{-1}+\\mathbf A^{-1}\\mathbf B(\\mathbf M/\\mathbf A)^{-1}\\mathbf C\\mathbf A^{-1} & -\\mathbf A^{-1}\\mathbf B(\\mathbf M/\\mathbf A)^{-1} \\\\ -(\\mathbf M/\\mathbf A)^{-1}\\mathbf C\\mathbf A^{-1} & (\\mathbf M/\\mathbf A)^{-1}\\end{pmatrix} \\\\\n&=\\begin{pmatrix}(\\mathbf M/\\mathbf D)^{-1} & -(\\mathbf M/\\mathbf D)^{-1}\\mathbf B\\mathbf D^{-1} \\\\ -\\mathbf D^{-1}\\mathbf C(\\mathbf M/\\mathbf D)^{-1} & \\mathbf D^{-1}+\\mathbf D^{-1}\\mathbf C(\\mathbf M/\\mathbf D)^{-1}\\mathbf B\\mathbf D^{-1}\\end{pmatrix}\n\\end{split}\n\\tag{19}\\]\nが成り立つ。\n\n\n\n\\((59)\\) の行列式は、右辺の左右の行列の行列式は \\(1\\) になるから\n\\[\n\\det\\begin{pmatrix}\n\\mathbf A & \\mathbf B \\\\ \\mathbf C & \\mathbf D\n\\end{pmatrix}\n=\n\\det\\left(\\mathbf A-\\mathbf B\\mathbf D^{-1}\\mathbf C\\right)\\det\\mathbf D\n\\tag{20}\\]\n特に、\n\\[\n\\begin{split}\n\\det\\begin{pmatrix}\n\\mathbf A & \\mathbf b \\\\ \\mathbf b^T & c\n\\end{pmatrix}\n&=\n\\det\\left(\\mathbf A-c^{-1}\\mathbf b\\mathbf b^T\\right)\\det c \\\\\n&=\n\\det\\left(c\\mathbf A-\\mathbf b\\mathbf b^T\\right)\n\\end{split}\n\\tag{21}\\]\n\n\n\n定理\n対称な行列 \\(\\mathbf M\\) を\n\\[\\mathbf M=\\begin{pmatrix}\\mathbf A & \\mathbf B \\\\ \\mathbf B^T & \\mathbf C\\end{pmatrix}\\tag{22}\\]\nとすると、\n\\[\\text{If}\\ \\mathbf C\\succ 0, \\text{then}\\ (\\mathbf M\\succeq 0\\iff \\mathbf M/\\mathbf C\\succeq 0)\\tag{23}\\]\n\\[\\text{If}\\ \\mathbf A\\succ 0, \\text{then}\\ (\\mathbf M\\succeq 0\\iff \\mathbf M/\\mathbf A\\succeq 0)\\tag{24}\\]\nが成り立つ。\n定理\n\\(\\mathbb E\\) を任意の期待値： \\(\\mathbb E_{\\mathbf x,\\mathbf y}, \\mathbb E_{\\mathbf x\\mid\\mathbf y}, \\mathbb E_{\\mathbf y\\mid\\mathbf x}\\) であるとする。\n\\[\n\\begin{pmatrix} \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf f(\\mathbf x,\\mathbf y)^T] & \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\\\ \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]^T & \\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\end{pmatrix}\\succeq 0\n\\tag{25}\\]\n証明\n\\(\\mathbf h(\\mathbf x,\\mathbf y)\\) を\n\\[\\mathbf h(\\mathbf x,\\mathbf y)=\\begin{pmatrix}\\mathbf f(\\mathbf x,\\mathbf y) \\\\ \\mathbf g(\\mathbf x,\\mathbf y)\\end{pmatrix}\\tag{26}\\]\nとすると、任意のベクトル \\(\\mathbf u\\) に対して\n\\[\n\\begin{split}\n&\\phantom{=}\\mathbf u^T\\begin{pmatrix} \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf f(\\mathbf x,\\mathbf y)^T] & \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\\\ \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]^T & \\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\end{pmatrix}\\mathbf u \\\\\n&= \\mathbf u^T\\mathbb E[\\mathbf h(\\mathbf x,\\mathbf y)\\mathbf h(\\mathbf x,\\mathbf y)^T]\\mathbf u \\\\\n&= \\mathbb E[(\\mathbf h(\\mathbf x,\\mathbf y)\\mathbf u)^2] \\\\\n&\\succeq 0\n\\end{split}\n\\tag{27}\\]\n定理\n\\(\\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]\\succ 0\\) のとき、\n\\[\\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf f(\\mathbf x,\\mathbf y)^T]\\succeq\\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]\\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]^{-1}\\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]^T\\tag{28}\\]\nが成り立つ。\n証明\n\\[\\mathbf M=\\begin{pmatrix} \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf f(\\mathbf x,\\mathbf y)^T] & \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\\\ \\mathbb E[\\mathbf f(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]^T & \\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T] \\end{pmatrix}\\tag{29}\\]\nとすると、\\((59)\\) より \\(\\mathbf M\\succeq 0\\) であり、よって \\((59)\\) より \\(\\mathbf M/\\mathbb E[\\mathbf g(\\mathbf x,\\mathbf y)\\mathbf g(\\mathbf x,\\mathbf y)^T]\\succeq 0\\) である。\n\n\n\n\\(\\mathbf w\\) を未知変数、 \\(y\\) を観測変数とする。 Fisher 情報行列を\n\\[\n\\begin{split}\nI(\\mathbf w) &=-\\mathbb E_{y\\mid \\mathbf w}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y\\mid\\mathbf w)\\right] \\\\\n&= -\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y\\mid\\mathbf w)\\right)p(y\\mid\\mathbf w)dy \\\\\n&\\in\\mathbb R^{n\\times n}\n\\end{split}\n\\tag{30}\\]\nとする。各要素は\n\\[\nI_{ij}=-\\mathbb E_{y\\mid\\mathbf w}\\left[\\frac{\\partial^2}{\\partial w_i\\partial w_j}\\ln p(y\\mid\\mathbf w)\\right]\n\\tag{31}\\]\nとなる。\n\n\n\n\\[\n\\begin{split}\nI(\\mathbf w) &=-\\mathbb E_{y\\mid \\mathbf w}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y\\mid\\mathbf w)\\right] \\\\\n&= -\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y\\mid\\mathbf w)\\right)p(y\\mid\\mathbf w)dy \\\\\n&= -\\int\\left(\\frac{\\partial}{\\partial\\mathbf w}\\left[\\frac{1}{p(y\\mid\\mathbf w)}\\frac{\\partial}{\\partial\\mathbf w}p(y\\mid\\mathbf w)\\right]\\right)p(y\\mid\\mathbf w)dy \\\\\n&= -\\int\\left(-\\left[\\frac{1}{p(y\\mid\\mathbf w)}\\right]^2\\left[\\frac{\\partial}{\\partial\\mathbf w}p(y\\mid\\mathbf w)\\right]\\left[\\frac{\\partial}{\\partial\\mathbf w}p(y\\mid\\mathbf w)\\right]^T+\\frac{1}{p(y\\mid\\mathbf w)}\\frac{\\partial^2}{\\partial\\mathbf w^2}p(y\\mid\\mathbf w)\\right)p(y\\mid\\mathbf w)dy \\\\\n&= \\int\\left(\\frac{1}{p(y\\mid\\mathbf w)}\\frac{\\partial}{\\partial \\mathbf w}p(y\\mid\\mathbf w)\\right)\\left(\\frac{1}{p(y\\mid\\mathbf w)}\\frac{\\partial}{\\partial \\mathbf w}p(y\\mid\\mathbf w)\\right)^Tp(y\\mid\\mathbf w)dy-\\int\\frac{\\partial^2}{\\partial\\mathbf w^2}p(y\\mid\\mathbf w)dy \\\\\n&= \\int\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^Tp(y\\mid\\mathbf w)dy-\\underbrace{\\frac{\\partial^2}{\\partial\\mathbf w^2}\\int p(y\\mid\\mathbf w)dy}_\\mathbf O \\\\\n&= \\mathbb E_{y\\mid\\mathbf w}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^T\\right]\n\\end{split}\n\\tag{32}\\]\nであるから、Fisher 情報行列は\n\\[\nI(\\mathbf w) =-\\mathbb E_{y\\mid \\mathbf w}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y\\mid\\mathbf w)\\right] = \\mathbb E_{y\\mid\\mathbf w}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^T\\right]\n\\tag{33}\\]\nと表せる。\n\n\n\n定理\n\\(I(\\mathbf w)\\succ 0\\) のとき、\n\\[\\mathbb E_{y\\mid\\mathbf w}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right]\\succeq I^{-1}(\\mathbf w)\\tag{34}\\]\nが成り立つ。ただし、 \\(\\mathbf f(y)\\) は不偏推定値とする。つまり、次式が成り立つとする。\n\\[\\mathbb E_{y\\mid\\mathbf w}[\\mathbf f(y)]=\\mathbf w\\tag{35}\\]\n証明\nSchur 補行列の正定値性 \\((57)\\) より、\n\\[\n\\begin{split}\n&\\phantom{=}\\mathbb E_{y\\mid\\mathbf w}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right] \\\\\n&\\succeq \\mathbb E_{y\\mid\\mathbf w}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^T\\right]I^{-1}(\\mathbf w)\\mathbb E_{y\\mid\\mathbf w}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^T\\right]^T\n\\end{split}\n\\tag{36}\\]\nここで、\n\\[\n\\begin{split}\n\\mathbb E_{y\\mid\\mathbf w}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(y\\mid\\mathbf w)\\right)^T\\right] &= \\int\\left(\\mathbf w-\\mathbf f(y)\\right)\\left(\\frac{1}{p(y\\mid\\mathbf w)}\\frac{\\partial}{\\partial\\mathbf w}p(y\\mid\\mathbf w)\\right)^Tp(y\\mid\\mathbf w)dy \\\\\n&= \\int \\left(\\mathbf w - \\mathbf f(y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}p(y\\mid\\mathbf w)\\right)^Tdy \\\\\n&= \\mathbf w\\left( \\frac{\\partial}{\\partial \\mathbf w} \\int p(y\\mid\\mathbf w) dy \\right)^T-\\frac{\\partial}{\\partial \\mathbf w^T}\\int \\mathbf f(y) p(y\\mid\\mathbf w)dy \\\\\n&= \\underbrace{\\mathbf w\\left(\\frac{\\partial}{\\partial \\mathbf w} 1\\right)^T}_\\mathbf O-\\frac{\\partial}{\\partial\\mathbf w^T}\\mathbf w \\\\\n&= -\\mathbf I\n\\end{split}\n\\tag{37}\\]\nが成り立つ。 \\(\\mathbf I\\) は単位行列を表す。\n\n\n\n\\(\\mathbf w\\) を未知変数、 \\(y\\) を観測変数とする。 ベイズ情報行列を\n\\[\n\\begin{split}\nJ &=-\\mathbb E_{\\mathbf w, y}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w, y)\\right] \\\\\n&= -\\int\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w, y)\\right)p(\\mathbf w, y)dyd\\mathbf w \\\\\n&\\in\\mathbb R^{n\\times n}\n\\end{split}\n\\tag{38}\\]\nとする。各要素は\n\\[\nJ_{ij}=-\\mathbb E_{\\mathbf w,y}\\left[\\frac{\\partial^2}{\\partial w_i\\partial w_j}\\ln p(\\mathbf w,y)\\right]\n\\tag{39}\\]\nとなる。\n\n\n\n\\[\n\\begin{split}\nJ &=-\\mathbb E_{\\mathbf w,y}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w,y)\\right] \\\\\n&= -\\int\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w,y)\\right)p(\\mathbf w,y)d\\mathbf wdy \\\\\n&= -\\int\\int\\left(\\frac{\\partial}{\\partial\\mathbf w}\\left[\\frac{1}{p(\\mathbf w,y)}\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right]\\right)p(\\mathbf w,y)d\\mathbf wdy \\\\\n&= -\\int\\int\\left(-\\left[\\frac{1}{p(\\mathbf w,y)}\\right]^2\\left[\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right]\\left[\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right]^T+\\frac{1}{p(\\mathbf w,y)}\\frac{\\partial^2}{\\partial\\mathbf w^2}p(\\mathbf w,y)\\right)p(\\mathbf w,y)d\\mathbf wdy \\\\\n&= \\int\\int\\left(\\frac{1}{p(\\mathbf w,y)}\\frac{\\partial}{\\partial \\mathbf w}p(\\mathbf w,y)\\right)\\left(\\frac{1}{p(\\mathbf w,y)}\\frac{\\partial}{\\partial \\mathbf w}p(\\mathbf w,y)\\right)^Tp(\\mathbf w,y)d\\mathbf wdy-\\int\\int\\frac{\\partial^2}{\\partial\\mathbf w^2}p(\\mathbf w,y)d\\mathbf wdy \\\\\n&= \\int\\int\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)^Tp(\\mathbf w,y)d\\mathbf wdy-\\underbrace{\\frac{\\partial^2}{\\partial\\mathbf w^2}\\int\\int p(\\mathbf w,y)d\\mathbf wdy}_\\mathbf O \\\\\n&= \\mathbb E_{\\mathbf w,y}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)^T\\right]\n\\end{split}\n\\tag{40}\\]\nであり、\n\\[\n\\begin{split}\nJ &=-\\mathbb E_{\\mathbf w,y}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w,y)\\right] \\\\\n&= -\\int\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w\\mid y)\\right)p(\\mathbf w,y)d\\mathbf wdy -\\underbrace{\\int\\int\\left(\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(y)\\right)p(\\mathbf w,y)d\\mathbf wdy}_\\mathbf O \\\\\n&= \\mathbb E_{\\mathbf w,y}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w\\mid y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w\\mid y)\\right)^T\\right]\n\\end{split}\n\\tag{41}\\]\nであるから、ベイズ情報行列は\n\\[\n\\begin{split}\nJ &=-\\mathbb E_{\\mathbf w,y}\\left[\\frac{\\partial^2}{\\partial \\mathbf w^2}\\ln p(\\mathbf w,y)\\right] \\\\\n&= \\mathbb E_{\\mathbf w,y}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w,y)\\right)^T\\right] \\\\\n&= \\mathbb E_{\\mathbf w,y}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w\\mid y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}\\ln p(\\mathbf w\\mid y)\\right)^T\\right]\n\\end{split}\\tag{42}\n\\]\nと表せる。\n\n\n\n定理\n\\(J\\succ 0\\) のとき、\n\\[\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right]\\succeq J^{-1}\\tag{43}\\]\nが成り立つ。ただし、次式が成り立つとする。\n\\[\\lim_{\\mathbf w_i\\to\\pm\\infty}\\mathbb E_{y\\mid\\mathbf w}[\\mathbf f(y)-\\mathbf w]p(\\mathbf w)=\\lim_{\\mathbf w_i\\to\\pm\\infty}\\int (\\mathbf f(y)-\\mathbf w)p(\\mathbf w,y)dy=\\mathbf 0,\\ i=1,\\ldots,n\\tag{44}\\]\n証明\nSchur 補行列の正定値性より、\n\\[\n\\begin{split}\n&\\phantom{=}\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right] \\\\\n&\\succeq \\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(\\mathbf w,y)\\right)^T\\right]J^{-1}\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(\\mathbf w,y)\\right)^T\\right]^T\n\\end{split}\n\\tag{45}\\]\nここで、\n\\[\n\\begin{split}\n\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))\\left(\\frac{\\partial}{\\partial \\mathbf w}\\ln p(\\mathbf w,y)\\right)^T\\right] &= \\int\\int\\left(\\mathbf w-\\mathbf f(y)\\right)\\left(\\frac{1}{p(\\mathbf w,y)}\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right)^Tp(\\mathbf w,y)d\\mathbf wdy \\\\\n&= \\int\\int \\left(\\mathbf w - \\mathbf f(y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right)^Td\\mathbf wdy\n\\end{split}\n\\tag{46}\\]\nが成り立つ。\\(ij\\) 要素に対して部分積分すると、\n\\[\n\\begin{split}\n& \\left\\{\\int\\int \\left(\\mathbf w - \\mathbf f(y)\\right)\\left(\\frac{\\partial}{\\partial\\mathbf w}p(\\mathbf w,y)\\right)^Td\\mathbf wdy\\right\\}_{ij} \\\\\n&= \\int\\int(w_i-f_i(y))\\left(\\frac{\\partial}{\\partial w_j}p(\\mathbf w,y)\\right)d\\mathbf wdy \\\\\n&= \\int\\int\\left[(w_i-f_i(y))p(\\mathbf w,y)\\right]_{w_j=-\\infty}^{w_j=\\infty}d\\mathbf w_kdy-\\int\\int\\frac{\\partial}{\\partial w_j}(w_i-f_i(y))p(\\mathbf w,y)d\\mathbf wdy \\\\\n&= \\int\\left[\\lim_{w_j\\to\\infty}\\int(w_i-f_i(y))p(\\mathbf w,y)dy-\\lim_{w_j\\to-\\infty}\\int(w_i-f_i(y))p(\\mathbf w,y)dy\\right]d\\mathbf w_k - I_{ij} \\\\\n&= -I_{ij}\n\\end{split}\n\\tag{47}\\]\nとなる。\\(\\mathbf w_k\\) は \\(k\\neq j\\) となる全ての \\(k\\) を添字とする \\(w\\) を表す。 \\(I_{ij}\\) とは単位行列 \\(\\mathbf I\\) の \\(ij\\) 要素を表す。\n\n\n\n定理\n\\[\\mathbf w - \\mathbf f(y)=\\begin{pmatrix}\\mathbf w_a-\\mathbf f_a(y) \\\\ \\mathbf w_b-\\mathbf f_b(y)\\end{pmatrix}\\tag{48}\\]\nとおくと、ベイズ情報行列は\n\\[J=\\begin{pmatrix}\\mathbf A &\\mathbf B \\\\\\mathbf C &\\mathbf D\\end{pmatrix}\\tag{49}\\]\nと表せる。ただし、例えば \\(\\mathbf A\\) は\n\\[\\mathbf A=\\mathbb E_{\\mathbf w_a,y}\\left[\\left(\\frac{\\partial}{\\partial\\mathbf w_a}\\ln p(\\mathbf w_a\\mid y)\\right)\\left(\\frac{\\partial}{\\partial \\mathbf w_a}\\ln p(\\mathbf w_a\\mid y)\\right)^T\\right]\\tag{50}\\]\nと表す。このとき、\\(J\\succ 0\\) ならば、次を得る。\n\\[\\mathbb E_{\\mathbf w_b,y}\\left[(\\mathbf w_b-\\mathbf f_b(y))(\\mathbf w_b-\\mathbf f_b(y))^T\\right]\\succeq (J/\\mathbf A)^{-1}\\tag{51}\\]\n証明\n次の式において、\\(\\cdot\\) は省略を意味する。\n\\[\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right]=\\begin{pmatrix}\\cdot & \\cdot \\\\ \\cdot & \\mathbb E_{\\mathbf w_b,y}\\left[(\\mathbf w_b-\\mathbf f_b(y))(\\mathbf w_b-\\mathbf f_b(y))^T\\right]\\end{pmatrix}\\tag{52}\\]\n\\[J^{-1}=\\begin{pmatrix}\\cdot & \\cdot \\\\ \\cdot & (J/\\mathbf A)^{-1}\\end{pmatrix}\\tag{53}\\]\n任意の \\(\\mathbf x\\) について、\n\\[\\mathbf x^T(\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right]-J^{-1})\\mathbf x\\ge 0\\tag{54}\\]\nであるから、\n\\[\\mathbf x=\\begin{pmatrix}\\mathbf 0 \\\\ \\mathbf x_b\\end{pmatrix}\\tag{55}\\]\nとして、\n\\[\n\\begin{split}\n\\phantom{=}&\\, \\mathbf x^T(\\mathbb E_{\\mathbf w,y}\\left[(\\mathbf w-\\mathbf f(y))(\\mathbf w-\\mathbf f(y))^T\\right]-J^{-1})\\mathbf x \\\\\n=&\\, \\mathbf x_b^T (\\mathbb E_{\\mathbf w_b,y}\\left[(\\mathbf w_b-\\mathbf f_b(y))(\\mathbf w_b-\\mathbf f_b(y))^T\\right]-(J/\\mathbf A)^{-1})\\mathbf x_b \\\\\n\\ge&\\, 0\n\\end{split}\n\\tag{56}\\]\nが成り立つ。",
    "crumbs": [
      "非線形カルマンフィルタ",
      "非線形カルマンフィルタの概要"
    ]
  },
  {
    "objectID": "EKF/summary.html#非線形フィルタリング",
    "href": "EKF/summary.html#非線形フィルタリング",
    "title": "非線形カルマンフィルタの概要",
    "section": "非線形フィルタリング",
    "text": "非線形フィルタリング\n\n最小分散推定値と条件付き期待値は等価\n\\[\n\\hat{\\mathbf w}\\coloneqq\\mathbb E_{\\mathbf w\\mid y}[\\mathbf w]=\\int \\mathbf w p(\\mathbf w\\mid y)d\\mathbf w\n\\tag{57}\\]\n\\[\\overline{\\mathbf w}\\coloneqq\\mathbb E_{\\mathbf w}[\\mathbf w],\\ \\overline{y}\\coloneqq\\mathbb E_y[y]\\tag{58}\\]\n\\[\n\\begin{pmatrix}\n\\mathbf\\Sigma_{\\mathbf w\\mathbf w} & \\mathbf\\Sigma_{\\mathbf wy} \\\\\n\\mathbf\\Sigma_{\\mathbf wy}^T & \\Sigma_{yy}\n\\end{pmatrix}\n\\coloneqq\n\\begin{pmatrix}\n\\mathbb E[(\\mathbf w-\\overline{\\mathbf w})(\\mathbf w-\\overline{\\mathbf w})^T] & \\mathbb E[(y-\\overline y)(\\mathbf w - \\overline{\\mathbf w})] \\\\\n\\mathbb E[(y-\\overline y)(\\mathbf w - \\overline{\\mathbf w})^T] & \\mathbb E[(y-\\overline y)^2]\n\\end{pmatrix}\n\\tag{59}\\]\n区分行列の行列式より",
    "crumbs": [
      "非線形カルマンフィルタ",
      "非線形カルマンフィルタの概要"
    ]
  },
  {
    "objectID": "Gen/index.html",
    "href": "Gen/index.html",
    "title": "データ生成",
    "section": "",
    "text": "データ生成や実データの整形等。\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\n\n\n\n\n\n00_Gen\n\n\n乱数によってデータを生成する。生成過程: \\((\\mathbf w_t,y_t)\\to\\mathbf x_t\\)\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "データ生成"
    ]
  },
  {
    "objectID": "AnalysisStorage/index.html",
    "href": "AnalysisStorage/index.html",
    "title": "分析データ",
    "section": "",
    "text": "分析データの全て。\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\n\n\n\n\n\n分析00\n\n\n00_Gen によって生成されたデータに対して各種モデルを適用する\n\n\n\n\n\n\n分析01\n\n\n実データ 01_Data/ に対して適用する\n\n\n\n\n\n\n分析02\n\n\n00_Gen/gen_xy_logistic によって生成されたデータに対して各種モデルを適用する\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "分析データ"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis00.html",
    "href": "AnalysisStorage/analysis00.html",
    "title": "分析00",
    "section": "",
    "text": "Parameter (G:jaxtyping.Float[Array,'{N}{N}'],\n            S:jaxtyping.Float[Array,'{N}{N}'],\n            w0:jaxtyping.Float[Array,'{N}'],\n            P0:jaxtyping.Float[Array,'{N}{N}'],\n            epsilon:jaxtyping.Float[Array,'']=Array(1.5258789e-05,\n            dtype=float32, weak_type=True))\n\n\\(\\!\\) 00_Gen によって生成するときのパラメータ。\n\n\n\n\\(\\!\\)\nType\nDefault\nDetails\n\n\n\n\nG\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\boldsymbol\\Gamma\\)\n\n\nS\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\boldsymbol\\Sigma\\)\n\n\nw0\nFloat[Array, ‘{N}’]\n\\(\\!\\)\n\\(\\mathbf w_{-1}\\)\n\n\nP0\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\mathbf P_{-1}\\)\n\n\nepsilon\nFloat[Array, ’’]\n1.52587890625e-05\n\\(\\epsilon\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n Param (N:int, p:int, q:int, r:int)\n\n\\(\\!\\) 可変パラメータ。各パラメータは次のように定義される。\n\n\\(N\\)\n\\(T=1000\\)\n\\(\\boldsymbol\\Gamma=2^p\\mathbf I\\)\n\\(\\boldsymbol\\Sigma=2^q\\mathbf I\\)\n\\(\\mathbf w_{-1}=(r/2)(1,\\ldots,1)^T/\\sqrt{N}\\)\n\\(\\mathbf P_{-1}=\\boldsymbol\\Gamma\\)\n\\(\\epsilon=2^{-16}\\)\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nN\nint\n\\(N\\)\n\n\np\nint\n\\(p\\)\n\n\nq\nint\n\\(q\\)\n\n\nr\nint\n\\(r\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n restore_param (param:__main__.Param)\n\n\\(\\!\\) Param から Parameter に変換する。 \\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nReturns\nTuple\n\\(N\\), \\(T\\), Parameter\n\n\n\n\n\n\n\n\n\n\n\n\n save_data (param:__main__.Param, name:str, data:dict)\n\n\\(\\!\\) 00_Data.h5 にデータを格納する\n.\n├───param1\n│   ├───Gen\n│   │       W (seed, T, N)\n│   │       X (seed, T, N)\n│   │       Y (seed, T)\n│   │\n│   ├───Model1\n│   │       W (seed, T, N)\n│   │       P (seed, T, N, N)\n│   │\n│   ├───Model2\n│\n├───param2\n\\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nname\nstr\nModel name (Gen, EKF, etc.)\n\n\ndata\ndict\ndataset_name: jnp.array\n\n\nReturns\nNone\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n\n\n\n WXY (W:jaxtyping.Float[Array,'TN'], X:jaxtyping.Float[Array,'TN'],\n      Y:jaxtyping.Float[Array,'T'])\n\n\\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nW\nFloat[Array, ‘T N’]\n\\(\\{\\mathbf w_t\\}_{t=0,\\ldots,T-1}\\)\n\n\nX\nFloat[Array, ‘T N’]\n\\(\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1}\\)\n\n\nY\nFloat[Array, ‘T’]\n\\(\\{y_t\\}_{t=0,\\ldots,T-1}\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n generate (key:Union[jaxtyping.Key[Array,''],jaxtyping.UInt32[Array,'2']],\n           N:int, T:int, p:__main__.Parameter)\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nkey\nUnion\nPRNGKeyArray\n\n\nN\nint\n\\(N\\)\n\n\nT\nint\n\\(T\\)\n\n\np\nParameter\nParameter\n\n\nReturns\nWXY\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n\n\n\n generate_main (param:__main__.Param, seed:int)\n\n\\(\\!\\) データを生成し、00_Data.h5 に保存する。 \\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nseed\nint\nseed値\n\n\n\n\n\n\n\n\n\n\n\n\n predict_main (param:__main__.Param, model_name:str, func:Callable[[int,in\n               t,jaxtyping.Float[Array,'TN'],jaxtyping.Float[Array,'T'],__\n               main__.Parameter],NamedTuple])\n\n\\(\\!\\) 00_Data.h5 のデータ \\(X,Y\\) に対して func で \\(W\\) 等を推論し、保存する。 \\(\\!\\)\n\n\n\n\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nmodel_name\nstr\nEKF, etc.\n\n\nfunc\nCallable\n\\(N,T,\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1},\\{y_t\\}_{t=0,\\ldots,T-1},\\mathrm{p}\\to\\{\\hat{\\mathbf w_t}\\}_{t=0,\\ldots,T-1},\\{\\mathbf P_{t/t}\\}_{t=0,\\ldots,T-1},\\ldots\\)",
    "crumbs": [
      "分析データ",
      "分析00"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis00.html#関数定義",
    "href": "AnalysisStorage/analysis00.html#関数定義",
    "title": "分析00",
    "section": "",
    "text": "Parameter (G:jaxtyping.Float[Array,'{N}{N}'],\n            S:jaxtyping.Float[Array,'{N}{N}'],\n            w0:jaxtyping.Float[Array,'{N}'],\n            P0:jaxtyping.Float[Array,'{N}{N}'],\n            epsilon:jaxtyping.Float[Array,'']=Array(1.5258789e-05,\n            dtype=float32, weak_type=True))\n\n\\(\\!\\) 00_Gen によって生成するときのパラメータ。\n\n\n\n\\(\\!\\)\nType\nDefault\nDetails\n\n\n\n\nG\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\boldsymbol\\Gamma\\)\n\n\nS\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\boldsymbol\\Sigma\\)\n\n\nw0\nFloat[Array, ‘{N}’]\n\\(\\!\\)\n\\(\\mathbf w_{-1}\\)\n\n\nP0\nFloat[Array, ‘{N} {N}’]\n\\(\\!\\)\n\\(\\mathbf P_{-1}\\)\n\n\nepsilon\nFloat[Array, ’’]\n1.52587890625e-05\n\\(\\epsilon\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n Param (N:int, p:int, q:int, r:int)\n\n\\(\\!\\) 可変パラメータ。各パラメータは次のように定義される。\n\n\\(N\\)\n\\(T=1000\\)\n\\(\\boldsymbol\\Gamma=2^p\\mathbf I\\)\n\\(\\boldsymbol\\Sigma=2^q\\mathbf I\\)\n\\(\\mathbf w_{-1}=(r/2)(1,\\ldots,1)^T/\\sqrt{N}\\)\n\\(\\mathbf P_{-1}=\\boldsymbol\\Gamma\\)\n\\(\\epsilon=2^{-16}\\)\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nN\nint\n\\(N\\)\n\n\np\nint\n\\(p\\)\n\n\nq\nint\n\\(q\\)\n\n\nr\nint\n\\(r\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n restore_param (param:__main__.Param)\n\n\\(\\!\\) Param から Parameter に変換する。 \\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nReturns\nTuple\n\\(N\\), \\(T\\), Parameter\n\n\n\n\n\n\n\n\n\n\n\n\n save_data (param:__main__.Param, name:str, data:dict)\n\n\\(\\!\\) 00_Data.h5 にデータを格納する\n.\n├───param1\n│   ├───Gen\n│   │       W (seed, T, N)\n│   │       X (seed, T, N)\n│   │       Y (seed, T)\n│   │\n│   ├───Model1\n│   │       W (seed, T, N)\n│   │       P (seed, T, N, N)\n│   │\n│   ├───Model2\n│\n├───param2\n\\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nname\nstr\nModel name (Gen, EKF, etc.)\n\n\ndata\ndict\ndataset_name: jnp.array\n\n\nReturns\nNone\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n\n\n\n WXY (W:jaxtyping.Float[Array,'TN'], X:jaxtyping.Float[Array,'TN'],\n      Y:jaxtyping.Float[Array,'T'])\n\n\\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nW\nFloat[Array, ‘T N’]\n\\(\\{\\mathbf w_t\\}_{t=0,\\ldots,T-1}\\)\n\n\nX\nFloat[Array, ‘T N’]\n\\(\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1}\\)\n\n\nY\nFloat[Array, ‘T’]\n\\(\\{y_t\\}_{t=0,\\ldots,T-1}\\)\n\n\n\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n generate (key:Union[jaxtyping.Key[Array,''],jaxtyping.UInt32[Array,'2']],\n           N:int, T:int, p:__main__.Parameter)\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nkey\nUnion\nPRNGKeyArray\n\n\nN\nint\n\\(N\\)\n\n\nT\nint\n\\(T\\)\n\n\np\nParameter\nParameter\n\n\nReturns\nWXY\n\\(\\!\\)\n\n\n\n\n\n\n\n\n\n\n\n\n generate_main (param:__main__.Param, seed:int)\n\n\\(\\!\\) データを生成し、00_Data.h5 に保存する。 \\(\\!\\)\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nseed\nint\nseed値\n\n\n\n\n\n\n\n\n\n\n\n\n predict_main (param:__main__.Param, model_name:str, func:Callable[[int,in\n               t,jaxtyping.Float[Array,'TN'],jaxtyping.Float[Array,'T'],__\n               main__.Parameter],NamedTuple])\n\n\\(\\!\\) 00_Data.h5 のデータ \\(X,Y\\) に対して func で \\(W\\) 等を推論し、保存する。 \\(\\!\\)\n\n\n\n\n\n\n\n\n\\(\\!\\)\nType\nDetails\n\n\n\n\nparam\nParam\nParam\n\n\nmodel_name\nstr\nEKF, etc.\n\n\nfunc\nCallable\n\\(N,T,\\{\\mathbf x_t\\}_{t=0,\\ldots,T-1},\\{y_t\\}_{t=0,\\ldots,T-1},\\mathrm{p}\\to\\{\\hat{\\mathbf w_t}\\}_{t=0,\\ldots,T-1},\\{\\mathbf P_{t/t}\\}_{t=0,\\ldots,T-1},\\ldots\\)",
    "crumbs": [
      "分析データ",
      "分析00"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis00.html#関数のテスト",
    "href": "AnalysisStorage/analysis00.html#関数のテスト",
    "title": "分析00",
    "section": "関数のテスト",
    "text": "関数のテスト\n\nLOCK = True",
    "crumbs": [
      "分析データ",
      "分析00"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis00.html#データ生成",
    "href": "AnalysisStorage/analysis00.html#データ生成",
    "title": "分析00",
    "section": "データ生成",
    "text": "データ生成",
    "crumbs": [
      "分析データ",
      "分析00"
    ]
  },
  {
    "objectID": "AnalysisStorage/analysis00.html#分析",
    "href": "AnalysisStorage/analysis00.html#分析",
    "title": "分析00",
    "section": "分析",
    "text": "分析\n\n推論結果の様子\n\n\n\n\n\n\n\n\n\n\n\n結果\n\n\\(N\\)\n\\(T=1000\\)\n\\(\\boldsymbol\\Gamma=2^p\\mathbf I\\)\n\\(\\boldsymbol\\Sigma=2^q\\mathbf I\\)\n\\(\\mathbf w_{-1}=(r/2)(1,\\ldots,1)^T/\\sqrt{N}\\)\n\\(\\mathbf P_{-1}=\\boldsymbol\\Gamma\\)\n\\(\\epsilon=2^{-16}\\)\n\n\n\nListening on: localhost:8060\n\n\n\n        \n        \n\n\n\n\n誤差\n\\[E(\\{w_{0,t}\\}_{t=0,\\ldots,T})=\\{\\hat{w}_{0,t} - w_{0,t}\\}_{t=0,\\ldots,T}\\]\n\n\\(N\\)\n\\(T=1000\\)\n\\(\\boldsymbol\\Gamma=2^p\\mathbf I\\)\n\\(\\boldsymbol\\Sigma=2^q\\mathbf I\\)\n\\(\\mathbf w_{-1}=(r/2)(1,\\ldots,1)^T/\\sqrt{N}\\)\n\\(\\mathbf P_{-1}=\\boldsymbol\\Gamma\\)\n\\(\\epsilon=2^{-16}\\)\n\n\n\nListening on: localhost:8070\n\n\n\n        \n        \n\n\n\n\nListening on: localhost:8061\n\n\n\n        \n        \n\n\n\n\n\n\n\n\n\n\n\nalgorithm\nfrob_error\nrelative_error\n\n\np\n\n\n\n\n\n\n\n-4\nEKF\n5.580760\n63.139098\n\n\n-4\nVApre\n1.658594\n18.764848\n\n\n-4\nVAEM\n1.655468\n18.729480\n\n\n-6\nEKF\n1.061542\n48.039904\n\n\n-6\nVApre\n0.723463\n32.740207\n\n\n-6\nVAEM\n0.722900\n32.714732\n\n\n-8\nEKF\n0.375931\n68.050840\n\n\n-8\nVApre\n0.341001\n61.727846\n\n\n-8\nVAEM\n0.340927\n61.714354\n\n\n-10\nEKF\n0.164551\n119.147344\n\n\n-10\nVApre\n0.161168\n116.698451\n\n\n-10\nVAEM\n0.161162\n116.693650\n\n\n-12\nEKF\n0.072807\n210.870368\n\n\n-12\nVApre\n0.072609\n210.298627\n\n\n-12\nVAEM\n0.072609\n210.297181",
    "crumbs": [
      "分析データ",
      "分析00"
    ]
  },
  {
    "objectID": "funcs.html",
    "href": "funcs.html",
    "title": "簡単な関数等",
    "section": "",
    "text": "source\n\nreshow_doc\n\ndef reshow_doc(\n    sym:object, # 定義した関数等\n):\n\n*\\(\\!\\)** VSCode で Quarto 拡張機能 (nbdev 拡張機能の Extention pack) を有効にすると 空セルを含むテーブルが表示されないというバグを解決する(空セルを $\\!$ で埋める)。\nshow_doc の代わりに使用すること。 *\\(\\!\\)\n\nsource\n\n\nrewrite_nt\n\ndef rewrite_nt(\n    nt:Type, # NamedTuple を継承したクラス\n):\n\n*\\(\\!\\)** NamedTuple のメンバがテーブルで表示されるように __doc__ を書き換える。\n定義した NamedTuple と同じセルで実行すること。\nコメントは下記のように、table と記載した後下に引数とコメントを列挙し、上下を空行で挟むこと。\n\ntable\n{arg1}: {comment1}\n{arg2}: {comment2}\n\n*\\(\\!\\)\n\nsource\n\n\nhex_to_rgb\n\ndef hex_to_rgb(\n    hex_color:str, # #123456 のような形式\n)-&gt;str: # rgb(14, 35, 54) のような形式\n\n*\\(\\!\\)** 6桁カラーコード(#xxyyzz)を形式 “rgb(XX, YY, ZZ)” にして出力する *\\(\\!\\)\n\nsource\n\n\nlosi\n\ndef losi(\n    x:Float[Array, ''], # $x$\n)-&gt;Float[Array, '']: # $\\sigma(x)=1/(1+ e\\\\^{-x})$\n\n*\\(\\!\\)** Logistic sigmoid 関数 \\[\\sigma(x)=\\frac{1}{1+e^{-x}}\\] *\\(\\!\\)\n\nsource\n\n\ndxlosi\n\ndef dxlosi(\n    x:Float[Array, ''], # $x$\n)-&gt;Float[Array, '']: # $(d/dx)\\sigma(x)$\n\n*\\(\\!\\)** Logistic sigmoid 関数の導関数 \\[\\frac{d}{dx}\\sigma(x)=\\sigma(x)\\{1-\\sigma(x)\\}\\] *\\(\\!\\)",
    "crumbs": [
      "簡単な関数等"
    ]
  }
]